(151.64700317382812, 77.11167907714844, 445.902099609375, 111.7160873413086, 'A Scalable MMR Approach to Sentence Scoring\nfor Multi-Document Update Summarization\n', 1, 0)
(103.84500122070312, 128.00344848632812, 294.0196533203125, 147.46478271484375, 'Florian Boudin ♮ and Marc El-B`eze ♮\n', 2, 0)
(317.7959899902344, 131.91107177734375, 478.428466796875, 147.46478271484375, 'Juan-Manuel Torres-Moreno ♮,♭\n', 6, 0)
(108.19798278808594, 142.06045532226562, 290.1680908203125, 188.70046997070312, '♮ Laboratoire Informatique d’Avignon\n339 chemin des Meinajaries, BP1228,\n84911 Avignon Cedex 9, France.\n', 3, 0)
(307.5409851074219, 142.94644165039062, 489.18829345703125, 189.58645629882812, '♭ ´Ecole Polytechnique de Montr´eal\nCP 6079 Succ. Centre Ville H3C 3A7\nMontr´eal (Qu´ebec), Canada.\n', 7, 0)
(118.48497772216797, 192.01731872558594, 279.8801574707031, 201.41409301757812, 'florian.boudin@univ-avignon.fr\n', 4, 0)
(306.906005859375, 192.90330505371094, 489.82098388671875, 202.30007934570312, 'juan-manuel.torres@univ-avignon.fr\n', 8, 0)
(126.55497741699219, 205.96434020996094, 271.8106384277344, 215.36111450195312, 'marc.elbeze@univ-avignon.fr\n', 5, 0)
(159.60101318359375, 255.73309326171875, 204.0863037109375, 271.28680419921875, 'Abstract\n', 9, 0)
(89.00898742675781, 277.55206298828125, 274.681884765625, 412.6405944824219, 'We present SMMR, a scalable sentence\nscoring method for query-oriented up-\ndate summarization. Sentences are scored\nthanks to a criterion combining query rele-\nvance and dissimilarity with already read\ndocuments (history).\nAs the amount of\ndata in history increases, non-redundancy\nis prioritized over query-relevance.\nWe\nshow that SMMR achieves promising re-\nsults on the DUC 2007 update corpus.\n', 10, 0)
(72.00098419189453, 418.91815185546875, 154.81466674804688, 434.47186279296875, '1\nIntroduction\n', 11, 0)
(72.00098419189453, 440.67413330078125, 291.6885070800781, 697.70458984375, 'Extensive experiments on query-oriented multi-\ndocument summarization have been carried out\nover the past few years.\nMost of the strategies\nto produce summaries are based on an extrac-\ntion method, which identiﬁes salient textual seg-\nments, most often sentences, in documents. Sen-\ntences containing the most salient concepts are se-\nlected, ordered and assembled according to their\nrelevance to produce summaries (also called ex-\ntracts) (Mani and Maybury, 1999).\nRecently emerged from the Document Under-\nstanding Conference (DUC) 20071, update sum-\nmarization attempts to enhance summarization\nwhen more information about knowledge acquired\nby the user is available. It asks the following ques-\ntion: has the user already read documents on the\ntopic? In the case of a positive answer, producing\nan extract focusing on only new facts is of inter-\nest. In this way, an important issue is introduced:\n', 12, 0)
(72.00101470947266, 702.9140625, 291.68731689453125, 774.6765747070312, 'c⃝ 2008.\nLicensed under the Creative Commons\nAttribution-Noncommercial-Share Alike 3.0 Unported\nli-\ncense\n(http://creativecommons.org/licenses/by-nc-sa/3.0/).\nSome rights reserved.\n1Document Understanding Conferences are conducted\nsince 2000 by the National Institute of Standards and Tech-\nnology (NIST), http://www-nlpir.nist.gov\n', 13, 0)
(305.8590393066406, 257.1300048828125, 525.5465087890625, 775.2225341796875, 'redundancy with previously read documents (his-\ntory) has to be removed from the extract.\nA natural way to go about update summarization\nwould be extracting temporal tags (dates, elapsed\ntimes, temporal expressions...) (Mani and Wilson,\n2000) or to automatically construct the timeline\nfrom documents (Swan and Allan, 2000). These\ntemporal marks could be used to focus extracts on\nthe most recently written facts. However, most re-\ncently written facts are not necessarily new facts.\nMachine Reading (MR) was used by (Hickl et\nal., 2007) to construct knowledge representations\nfrom clusters of documents. Sentences contain-\ning “new” information (i.e. that could not be in-\nferred by any previously considered document)\nare selected to generate summary. However, this\nhighly efﬁcient approach (best system in DUC\n2007 update) requires large linguistic resources.\n(Witte et al., 2007) propose a rule-based system\nbased on fuzzy coreference cluster graphs. Again,\nthis approach requires to manually write the sen-\ntence ranking scheme. Several strategies remain-\ning on post-processing redundancy removal tech-\nniques have been suggested. Extracts constructed\nfrom history were used by (Boudin and Torres-\nMoreno, 2007) to minimize history’s redundancy.\n(Lin et al., 2007) have proposed a modiﬁed Max-\nimal Marginal Relevance (MMR) (Carbonell and\nGoldstein, 1998) re-ranker during sentence selec-\ntion, constructing the summary by incrementally\nre-ranking sentences.\nIn this paper, we propose a scalable sentence\nscoring method for update summarization derived\nfrom MMR. Motivated by the need for relevant\nnovelty, candidate sentences are selected accord-\ning to a combined criterion of query relevance and\ndissimilarity with previously read sentences. The\nrest of the paper is organized as follows. Section 2\n', 14, 0)
(293.3169860839844, 787.5889892578125, 304.2261047363281, 800.7344360351562, '23\n', 15, 0)
(160.4530029296875, 801.6880493164062, 440.4891357421875, 823.8195190429688, 'Coling 2008: Companion volume – Posters and Demonstrations, pages 23–26\nManchester, August 2008\n', 0, 0)
