(117.96499633789062, 515.1713256835938, 476.3507080078125, 569.5201416015625, 'This article appeared in a journal published by Elsevier. The attached\ncopy is furnished to the author for internal non-commercial research\nand education use, including for instruction at the authors institution\nand sharing with colleagues.\n', 0, 0)
(124.77799224853516, 575.3453369140625, 469.5382080078125, 616.1451416015625, 'Other uses, including reproduction and distribution, or selling or\nlicensing copies, or posting to personal, institutional or third party\nwebsites are prohibited.\n', 1, 0)
(133.3409881591797, 621.9703369140625, 460.97393798828125, 689.869140625, 'In most cases authors are permitted to post their version of the\narticle (e.g. in Word or Tex form) to their personal website or\ninstitutional repository. Authors requiring further information\nregarding Elsevier’s archiving and manuscript policies are\nencouraged to visit:\n', 2, 0)
(209.05499267578125, 695.6943359375, 385.2587585449219, 709.3961791992188, 'http://www.elsevier.com/copyright\n', 3, 0)

page suivante
(214.17039489746094, 6.72001838684082, 381.1054382324219, 27.375019073486328, "Author's personal copy\n", 0, 0)
(44.884525299072266, 192.3704376220703, 440.278564453125, 210.45909118652344, 'A hybrid approach to managing job offers and candidates\n', 1, 0)
(44.88358688354492, 217.990966796875, 484.6080017089844, 248.50672912597656, 'Rémy Kessler a,⇑, Nicolas Béchet c, Mathieu Roche d, Juan-Manuel Torres-Moreno b,\nMarc El-Bèze a\n', 2, 0)
(44.884525299072266, 252.26365661621094, 373.42315673828125, 291.8841552734375, 'a LIA/Université d’Avignon et des Pays de Vaucluse, 339 chemin des Meinajariès, 84911 Avignon, France\nb École Polytechnique de Montréal, CP 6079, succ. Centre-ville, Montréal (Québec) Canada H3C 3A7\nc INRIA Domaine de Voluceau, BP 105, 78153 Le Chesnay Cedex, France\nd LIRMM, CNRS Université Montpellier 2, 161 rue Ada, 34392 Montpellier, France\n', 3, 0)
(44.884525299072266, 314.244384765625, 148.1293182373047, 326.303466796875, 'a r t i c l e\ni n f o\n', 4, 0)
(44.884525299072266, 337.8798522949219, 176.41688537597656, 383.8501281738281, 'Article history:\nReceived 9 February 2011\nReceived in revised form 1 March 2012\nAccepted 6 March 2012\nAvailable online 10 April 2012\n', 5, 0)
(44.884525299072266, 397.31378173828125, 139.25357055664062, 462.08197021484375, 'Keywords:\nNatural language processing\nAutomatic summarization\nInformation retrieval\nHuman resources\nStatistical approaches\nSimilarity measures\n', 6, 0)
(218.72267150878906, 314.55462646484375, 290.0967712402344, 326.61370849609375, 'a b s t r a c t\n', 7, 0)
(218.72218322753906, 338.06591796875, 555.1397705078125, 473.6056213378906, 'The evolution of the job market has resulted in traditional methods of recruitment becom-\ning insufﬁcient. As it is now necessary to handle volumes of information (mostly in the\nform of free text) that are impossible to process manually, an analysis and assisted catego-\nrization are essential to address this issue. In this paper, we present a combination of the\nE-Gen and CORTEX systems. E-Gen aims to perform analysis and categorization of job offers\ntogether with the responses given by the candidates. E-Gen system strategy is based on\nvectorial and probabilistic models to solve the problem of proﬁling applications according\nto a speciﬁc job offer. CORTEX is a statistical automatic summarization system. In this work,\nE-Gen uses Cortex as a powerful ﬁlter to eliminate irrelevant information contained in\ncandidate answers. Our main objective is to develop a system to assist a recruitment\nconsultant and the results obtained by the proposed combination surpass those of E-Gen\nin standalone mode on this task.\n\x02 2012 Elsevier Ltd. All rights reserved.\n', 8, 0)
(44.884525299072266, 514.8094482421875, 110.771728515625, 525.5201416015625, '1. Introduction\n', 9, 0)
(44.88448715209961, 537.7893676757812, 555.13671875, 594.2941284179688, 'The evolution of the job market has resulted in that traditional methods of recruitment becoming insufﬁcient. The\nInternet has introduced a new way of managing human resources. Theoretically, shifting job search and recruitment activ-\nities to the Internet improves the quality of job matching by reducing search costs, increasing contact opportunities and\nrationalizing the screening process of job applicants (Marchal, Mellet, & Rieucau, 2007). Over the last few years, there has\nbeen a signiﬁcant expansion of online recruitment (e.g. August 2003: 177,000 job offers, May 2008: 500,000 job offers).1\n', 10, 0)
(44.884521484375, 594.9912109375, 555.16845703125, 685.8660278320312, 'The Internet has become essential in this process because it allows a better ﬂow of information, either through job search\nsites or by e-mail exchanges. Nowadays, job seekers can send their curriculum vitae (CV) directly to companies (by e-mail\nor uploaded to dedicated servers on the Web). The job search task is becoming easier and less time consuming. The Internet\nmakes every user a potential job seeker. Employees may be constantly in search of new career opportunities and job candi-\ndates may provide more interaction than can be managed efﬁciently by companies (Bourse, LeclFre, Morin, & Trichet, 2004).\nAs intellectual capital has become one of the most strategic assets of successful organizations in the last decade, the capa-\nbility of managing people’s expertise, skills and experience represents a key factor in facing up to the increasing competitive-\nness of the global market (Colucci et al., 2003). Even though a browser has become a universal and easy tool for users, they\n', 11, 0)
(44.88451385498047, 751.2744750976562, 283.8144836425781, 769.4961547851562, '0306-4573/$ - see front matter \x02 2012 Elsevier Ltd. All rights reserved.\nhttp://dx.doi.org/10.1016/j.ipm.2012.03.002\n', 12, 0)
(44.8841552734375, 700.6885986328125, 555.077880859375, 740.461181640625, '⇑ Corresponding author.\nE-mail addresses: remy.kessler@univ-avignon.fr (R. Kessler), nicolas.bechet@inria.fr (N. Béchet), mathieu.roche@lirmm.fr (M. Roche), juan-manuel.tor-\nres@univ-avignon.fr (J.-M. Torres-Moreno), marc.elbeze@univ-avignon.fr (M. El-Bèze).\n1 http://www.keljob.com.\n', 13, 0)
(193.96849060058594, 51.11286544799805, 406.0278625488281, 59.688148498535156, 'Information Processing and Management 48 (2012) 1124–1135\n', 14, 0)
(199.6761932373047, 80.82420349121094, 403.56060791015625, 89.72067260742188, 'Contents lists available at SciVerse ScienceDirect\n', 15, 0)
(149.54734802246094, 103.863037109375, 453.5, 122.6216049194336, 'Information Processing and Management\n', 16, 0)
(154.63467407226562, 141.87229919433594, 448.56500244140625, 150.76876831054688, 'journal homepage: www.elsevier.com/locate/infoproman\n', 17, 0)

page suivante
(214.17039489746094, 6.72001838684082, 381.1054382324219, 27.375019073486328, "Author's personal copy\n", 0, 0)
(40.167327880859375, 72.29792785644531, 550.4683227539062, 140.28060913085938, 'frequently have to enter data into Web forms from paper sources and the need to ‘‘copy and paste’’ data between different\napplications is symptomatic of the issues of data integration. In this context, electronic recruitment tends to automate match-\ning between the published information about the candidates and job offers. The Laboratoire Informatique d’Avignon (LIA),2 the\nLaboratoire d’Informatique, de Robotique et de Microélectronique de Montpellier(LIRMM),3 and Aktor Interactive4 are developing\nthe E-Gen system to resolve this issue. E-Gen is a Natural Language Processing (NLP) and Information Retrieval (IR) system\ncomposed of three main modules:\n', 1, 0)
(48.2968635559082, 152.4546661376953, 550.3771362304688, 186.06674194335938, '1. The ﬁrst one extracts the information from a corpus of e-mails of job offers from Aktor’s database.\n2. The second module analyses the candidate’s answers (i.e. splitting e-mails into cover letter (CL) and curriculum vitae).\n3. The third module analyses and computes a relevant ranking of the candidate’s answers.\n', 2, 0)
(40.16799545288086, 198.2400665283203, 550.4512939453125, 403.5815734863281, 'Our ﬁrst work (Kessler, Torres-Moreno, & El-Bèze, 2007) presented the ﬁrst module: the identiﬁcation of different parts\nof a job offer and the extraction of relevant information (type of contract, salary, localization, etc.). The second module\nanalyses the content of a candidate’s e-mail, using a combination of rules and machine learning methods (Support Vector\nMachines, SVM) and was presented in Kessler, Torres-Moreno, and El-Bèze (2008b). Furthermore, it separates the distinct\nparts of CV and CL with a precision of 0.98 and a recall of 0.96. Reading a large number of candidate answers for a job is a\nvery time consuming task for a recruiting consultant. In order to facilitate this task, we propose a system capable of pro-\nviding an initial evaluation of candidate answers according to various criteria. We do not seek the best or even a good can-\ndidate as no scoring is involved, but simply a candidate who has a close application to those already selected. Our previous\nwork (Kessler, Béchet, Roche, El-Bèze, & Torres-Moreno, 2009) presented an approach based on a process of relevance feed-\nback, permitting a reinforcement learning (Sutton & Barto, 1998). In this paper, we present an original combination of the\nE-Gen and CORTEX systems. Each document contains a number of additional information, present in many applications and\nwhich is partially removed by classical pre-processing. Each application added by the process of relevance feedback adds\nrelevant information but also multiplies additional information. CORTEX allows us to ﬁlter these sentences and keep only the\nmost relevant sentences at the evaluation step. Some related studies are brieﬂy discussed in Section 2. Section 3 shows a\ngeneral system overview. In Section 4, we describe the E-Gen pre-processing task, the strategy used to rank the candidate\nanswers with relevance feedback and the coupling of E-Gen with the CORTEX summarization system. In Section 5, we present\nstatistics about the textual corpus, experimental protocol, an example of CL summary generated by CORTEX, and several\nresults.\n', 3, 0)
(40.170833587646484, 417.5917663574219, 108.83124542236328, 428.30242919921875, '2. Related work\n', 4, 0)
(40.169960021972656, 440.5716857910156, 550.4694213867188, 577.169921875, 'Many approaches have been proposed in the literature to reduce the costly and tedious task of managing human re-\nsources. Candidate answers to a job offer come as ad hoc documents, and require semantic approaches to analyse them.\nThe BONOM system is based on an indexing method (Morin, LeclFre, & Trichet, 2004; Cazalens & Lamarre, 2001). This\nmethod consists in using distributional attributes of documents to locate each part for the ﬁnal indexation of the\ndocument.\nA semantic-based method to select candidate answers and to discuss the economic impacts on the German government\nwas proposed by Tolksdorf, Mocho, Heese, Oldakowski, and Christian (2006). In the same way (Gorenak & Mlaker KaF, 2010),\nperform a comparison between Slovenian, German, and British online job advertisements (ads). More recently (Marchal et\nal., 2007), present a comparison between French and English job search sites and newspapers as well as the various short-\ncoming of current matching systems. They propose a comparative analysis of job offers posted on the Internet with those\nposted in newspapers and they observe that search engine toolkits have a considerable impact on ad content which is gen-\nerally more standardized and quantiﬁed than before.\n', 5, 0)
(40.16996383666992, 577.9279174804688, 550.4568481445312, 714.5261840820312, 'Mocho, Paslaru, and Simperl (2006) discuss the relevance of a common ontology (HR ontology) to work efﬁciently with\nthis kind of document. Using the same model (Dorn & Naz, 2007), outline a HR-XML based prototype dedicated to the job\nsearch task. The prototype selects and favors relevant information (paycheck, topic, abilities, etc.) from many job-service\nwebsites, such as Jobs.net, aftercollege.com, Directjobs.com, etc. Bourse et al. (2004) describe an efﬁcient model\nand a management tool used for the selection of candidate-answers. They propose a prototype job portal which uses seman-\ntically annotated job offers and applicants to obtain a more accurate job search with query approximation.\nThe limitations of current systems for automatic selection of candidate answers are presented in Rafter, Bradley, and Smyt\n(2000). They propose a system based on collaborative ﬁlters (ACF) to automatically select proﬁles of candidate answers on\nthe JobFinder website. Enrica and Iezzi (2006) present a model for ranking skills in the ﬁeld of information technology in Italy\nwith multidimensional scaling and cluster analysis. In the same way, Colucci et al. (2003) present a semantic based approach\nto the issue of skills detection in an ontology supported framework. Based on Description Logics formalization and reasoning,\nthey propose a skill matching approach with contradiction matches and partial matches between skill proﬁles. Loth et al.\n', 6, 0)
(46.187435150146484, 738.4002075195312, 354.58258056640625, 769.4962768554688, '2 http://www.lia.univ-avignon.fr.\n3 http://www.lirmm.fr.\n4 A French recruitment agency specialized in recruiting on the internet, (http://www.aktor.fr).\n', 7, 0)
(167.7873077392578, 51.2989616394043, 550.4119873046875, 59.874244689941406, 'R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135\n1125\n', 8, 0)

page suivante
(214.17039489746094, 6.72001838684082, 381.1054382324219, 27.375019073486328, "Author's personal copy\n", 0, 0)
(44.88251876831055, 72.29792785644531, 555.16162109375, 357.7951354980469, '(2010) combine, through the SIRE project (Semantics-Internet-Recruitment-Employment) a linguistic approach and machine\nlearning methods to perform an extraction of key terms of job ads in order to improve the categorization of each job offer.\nThe study of the most relevant document – the CV – to use it automatically has been a major subject of research. Ben\nAbdessalem Karaa (2009) presents a system for analyzing and structuring CVs with an extension of General Architecture\nof Text Engineering (GATE5). They obtain good results in precision/recall for each part of the document (personal information,\nexperience, skill, and so forth) on a small corpus of CVs in French. Yahiaoui, Boufaı¨da, and Prié (2006) provide a semantic ap-\nproach to generating some annotations of CVs and job offers with the help of a specialized ontology to match graduates and the\nlevel of a job offer. They present interesting results on a sample of data. Clech and Zighed (2003) propose a data mining ap-\nproach. Their aim is to build automats which recognize CV topologies and candidate/job offer proﬁles. A ﬁrst step differentiates\nthe CV of employed executives from other CV. They use a speciﬁc term extraction to obtain a categorization with the C4.5 deci-\nsion tree algorithm (Quilan, 1993). This method focuses on the speciﬁcity of selected terms or concepts, such as education level\nor relevant abilities, to build a classiﬁer. The results of this method are still poor (an accuracy between 0.5–0.6 of correctly cat-\negorized CV). Roche and Kodratoff (2006) and Roche and Prince (2008) have made a terminology study of corpus composed of\nCVs (of the Vediorbis company (http://www.vediorbis.com)). Their approach extracts collocations from a CV corpus based on\nsyntactic patterns such as Noun-Noun, Adjective-Noun, etc. Then, these collocations are ranked according to relevance to build\na specialized ontology.\nThere are few studies on the treatment of the cover letter. Audras and Ganascia (2006) use cover letters to detect the\nusual errors in the ﬁeld of acquisition of written French as a foreign language. The approach proposed is the detection of\nsyntactic patterns particular to a group of learners, and which are absent or little used among native speakers. The study\nfocuses in part on cover letter writing. Among the innovative solutions on the market, Twitter6 has launched the job search\nsite http://www.twitterjobsearch.com based on the concept of short messages (less than 140 characters) and ZaPoint7 with an\noriginal solution, SkillsMapper, which transforms each CV into graphic format with various curves (training, education, etc.). In\nthis paper, we present an approach to the application ranking by using a combination of similarity measures, relevance feedback\nand summaries of a CV and CL. Our approach is distinguished from other work by a purely statistical approach as well as rein-\nforcement learning through the process of relevance feedback.\n', 1, 0)
(44.884525299072266, 377.9474792480469, 128.67491149902344, 388.65814208984375, '3. System overview\n', 2, 0)
(44.88365173339844, 400.990234375, 555.1707153320312, 674.9475708007812, 'Nowadays technology proposes new approaches to the online employment market. E-Gen is a system which meets this\nchallenge as fast and judiciously as possible. We chose emails as the input format, which is the most frequent mode of com-\nmunication in this ﬁeld. An e-mail inbox receives messages sometimes with an attached ﬁle containing the job offer. When a\njob offer is published online, a particular segmentation is required by the job search sites. Firstly, the job offer language is\nidentiﬁed by using n-grams. Then, E-Gen parses the e-mail, splits the job offer into thematic segments, and retrieves relevant\ninformation (contract, salary, starting date, location, etc.) to generate an XML document for the job offer. Subsequently, a\nﬁltering and lemmatisation process is applied to the text, and is represented in a vector space model (VSM). A categorization\nof text segments (preamble, skills or proﬁle, mission) is obtained by using a SVM classiﬁer (Fan, Chen, & Lin, 2005). This pre-\nliminary classiﬁcation is then transmitted to a ‘‘corrective’’ post-process which improves the quality of the solution (Module\n1, described in Kessler et al., 2007). Preliminary experiments showed that segment categorization without segment position\nin job posting is not enough and may be a source of errors. In order to avoid this kind of error, we have decided to consider\neach job posting as produced by a succession of states in a Markov machine and we have applied a post-processing, based on\nthe Viterbi algorithm (Viterbi, 1967). During the publication of a job offer, Aktor generates a temporary e-mail address for\napplying to the job. Each e-mail is redirected to human resources software (Gestmax8) to be read by a recruiting consultant.\nAt this step, E-Gen analyses the candidate’s answers to identify each part of the application and extracts the text from the e-mail\nand attached ﬁles (by using wvWare9 and pdftotext10).\nAfter a pre-processing task, we use a combination of rules and machine learning methods to separate each distinct part\n(CV or CL). We use a vector representation of each document with a label (CV or CL). With a learning set of 2.000 documents\nof each type, the system gets very good performance (F-score between 0.95 and 0.98). This process (Module 2 represented by\nthe lowest box in Fig. 1) is more fully described in Kessler et al. (2008b). Once the CL and CV have been identiﬁed, the CORTEX\nsystem is applied to each document (Cover Letter and CV) and a summary is generated by concatenating high-scoring sen-\ntences. Afterwards, E-Gen performs an automated proﬁling of this application by using measures of similarity and a small\nnumber of applications that have been previously validated as relevant by a recruitment consultant (Module 3). The whole\nchain is summarized in Fig. 1.\n', 3, 0)
(47.92457580566406, 709.2410278320312, 214.18698120117188, 769.4962768554688, '5 http://gate.ac.uk/.\n6 http://twitter.com.\n7 http://www.zapoint.com.\n8 http://www.gestmax.fr.\n9 http://wvware.sourceforge.net.\n10 http://www.bluem.net/downloads/pdftotext_en.\n', 4, 0)
(44.884525299072266, 51.36103439331055, 427.51580810546875, 59.936317443847656, '1126\nR. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135\n', 5, 0)

page suivante
(214.17039489746094, 6.72001838684082, 381.1054382324219, 27.375019073486328, "Author's personal copy\n", 0, 0)
(40.16949462890625, 362.9957580566406, 291.05279541015625, 373.7064208984375, '4. Coupling E-Gen proﬁling module and the CORTEX system\n', 1, 0)
(40.1697998046875, 386.0716247558594, 148.85108947753906, 396.51190185546875, '4.1. E-Gen proﬁling module\n', 2, 0)
(40.1690559387207, 408.9643249511719, 550.4321899414062, 545.5303344726562, '4.1.1. Linguistic pre-processing\nFirstly, we remove information such as e-mail adresses, the names of candidates, addresses, names of cities in order to\nensure that the applications become anonymous. Then, classic pre-processing is applied to textual information (job offer,\nCV, and CL). French accents are deleted and capital letters are converted to lower case. This pre-processing task is performed\nto obtain a representation well suited for the Vector Space Model (VSM). In order to avoid the introduction of noise into the\nmodels, the following items are also deleted: verbs and functional words (to be, to have, to need, etc.), common expressions\nwith a stop word11 list (for example, that is, each of, etc.), numbers (in numeric and/or textual format), symbols such as ‘‘$’’, ‘‘#’’,\n‘‘⁄’’. Finally, lemmatisation12 is performed to signiﬁcantly reduce the size of the lexicon. All these processes allow us to repre-\nsent the collection of documents through the bag-of-words paradigm (a matrix of frequencies of terms (columns) for each can-\ndidate answer (rows)). To improve ﬁltering, we tried parsing applications with different signiﬁcant terms (like ‘‘Personal\nInformation’’, ‘‘Education’’, ’’Work Experience’’, etc.) and extract only paragraphs with the relevant information, but initial tests\nshowed a decline in results due to the great variability of signiﬁant terms and order of paragraphs.\n', 3, 0)
(40.16949462890625, 557.8007202148438, 550.4671630859375, 705.7803955078125, '4.1.2. Proximity between applications and job offer using similarity measures\nAfter the step of linguistic pre-processing, each document is transformed into a vector with weights characterizing the\nfrequency of terms Tf. Some tests with Tf-idf (Salton & Mcgill, 1986) were made but they offered no improvement. We have\nestablished a strategy using measures of similarity, to rank all applications in relation to a job offer. We combined different\nsimilarity measures between the candidate’s answers (CV and CL) and the associated job offer. We decided to use several\nsimilarity measures as deﬁned in Bernstein, Kaufmann, Kiefer, and Bnrki (2005): Cosine (Eq. (1)), which calculates the angle\nbetween job offer and each candidate answer, Minkowski distances (Eq. (2)) (p = 1 for Manhattan, p = 2 for Euclidean). The\nlast measure used is Okabis (Eq. (3)) (Bellot & El-Bèze, 2001). Based on the formula of Okapi (Robertson, Walker, Jones, Han-\ncock-Beaulieu, & Gatford, 1994), this measure is often used in Information Retrieval. To combine these measures, we use an\nAlgorithm Decision (AD) (Boudin & Torres Moreno, 2007), which weights the values obtained by each measure of similarity.\nSeveral other similarity measures (Overlap, Enertex, Needleman-Wunsch, Jaro-Winkler, Jensen-Shannon divergence) have\nbeen tested but they are not retained in this study, because the results obtained were disapointing. All measures used\nand their combinations are described in Kessler, Béchet, Roche, El-Bèze, and Torres-Moreno (2008a).\n', 4, 0)
(420.948486328125, 255.4051055908203, 467.90960693359375, 274.3564453125, 'candidatures \nranking\n', 5, 0)
(137.09518432617188, 99.72374725341797, 163.62254333496094, 110.02506256103516, 'Internet\n', 6, 0)
(227.22068786621094, 173.7758331298828, 265.75311279296875, 192.72715759277344, 'Job offer\nprocessing\n', 7, 0)
(376.1444396972656, 92.86921691894531, 414.6625061035156, 111.82128143310547, 'Job offer \npublication\n', 8, 0)
(301.65655517578125, 271.7811279296875, 311.68798828125, 282.06610107421875, 'CV\n', 9, 0)
(230.7207794189453, 241.67738342285156, 261.618896484375, 251.9623260498047, 'Splitting \n', 10, 0)
(225.34632873535156, 254.67529296875, 265.148193359375, 264.9765930175781, 'candidate’s\n', 11, 0)
(232.62733459472656, 267.6900634765625, 257.5596618652344, 277.97503662109375, 'e-mails\n', 12, 0)
(382.8375549316406, 218.7366943359375, 412.1788635253906, 229.0380096435547, 'Profiling\n', 13, 0)
(231.6014404296875, 198.017578125, 262.95391845703125, 208.3188934326172, 'Module 1\n', 14, 0)
(230.43211364746094, 277.19976806640625, 261.7347106933594, 287.4847412109375, 'Module 2\n', 15, 0)
(381.8548583984375, 232.511962890625, 413.207275390625, 242.8132781982422, 'Module 3\n', 16, 0)
(320.7237243652344, 177.42811584472656, 352.5087890625, 185.65606689453125, 'Description\n', 17, 0)
(320.7237243652344, 165.92921447753906, 332.60113525390625, 174.15716552734375, 'Title\n', 18, 0)
(321.1472473144531, 188.2088165283203, 342.658935546875, 196.436767578125, 'Mission\n', 19, 0)
(321.1472473144531, 199.22120666503906, 339.1285705566406, 207.44915771484375, 'Profile\n', 20, 0)
(255.49871826171875, 113.94905090332031, 290.41259765625, 124.23400115966797, 'Candidate\n', 21, 0)
(195.4169921875, 79.75233459472656, 233.147705078125, 90.03728485107422, 'companies\n', 22, 0)
(341.8569030761719, 235.18287658691406, 353.49102783203125, 245.4678192138672, 'LIA\n', 23, 0)
(332.61199951171875, 248.1835479736328, 362.70489501953125, 258.468505859375, 'CORTEX\n', 24, 0)
(334.8083801269531, 261.18487548828125, 360.4990539550781, 271.4698486328125, 'System\n', 25, 0)
(304.5306091308594, 237.10414123535156, 314.1575927734375, 247.3890838623047, 'CL\n', 26, 0)
(401.9400939941406, 297.85174560546875, 439.6779479980469, 316.8038330078125, 'Relevance \nFeedback\n', 27, 0)
(254.0859375, 326.3799133300781, 336.4775695800781, 335.02496337890625, 'Fig. 1. System overview.\n', 28, 0)
(40.169063568115234, 738.71044921875, 550.364990234375, 769.4961547851562, '11 http://sites.univ-provence.fr/veronis/donnees/index.html.\n12 Lemmatisation ﬁnds the root of verbs and transforms plural and/or feminine words into masculine singular form. So we conﬂate terms developer,\ndevelopment, developing, to develop into develop.\n', 29, 0)
(167.7873077392578, 51.2989616394043, 550.4119873046875, 59.874244689941406, 'R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135\n1127\n', 30, 0)

page suivante
(214.17039489746094, 6.72001838684082, 381.1054382324219, 27.375019073486328, "Author's personal copy\n", 0, 0)
(71.06582641601562, 77.89144134521484, 125.93026733398438, 95.74857330322266, 'cosineðj; dÞ ¼\n', 1, 0)
(137.57339477539062, 66.66561889648438, 199.45086669921875, 125.54007720947266, 'Pn\ni¼1ji \x02 di\nﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ\nPn\ni¼1j\n2\ni \x02 Pn\ni¼1d\n2\ni\n', 2, 0)
(128.45347595214844, 77.8912582397461, 555.0859375, 113.93827056884766, 'q\nð1Þ\n', 3, 0)
(71.06591796875, 108.60164642333984, 190.91673278808594, 132.72471618652344, 'Minkowskiðj; dÞ ¼\n1\n', 4, 0)
(148.4924774169922, 114.86775970458984, 555.0875854492188, 161.27513122558594, '1 þ Pn\ni¼1jji \x03 dijp\n\x03\n\x041\np\nð2Þ\n', 5, 0)
(71.067626953125, 145.27194213867188, 142.40391540527344, 186.5885467529297, 'Okabisðj; dÞ ¼ P\n', 6, 0)
(130.37664794921875, 162.01751708984375, 144.82228088378906, 173.5585479736328, 'i2d\\j\n', 7, 0)
(146.32113647460938, 139.00521850585938, 196.75311279296875, 191.0549774169922, 'Pn\ni¼1ji \x02 di\nPn\ni¼1ji \x02 di þ\n', 8, 0)
(195.8917694091797, 151.97164916992188, 209.88856506347656, 186.33995056152344, 'ﬃﬃﬃﬃ\njdj\np\n', 9, 0)
(198.62147521972656, 168.03546142578125, 206.5393829345703, 176.44248962402344, 'Md\n', 10, 0)
(542.7615356445312, 150.29299926757812, 555.0875854492188, 168.15013122558594, 'ð3Þ\n', 11, 0)
(44.884525299072266, 181.98609924316406, 555.1162109375, 204.12088012695312, 'where j is a job offer, d is a candidate answer, i a term, ji and di occurrence of i respectively in j and d, and Md their average\nsize.\n', 12, 0)
(44.88291931152344, 216.3900909423828, 555.1861572265625, 421.6354064941406, '4.1.3. Relevance Feedback\nWe previously changed the system to incorporate a process of Relevance Feedback (Sparck Jones, 1970). Relevance Feed-\nback is a standard method used particulary for manual query reformulation. For example, the user carefully checks the an-\nswer set resulting from an initial query, and then reformulates the query. Rocchio’s algorithm (Rocchio, 1971) and variations\nhave found wide usage in Information Retrieval and related areas such as Text Categorisation (Joachims, 1997). Relevance\nFeedback has been proposed in Smyth and Bradley (2003) to help the user to ﬁnd a job with server logs from the jobFinder\nsite.13 In our system, Relevance Feedback takes into account the recruiting consultant’s choice during a ﬁrst evaluation of a few\nCVs. Our goal is not a system capable of ﬁnding the best candidate, but a system capable of reproducing the judgement of the\nrecruitment consultant. It is critical for recruiters not to miss a promising candidate that they may have unfortunately rejected.\nThe goal of this Relevance Feedback approach is to help them to avoid this kind of error. We assume that successful candidates\nhave similar proﬁles or, at least, that they have much in common. This approach uses documents returned in response to a ﬁrst\nrequest to improve the search results (Salton & Buckley, 1990). In this case, we randomly take a few candidate answers (1–6 in\nour experiments) from all relevant candidate answers. These selected candidate answers are added to the job offer. So, we use\nmanual Relevance Feedback to reﬂect user judgements in the resulting ranking. We increase the vector representation with the\nterms from the candidates considered relevant by a recruitment consultant. The system will recompute the similarity between\nthe candidate’s answer that we evaluate and the job offer enriched with relevant candidates. This allows Sim0 to be recalculed\nfor each measure of similarity between the application evaluated and the job offer expanded by relevant applications of the\nrelevance feedback process:\n', 13, 0)
(71.06582641601562, 430.66162109375, 555.0863647460938, 448.88446044921875, 'Sim\n0\nmeasureðj; dÞ ¼ Simmeasureðj; dkp1k \x02 \x02 \x02 kpnÞ\nð4Þ\n', 14, 0)
(44.88375473022461, 452.21038818359375, 555.1430053710938, 543.1723022460938, 'where j is a job offer, d is a candidate’s response, pi is a relevant candidate’s response, n are numbers of retained applications\nfor Relevance Feedback and k is the concatenation operator.\nThe results, presented in Kessler et al. (2009) and hereafter called ISMIS Result showed an improvement in the quality of\nthe ranking obtained for each application added to the process of relevance feedback. However, we suspected that a lot of\nunnecessary information was still kept in the evaluation and we wanted to use a ﬁlter to take into account the content of\nsentences. Each document contains additional information (hobbies, greeting and complimentary close, etc.) and standard\npre-processing only partially removes it. The idea was to use a system of automatic summarization, coupled to E-Gen, as\na powerful ﬁlter capable of removing non-essential information contained in CV and Cover Letters.\n', 15, 0)
(44.88375473022461, 555.441650390625, 192.7448272705078, 565.88330078125, '4.2. The CORTEX summarization system\n', 16, 0)
(44.883731842041016, 578.24072265625, 555.17529296875, 727.2454223632812, 'Automatic summarization is useful to cope with ever increasing volumes of information. An abstract is, by far, the most\nconcrete and recognized kind of text condensation. However, the CV is already a kind of summary, with a very important\nstructure. We suspect that the ﬁltering system of automatic summarization may not be useful in this case. Since the CL is\nin free text, we used CORTEX (Torres-Moreno, St-Onge, Gagnon, El-Bèze, & Bellot, 2009, 2001), an efﬁcient state-of-art summa-\nrization system, in order to retain the more informative segments of the CL.\nEach document of the application is transmitted to the CORTEX system which provides a summary based on the requested\nsize. CORTEX is a document extract summarization system using an optimal decision algorithm that combines several metrics.\nThese metrics result from processing statistical and informational algorithms on the document vector space representation.\nFig. 2 presents an overview of the system.\nThe idea is to represent the text in an appropriate vectorial space and apply numeric processings to it. In order to reduce\ncomplexity, a pre-processing of the document is performed: words are ﬁltered, lemmatized, and stemmed. Based on the\nterms that remain in the text after ﬁltering, a frequency matrix c is built in the following way: Each element cl\ni of this matrix\nrepresents the number of occurrences of the word i in the sentence l.\n', 17, 0)
(47.86252212524414, 757.8189697265625, 183.03822326660156, 769.4962768554688, '13 JobFinder (http://www.jobﬁnder.com).\n', 18, 0)
(44.884525299072266, 51.36103439331055, 427.51580810546875, 59.936317443847656, '1128\nR. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135\n', 19, 0)

page suivante
(214.17039489746094, 6.72001838684082, 381.1054382324219, 27.375019073486328, "Author's personal copy\n", 0, 0)
(67.83963012695312, 435.3992004394531, 82.19192504882812, 453.1032409667969, 'c ¼\n', 1, 0)
(94.08287048339844, 391.7505187988281, 207.38490295410156, 421.1932067871094, 'c1\n1\nc1\n2\n. . .\nc1\ni\n. . .\nc1\nNL\nc2\n1\nc2\n2\n. . .\nc2\ni\n. . .\nc2\nNL\n', 2, 0)
(97.24690246582031, 423.3985595703125, 203.56690979003906, 440.0046081542969, '..\n.\n..\n.\n...\n..\n.\n...\n..\n.\n', 3, 0)
(93.77262878417969, 440.9181213378906, 207.38490295410156, 456.49432373046875, 'cl\n1\ncl\n2\n. . .\ncl\ni\n. . .\ncl\nNL\n', 4, 0)
(97.24690246582031, 458.7000732421875, 203.56690979003906, 475.30609130859375, '..\n.\n..\n.\n...\n..\n.\n...\n..\n.\n', 5, 0)
(92.22163391113281, 476.5020446777344, 207.43055725097656, 491.85760498046875, 'cNS\n1\ncNS\n2\n. . .\ncNS\ni\n. . .\ncNS\nNL\n', 6, 0)
(84.77679443359375, 386.1754455566406, 90.76721954345703, 420.5437316894531, '2\n', 7, 0)
(84.77679443359375, 402.2441101074219, 90.76721954345703, 502.1877136230469, '6666666666664\n', 8, 0)
(210.0369415283203, 386.17352294921875, 216.02737426757812, 420.54180908203125, '3\n', 9, 0)
(210.0369415283203, 402.2421875, 216.02737426757812, 502.1857604980469, '7777777777775\n', 10, 0)
(216.05474853515625, 433.6593322753906, 550.4337158203125, 456.0191955566406, ';\ncl\ni 2 f0; 1; 2; . . .g\nð5Þ\n', 11, 0)
(40.16949462890625, 498.2697448730469, 343.3431396484375, 509.44268798828125, 'Another matrix n, called a binary virtual or presence matrix, is deﬁned as:\n', 12, 0)
(67.83963012695312, 515.92529296875, 152.1025848388672, 544.7374267578125, 'nl\ni ¼\n1\nif cl\ni – 0\n', 13, 0)
(97.99152374267578, 531.3470458984375, 155.24026489257812, 542.6771850585938, '0\nelsewhere\n', 14, 0)
(89.12002563476562, 510.1323547363281, 164.0679168701172, 544.5006713867188, '(\n)\n', 15, 0)
(538.0448608398438, 523.9635620117188, 550.4330444335938, 541.8207397460938, 'ð6Þ\n', 16, 0)
(40.16939926147461, 547.1577758789062, 550.4514770507812, 630.4027099609375, 'Each line of these matrices represents a sentence of the text. Matrices c and cT are the frequency matrix of the sentences\nand frequency matrix of the titles respectively.\nThe CORTEX system can use up to C = 11 metrics (Torres-Moreno, Velazquez-Morales, & Meunier, 2002) to evaluate the sen-\ntence’s relevance.\nThe system scores each sentence with a decision algorithm which relies on the normalized metrics. Two averages are cal-\nculated, a positive ks > 0.5, and a negative ks < 0.5 tendency (the case ks = 0.5 is ignored). The following algorithm combines\nthe vote of each metric:\n', 17, 0)
(67.83963012695312, 634.674072265625, 105.79927062988281, 679.5637817382812, 'P\ns a ¼ P\nC\n', 18, 0)
(95.01348876953125, 637.3163452148438, 215.48568725585938, 682.1075439453125, 'v¼1\nkv\n\x05\x05 s\n\x05\x05 \x03 0:5\n\x03\n\x04\n;\nkv\n\x05\x05 s\n\x05\x05 > 0:5\n', 19, 0)
(67.84087371826172, 664.6715087890625, 105.36530303955078, 706.4894409179688, 'P\ns\nb ¼ P\nC\n', 20, 0)
(94.57925415039062, 664.2420043945312, 215.0513458251953, 709.0952758789062, 'v¼1\n0:5 \x03 kv\n\x05\x05 s\n\x05\x05\n\x03\n\x04\n;\nkv\n\x05\x05 s\n\x05\x05 < 0:5\n', 21, 0)
(40.16949462890625, 694.78564453125, 518.5231323242188, 706.8613891601562, 'Cis the number of metrics and v is the index of the metrics. The value given to each sentence s is calculated with:\n', 22, 0)
(66.3506851196289, 706.926025390625, 128.03778076171875, 754.2608032226562, 'if\nP\ns a > P\ns\nb\n\x06\n\x07\n', 23, 0)
(53.26008605957031, 743.0439453125, 226.64024353027344, 793.5516357421875, 'then Scorecortex\ns\n¼ 0:5 þ Psa=C: retain s\nelse Scorecortex\ns\n¼ 0:5 \x03 Psb=C: not retain s\n', 24, 0)
(256.691650390625, 372.166015625, 333.8712463378906, 380.8110656738281, 'Fig. 2. CORTEX overview.\n', 25, 0)
(167.78814697265625, 51.2976188659668, 550.412841796875, 59.872901916503906, 'R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135\n1129\n', 26, 0)

page suivante
(214.17039489746094, 6.72001838684082, 381.1054382324219, 27.375019073486328, "Author's personal copy\n", 0, 0)
(44.884300231933594, 74.46943664550781, 555.1167602539062, 142.45175170898438, 'The sentences are then ranked according to the obtained values. Depending on the desired compression rate, the sorted\nsentences will be used to produce the summary. The CORTEX system is applied to each document (Cover Letter) and a sum-\nmary is generated by concatenating high-scoring sentences. We generated several abstracts with a variable compression rate\n(5%, 10%, 20%, . . ., 50%, 75% of the size of the documents, in sentences) in order to test the impact of our powerful ﬁlter on the\nE-Gen system. The entire process chain is illustrated in Fig. 1. The best compression rates are generally with 30% (Torres-\nMoreno et al., 2009). The results are presented in Section 5.3.\n', 1, 0)
(44.885337829589844, 156.4619903564453, 110.11864471435547, 167.17263793945312, '5. Experiments\n', 2, 0)
(44.88438034057617, 179.44190979003906, 555.131103515625, 281.7320251464844, 'We selected a data subset from Aktor’s database composed of 1917 candidates. This subset is called the Mission Corpus. It\nhas a size of 10 MB of raw texts and contains 1,375,000 words. The Mission Corpus is composed of a set of 12 job offers cov-\nering various themes (jobs in accountancy, business, computer science, etc.) and their candidates. Each Job Offer is associated\nwith at least six candidates identiﬁed as relevant. As described in Kessler et al. (2008a), each document is segmented to keep\nthe relevant parts (we remove the description of the company (D) for the job offer). Each candidate answer is tagged as rel-\nevant or irrelevant. A relevant value corresponds to a potential candidate for a speciﬁc job chosen by the recruiting consul-\ntant. An irrelevant value is associated with an unsuitable candidate for the job (this is a decision made by the manager of a\nhuman resources company). Our study was conducted on French job offers because the French market represents Aktor’s\nmain activity. Table 1 shows a few statistics about the Mission Corpus.\n', 3, 0)
(44.8843879699707, 294.00128173828125, 163.61143493652344, 304.4415588378906, '5.1. Example of CL summaries\n', 4, 0)
(44.882816314697266, 312.8919982910156, 555.1356811523438, 396.1989440917969, 'Fig. 3 presents14 an example of an original Cover Letter and Fig. 4. Its corresponding summary15generated by the CORTEX sys-\ntem with a 30% compression rate (in number of sentences).\nAll the documents of Mission Corpus were previously made anonymous. We observe that the original CL contains a\nnumber of useless information for ranking, such as addresses, phone numbers or form of address at the beginning or\nend of the letter. The last part of the CL is generally as ‘‘Yours faithfully’’, ‘‘Yours sincerely’’, ‘‘Best regards’’, all of which\nrepresent irrelevant information. We further observe in Fig. 4 that the summary obtained with CORTEX removes all this\ninformation.\n', 5, 0)
(44.88532257080078, 408.46820068359375, 148.947265625, 418.9084777832031, '5.2. Experimental protocol\n', 6, 0)
(44.88532257080078, 431.26580810546875, 555.1482543945312, 487.7705993652344, 'We measured the similarity between a job offer and its candidate’s responses. These measures (Section 4.1.2) rank the\ncandidate’s answers by computing a similarity between a job offer and the associated candidate answers. We use the\nROC curves to evaluate the quality of the ranking obtained. ROC curves (Ferri, Flach, & Hernandez-Orallo, 2002) come from\nthe ﬁeld of signal processing. They are used in medicine to evaluate the validity of diagnostic tests. In our case, ROC curves\nshow the rate of irrelevant candidate answers on the X-axis and the rate of relevant candidate answers on the Y-axis. The\n', 7, 0)
(47.86252212524414, 509.53192138671875, 99.52587127685547, 521.209228515625, '14 Pierre ASPRE\n', 8, 0)
(47.86252212524414, 533.4796142578125, 555.1339111328125, 701.7477416992188, '26 years old\n19 Verdun street 92870 Vannes\n06-06-06-06-06.\nSubject: collaboration offer\nVannes, November 27th, 2008\nDear Sir,\nThe Accountant is a key player not only for the proper functioning of the enterprise, but also in increasing proﬁtability. With his legal knowledge in tax\nand social issues, he can make substantial savings: he is a key player for maintaining a cash reserve by ensuring the payment of customer invoices and\nknowing how to deal with the late settlement of invoices.\nTherefore I offer my skills. They allow me to:\n– Manage with rigueur the accounts of a company.\n– Ensure legal compliance activities (payroll, tax billing etc.).\n– Provide advice particularly important in times of assessment, all thanks to my seriousness, my strength and my analysis.\nI suggest we meet to discuss all the terms of our future cooperation.\nI look forward to hearing from you.\nBest regards.\nPierre ASPRE.\n15 Pierre ASPRE\n', 9, 0)
(57.975101470947266, 714.0181884765625, 555.1339111328125, 769.4952392578125, 'Subject: collaboration offer\nThe Accountant is a key player not only for the proper functioning of the enterprise, but also in increasing proﬁtability. With his legal knowledge in tax\nand social issues, he can make substantial savings: he is a key player for maintaining a cash reserve by ensuring the payment of customer invoices and\nknowing how to deal with late settlement of invoices.\n– ensure legal compliance activities (payroll, tax billing etc.).\n– provide advice particularly important in times of assessment, all thanks to my seriousness, my strength and my analysis.\n', 10, 0)
(44.884849548339844, 51.35602951049805, 427.51611328125, 59.931312561035156, '1130\nR. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135\n', 11, 0)

page suivante
(214.17039489746094, 6.72001838684082, 381.1054382324219, 27.375019073486328, "Author's personal copy\n", 0, 0)
(40.16949462890625, 709.7666015625, 550.4287109375, 766.2713623046875, 'Area Under the Curve (AUC) can be interpreted as the effectiveness of a measurement of interest. In the case of candidate\nanswers ranking, a perfect ROC curve corresponds to obtaining all relevant candidate answers at the beginning of the list\nand all irrelevant ones at the end. This situation corresponds to AUC = 1. The diagonal line corresponds to the performance\nof a random system, progress of the rate of relevant candidates being accompanied by an equivalent degradation in the rate\nof irrelevant candidates. This situation corresponds to AUC = 0.5, as explained in Fawcett (2006). An effective measurement\n', 1, 0)
(235.72189331054688, 525.4686279296875, 354.90277099609375, 534.1137084960938, 'Fig. 3. Example of full Cover Letter.\n', 2, 0)
(86.70008087158203, 72.69537353515625, 168.1925048828125, 90.7083511352539, 'Table 1\nMission corpus statistics.\n', 3, 0)
(96.00615692138672, 97.76753234863281, 442.2815246582031, 106.34281158447266, 'Number\nJob title\nNumber of candidate answers\nNumber of\n', 4, 0)
(406.45672607421875, 111.59478759765625, 494.5508728027344, 120.16309356689453, 'Relevant\nIrrelevant\n', 5, 0)
(96.00614166259766, 125.49946594238281, 476.89520263671875, 246.61410522460938, '34861\nSales engineer\n40\n14\n26\n31702\nAccountant, department suppliers\n55\n23\n32\n33633\nSales engineer\n65\n18\n47\n34865\nAccountant assistant\n67\n10\n57\n34783\nAccountant assistant\n108\n9\n99\n33746\n3 chefs\n116\n60\n56\n33553\nTrade commissioner\n117\n17\n100\n33725\nUrban sales consultant\n118\n43\n75\n31022\nRecruitment assistant\n221\n28\n193\n31274\nAccountant assistant junior\n224\n26\n198\n34119\nSales assistant\n257\n10\n247\n31767\nAccountant assistant junior\n437\n51\n386\nTotal\n1917\n323\n1594\n', 6, 0)
(176.65914916992188, 680.1362915039062, 413.89886474609375, 688.7813720703125, 'Fig. 4. Summary of Cover Letter (see Fig. 3) at a 30% compression rate.\n', 7, 0)
(167.78805541992188, 51.29584884643555, 550.4127197265625, 59.871131896972656, 'R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135\n1131\n', 8, 0)

page suivante
(214.17039489746094, 6.72001838684082, 381.1054382324219, 27.375019073486328, "Author's personal copy\n", 0, 0)
(44.884521484375, 369.7833557128906, 555.1993408203125, 414.87274169921875, 'of interest to order candidate’s answers consists in obtaining the highest AUC value. This is strictly equivalent to minimizing\nthe sum of the ranks of the relevant candidate’s answers. ROC curves are resistant to imbalance (for example, an imbalance\nin the number of positive and negative examples) (Roche & Kodratoff, 2006). For each job offer, we evaluated the quality of\nthe ranking obtained by this method. Candidate answers considered are only those composed of CV and CL.\n', 1, 0)
(44.884521484375, 427.1419982910156, 89.25869750976562, 437.582275390625, '5.3. Results\n', 2, 0)
(44.88450622558594, 449.9387512207031, 555.1417236328125, 529.3375244140625, 'In this section, we present the results obtained by combining the CORTEX system with the E-Gen ranking application. CORTEX\nwas used as an additional ﬁlter which generates a summary of each document before E-Gen evaluation. We keep the struc-\nture of data for job offers as described in Kessler et al. (2008a). A job offer is composed of a Description (D), a Title (T), a\nMission (M), and a Proﬁle (P). For these experiments, we use two combinations of a job offer content, keeping only Title, Mis-\nsion, Proﬁle (TMP) and all information of a job offer (DTMP). Results are presented in Tables 2 and 3. Each column presents a\npart of the application with different sizes of summaries for each line (75%, 50%, . . ., 5%). Full text is a result obtained with\n100% of the document and was published previously in Kessler et al. (2008a, 2009).\n', 3, 0)
(44.8845329284668, 530.0955200195312, 555.1312255859375, 620.9083862304688, 'Table 2 presents results obtained for each part of the application separately. We observe that AUC of CVs remains below\nthe baseline whatever the percentage of compression. We notice however a gradual decrease in AUC scores depending on the\npercentage of compression. We explain this by the fact that a CV is already a summary of the most important information\nabout the candidates and thereby attempting to summarize degrades ﬁnal results. We apply the same process with cover\nletters. Performance is still low overall for CLs in comparison with CVs, however, there is a slight increase in AUC scores with\na compression rate of 30%. We explain these results by particular information contained in a cover letter such as the form of\naddress at the beginning or end of the letter (see Fig. 4) which are noise for the ranking system of E-Gen. Results with TMP\nsegmentation (i.e. conserving only Title, Mission, and Proﬁle of job offer) are of better quality.\n', 4, 0)
(44.88542175292969, 621.6663208007812, 555.1563110351562, 769.741943359375, 'Table 3 presents the results obtained by combining both parts of the application. Full text values are computed with the\nwhole documents of the application. The ﬁrst two columns show the results obtained by combining the summary of the CV\nand the CL. We observe again a deterioration in the results when trying to summarize the CV. Even if results are lower, it\nshould be noted, however, that the best score is again obtained at 30%. The last two columns present the results with a sum-\nmarized CL and the full CV. We observe an overall improvement of the AUC score and the best results with a compression\nrate of 30% of the Cover Letter.\nNext step is to combine summaries of the cover letter, which suppresses noise and enriches the offer with the Relevance\nFeedback process. Table 4 presents the results obtained with different sizes of Relevance Feedback (RF1 corresponds to one\napplication added to the job offer, RF2 two applications added to the job offer, etc.). Each application added with the rele-\nvance feedback process consists in a full CV and a summary of the cover letter with a compression rate of 30%. A random\ndistribution of applications produces an AUC approximately at 0.5 like explained in Fawcett (2006). We compare ISMIS Result\nwith those obtained using a summary of the cover letter. Each test is carried out 100 times with a random distribution of\nrelevant applications for Relevance Feedback. Then we compute an average of AUC scores obtained (the curve shows the\n', 5, 0)
(91.41511535644531, 72.69537353515625, 483.389892578125, 90.7083511352539, 'Table 2\nResults of CL or CV according to the compression rate of Cortex and part of job offer (with or without Description part).\n', 6, 0)
(100.72118377685547, 97.76747131347656, 499.2727355957031, 107.95597076416016, 'CORTEX compression rate (%)\nCV + DTMP\nCV + TMP\nCL + DTMP\nCL + TMP\n', 7, 0)
(100.72102355957031, 113.642578125, 487.6923522949219, 187.92526245117188, '100 (full text)\n0.622\n0.648\n0.567\n0.560\n75\n0.565\n0.575\n0.563\n0.556\n50\n0.558\n0.569\n0.553\n0.560\n40\n0.552\n0.565\n0.561\n0.565\n30\n0.549\n0.560\n0.569\n0.571\n20\n0.520\n0.558\n0.564\n0.566\n10\n0.559\n0.559\n0.543\n0.554\n5\n0.550\n0.542\n0.521\n0.523\n', 8, 0)
(91.41511535644531, 221.5931396484375, 306.31005859375, 239.60610961914062, 'Table 3\nResults for CV and cover letter according to the compression rate.\n', 9, 0)
(100.72118377685547, 246.6652374267578, 465.7217712402344, 256.8536682128906, 'CORTEX compression rate (%)\nCV and CL summaries\nFull CV and CL summary\n', 10, 0)
(234.04624938964844, 260.56219482421875, 478.1799011230469, 269.1374816894531, 'DTMP\nTMP\nDTMP\nTMP\n', 11, 0)
(100.72102355957031, 274.32733154296875, 481.985595703125, 348.6099548339844, '100 (full text)\n0.634\n0.642\n0.634\n0.642\n75\n0.521\n0.581\n0.639\n0.641\n50\n0.556\n0.551\n0.643\n0.649\n40\n0.544\n0.568\n0.643\n0.651\n30\n0.570\n0.587\n0.646\n0.653\n20\n0.569\n0.533\n0.641\n0.652\n10\n0.564\n0.534\n0.631\n0.645\n5\n0.546\n0.547\n0.638\n0.649\n', 12, 0)
(44.88541030883789, 51.3574333190918, 427.5166931152344, 59.932716369628906, '1132\nR. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135\n', 13, 0)

page suivante
(214.17039489746094, 6.72001838684082, 381.1054382324219, 27.375019073486328, "Author's personal copy\n", 0, 0)
(40.16949462890625, 462.03790283203125, 550.4440307617188, 552.8507690429688, 'average for each size). In fact, we compute the Residual Ranking (Billerbeck & Zobel, 2006): Documents that are used for Rel-\nevance Feedback are removed from the collection before ranking with the reformulated query. We assume that the Rele-\nvance Feedback process would behave as a reinforcement learning (Sutton & Barto, 1998) but it is impossible to\nexperiment RFn with n > 6 with this corpus because the number of relevant candidates is too small for some job offers\n(see Table 1). We observe a slight improvement in results for almost any size of Relevance Feedback. We are conscious that\nthe performance gain is low, however, it conﬁrms previous results on the Cover Letter. Fig. 5 shows this improvement. This\nﬁgure conﬁrms that the addition of just one relevant candidate (RF1) enables the AUC value to be enhanced (i.e. an improve-\nment of 0.5–1.2%). This Relevance Feedback (i.e. RF1) is not very time-consuming for the expert.\n', 1, 0)
(40.17036819458008, 553.6087036132812, 550.4833374023438, 678.7944946289062, 'Fig. 6 shows detailed results of one test. For clarity reasons, we present only 3 of the 12 jobs of our dataset in order to\ncompare results with and without CORTEX (for each job, RFC are AUC scores with CORTEX and RF without CORTEX).\nFor standard system, we observe a positive progress from 1% to 10% for 10 jobs between RF0 and RF1 (e.g. ﬁve jobs have\nan improvement between 5% and 10%). Note that between RF0 and RF6, 6 jobs have a signiﬁcant positive progress between\n10% and 12%. The combination of the E-Gen and CORTEX systems improve standard system results for ﬁve jobs from 1% to 5%\nbetween RF0 and RF1. Between RF0 and RF6, the Cortex version improves E-Gen’s results for eight jobs from 1% to 5%.\nThe study of the results shows that job offer 31702 contains some relevant applications with a bad labeling (CV are la-\nbeled CL and CL are only a hyperlink to a CV). The reduction of information on the main document of the application leads\nthe system version using summaries to degrade the AUC scores. Job offer 34861 shows a good improvement with each size of\nrelevance feedback (RF0:0.65, RF1:0.70, RF6:0.73) and with CORTEX (RF0:0.68, RF1:0.72, RF6:0.79). The detailed study of re-\nsults shows that job offer 33746 contains some empty applications labeled relevant. This leads the system with and without\n', 2, 0)
(40.16949462890625, 679.5526733398438, 550.4404907226562, 701.6874389648438, 'CORTEX to degrade ﬁnal results. In the same way, an application added without CL explains the identical score in RF2 between\nRF and RFC for job offer 31274.\n', 3, 0)
(40.169795989990234, 715.6976318359375, 173.78494262695312, 726.4083251953125, '6. Conclusion and future work\n', 4, 0)
(40.169795989990234, 738.678466796875, 550.4281005859375, 760.813232421875, 'Job offer processing is a difﬁcult and highly subjective task. The retrieval of relevant information concerning job descrip-\ntions and skills is not a trivial task (Loth et al., 2010) and results on this type of document have been quite low (Clech &\n', 5, 0)
(102.21023559570312, 72.69537353515625, 419.26568603515625, 90.70853424072266, 'Table 4\nComparison of AUC score for each size of Relevance Feedback with CORTEX summarization system.\n', 6, 0)
(111.51631164550781, 97.76753234863281, 479.06658935546875, 106.34281158447266, 'Size of Relevance Feedback\nISMIS result\nFull CV and CL summary 30% compression rate\n', 7, 0)
(111.51631927490234, 111.60243225097656, 340.5927734375, 185.81668090820312, 'Random distribution\n0.500\n0.500\nRF0\n0.642\n0.653\nRF1\n0.654\n0.658\nRF2\n0.657\n0.659\nRF3\n0.659\n0.661\nRF4\n0.659\n0.659\nRF5\n0.660\n0.662\nRF6\n0.661\n0.663\n', 8, 0)
(172.5643768310547, 423.1014709472656, 418.0079040527344, 431.74652099609375, 'Fig. 5. Results of Relevance Feedback with and without summaries of CL.\n', 9, 0)
(167.78773498535156, 51.29694747924805, 550.4124755859375, 59.872230529785156, 'R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135\n1133\n', 10, 0)

page suivante
(214.17039489746094, 6.72001838684082, 381.1054382324219, 27.375019073486328, "Author's personal copy\n", 0, 0)
(44.884525299072266, 293.90753173828125, 555.1539916992188, 441.98382568359375, 'Zighed, 2003). The information we use in this kind of process is not well formated in natural language, but follows a conven-\ntional structure. This paper deals with the CORTEX summarizer and the E-Gen system for processing job offers. E-Gen assists an\nemployer in the recruitment task. This paper focuses on candidate answers to job offers. We rank the candidate answers by\nusing different similarity measures and different document representations in a vector space model. We use a process of rel-\nevance feedback to perform reinforcement learning, whereby each new application added to the process assists in the deci-\nsion-making. We choose to evaluate the quality of our approaches by computing Area Under the Curve.\nCORTEX is a\nsummarization system using an optimal decision algorithm that combines several metrics. We present the results obtained\nby combining both systems. AUC obtained with summarized cover letter at 30% of compression size and a full CV shows a\nslight improvement in the results. As future work, we plan to apply other techniques, such as ﬁnding discriminant features of\nirrelevant applications using the Rocchio algorithm (Rocchio, 1971), weighting the different parts of an application, etc. in\norder to improve results. We also plan to use a categorization of jobs to take into consideration similar jobs, such as ’’devel-\noper’’ and ‘‘programmer’’. Finally we propose to measure the CV quality by building an evaluation on an Internet portal. Our\naim with this evaluation is to present a job-seeker with a list of the most suitable job ads according to his proﬁle.\n', 1, 0)
(44.885738372802734, 454.69091796875, 130.28756713867188, 465.4015808105469, 'Acknowledgements\n', 2, 0)
(44.88568878173828, 477.67083740234375, 555.0797119140625, 499.8675231933594, 'Authors thank Richard James, Véronique Moriceau, André Bittar, ANRT (Agence Nationale de la Recherche Technologique)\nand Aktor Interactive that partially supported this work.\n', 3, 0)
(44.88568878173828, 512.5746459960938, 92.05546569824219, 523.2853393554688, 'References\n', 4, 0)
(44.884521484375, 534.0999755859375, 555.1390991210938, 769.4925537109375, 'Audras, I., & Ganascia, J.-G. (2006). Apprentissage du frantais langue TtrangFre et TALN: Analyses de corpus Tcrits a l’aide d’outils d’extraction automatique\ndu langage. In J.-M. Viprey (Ed.), 8Fmes JournTes d’Analyse de DonnTes Textuelles (pp. 67–78). Univ. de Franche ComtT, Besanton 2006.\nBellot, P., & El-Bèze, M. (2001). Classiﬁcation et segmentation de textes par arbres de dTcision. In TSI (Vol. 20, pp. 107–134). HermFs.\nBen Abdessalem Karaa, W. (2009). Web-based recruiting: A framework for cvs handling. In Second international conference on web and information\ntechnologies ‘‘ICWIT’09’’, kerkennah Island, Sfax, Tunisia, June 12–14 (pp. 395–406).\nBernstein, A., Kaufmann, E., Kiefer, C., & Bnrki, C. (2005). Simpack: A generic java library for similarity measures in ontologies. Tech. rep., University of Zurich\nDepartment of Informatics.\nBillerbeck, B., & Zobel, J. (2006). Efﬁcient query expansion with auxiliary data structures. Information Systems, 31(7), 573–584.\nBoudin, F., & Torres Moreno, J. M. (2007). Neo-cortex: A performant user-oriented multi-document summarization system. In CICLing (pp. 551–562).\nBourse, M., LeclFre, M., Morin, E., & Trichet, F. (2004). Human resource management and semantic web technologies. In ICTTA 2004 Damascus Syria (pp. 641–\n642).\nCazalens, S., & Lamarre, P. (2001). An organization of internet agents based on a hierarchy of information domains. In Proceedings MAAMAW’2001, Annecy,\nFrance (pp. 573–584).\nClech, J., & Zighed, D. A. (2003). Data mining et analyse des cv: une expérience et des perspectives. In EGC’03 Revue des Sciences et Technologies de\nl’Information (Vol. 17, pp. 83–92). Lyon.\nColucci, S., Di Noia, T., Di Sciascio, E., Donini, F. M., Mongiello, M., & Mottola, M. (2003). A formal approach to ontology-based semantic match of skills\ndescriptions. Journal of Universal Computer Science, Special issue on Skills Management, 9, 1437–1454.\nDorn, J., & Naz, T. (2007). Meta-search in human resource management. In Proceedings of 4th international conference on knowledge systems ICKS’07\nBangkok,Thailand (pp. 105–110).\nEnrica, A., & Iezzi, D. F. (2006). Recruitment via web and information technology: A model for ranking the competences in job market. In JADT’2006,\nBesanton, France (pp. 79–88).\nFan, R.-E., Chen, P.-H., & Lin, C.-J. (2005). Working set selection using the second order information for training SVM. Journal of Machine Learning Research,\n1889–1918.\nFawcett, T. (2006). An introduction to ROC analysis. Pattern Recognition Letters, 27, 861–874.\nFerri, C., Flach, P., & Hernandez-Orallo, J. (2002). Learning decision trees using the area under the ROC curve. In Proceedings of ICML 2002: Sydney, NSW,\nAustralia (pp. 139–146).\nGorenak, I., & Mlaker KaF, S. S. O. (2010). Cross-cultural comparison of online job advertisements. JLST, Journal of Logistics and Sustainable Transport, 2, 37–52.\n', 5, 0)
(193.96717834472656, 225.6049041748047, 405.9313659667969, 242.07229614257812, 'RF0\nRF1\nRF2\nRF3\nRF4\nRF5\nRF6\n0,40\n', 6, 0)
(193.96717834472656, 208.65940856933594, 206.74456787109375, 217.60226440429688, '0,45\n', 7, 0)
(193.96717834472656, 191.7572479248047, 206.74456787109375, 200.70010375976562, '0,50\n', 8, 0)
(193.96717834472656, 174.8124237060547, 206.74456787109375, 183.75527954101562, '0,55\n', 9, 0)
(193.96717834472656, 157.9103240966797, 206.74456787109375, 166.85317993164062, '0,60\n', 10, 0)
(193.96717834472656, 141.00816345214844, 206.74456787109375, 149.95101928710938, '0,65\n', 11, 0)
(193.96717834472656, 124.06266021728516, 206.74456787109375, 133.00552368164062, '0,70\n', 12, 0)
(193.96717834472656, 107.11722564697266, 206.74456787109375, 116.06008911132812, '0,75\n', 13, 0)
(193.96717834472656, 90.21573638916016, 206.74456787109375, 99.15859985351562, '0,80\n', 14, 0)
(193.96717834472656, 73.27091217041016, 206.74456787109375, 82.21377563476562, '0,85\n', 15, 0)
(179.992919921875, 136.20535278320312, 190.42625427246094, 173.2353515625, 'AUC score\n', 16, 0)
(270.3887023925781, 244.26744079589844, 353.83245849609375, 254.70077514648438, 'Relevance Feeback size\n', 17, 0)
(370.73162841796875, 141.05990600585938, 402.52410888671875, 185.20709228515625, ' 34861 RF\n 34861 RFC\n 31274 RF\n 31274 RFC\n 31702 RF\n 31702 RFC\n', 18, 0)
(44.884525299072266, 264.277099609375, 555.0830078125, 272.9221496582031, 'Fig. 6. Comparison of detailed results for 3 jobs with and without summaries of CL. For each job, RFC means AUC scores with CORTEX and RF without CORTEX.\n', 19, 0)
(44.88712692260742, 51.36030197143555, 427.5184326171875, 59.935585021972656, '1134\nR. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135\n', 20, 0)

page suivante
(214.17039489746094, 6.72001838684082, 381.1054382324219, 27.375019073486328, "Author's personal copy\n", 0, 0)
(40.16949462890625, 72.76515197753906, 550.42431640625, 430.18975830078125, 'Joachims, T. (1997). A probabilistic analysis of the rocchio algorithm with tﬁdf for text categorization. In ICML 1997, Nashville, Tennessee, USA (pp. 143–151).\nSan Francisco, CA, USA.\nKessler, R., Béchet, N., Roche, M., El-Bèze, M., & Torres-Moreno, J. M. (2008a). Automatic proﬁling system for ranking candidates answers in human\nresources. In OTM ’08 in Monterrey, Mexico (pp. 625–634).\nKessler, R., Béchet, N., Roche, M., El-Bèze, M., & Torres-Moreno, J. M. (2009). Job offer management: How improve the ranking of candidates. Prague: ISMIS.\n431–441.\nKessler, R., Torres-Moreno, J. M., & El-Bèze, M. (2007). E-Gen: Automatic job offer processing system for human ressources. In MICAI, Aguscalientes, Mexique\n(pp. 985–995).\nKessler, R., Torres-Moreno, J. M., & El-Bèze, M. (2008b). E-Gen: Proﬁlage automatique de candidatures. In TALN 2008, Avignon, France (pp. 370–379).\nLoth, R., Battistelli, D., Chaumartin, F., De Mazancourt, H., Minel, J. L., & Vinckx, A. (2010). Linguistic information extraction for job ads (SIRE project). In\nRIAO’2010 9th conference 28–30 April, Paris, France (pp. 300–303).\nMarchal, E., Mellet, K., & Rieucau, G. (2007). Job board toolkits: Internet matchmaking and changes in job advertisements. Human Relations, 60(7),\n1091–1113.\nMocho, M., Paslaru, E., & Simperl, B. (2006). Practical guidelines for building semantic e-recruitment applications. In I-Know’06 special track on advanced\nsemantic technologies, Graz, Austria, September 2006.\nMorin, E., LeclFre, M., & Trichet, F. (2004). The semantic web in e-recruitment. In The ﬁrst European symposium of semantic Web (ESWS’2004) (pp. 67–78).\nQuilan, J. (1993). C4.5: Programs for machine learning. San Mateo, CA, San Francisco, CA, USA: Morgan Kaufmann.\nRafter, R., Bradley, K., & Smyt, B. (2000). Automated collaborative ﬁltering applications for online recruitment services. In International conference on adaptive\nhypermedia and adaptive web-based systems, Trento, Italy (pp. 363–368).\nRobertson, S., Walker, S., Jones, S., Hancock-Beaulieu, M. M., & Gatford, M. (1994). Okapi at trec-3. NIST Special Publication 500-225: TREC-3, pp. 109–126.\nRocchio, J. (1971). Relevance feedback in information retrieval. In The smart system: Experiments in automatic document processing (pp. 313–323). Prentice-\nHall.\nRoche, M., & Kodratoff, Y., 2006. Pruning terminology extracted from a specialized corpus for CV ontology acquisition. In OTM’06, Montpellier, France (pp.\n1107–1116).\nRoche, M., & Prince, V. (2008). Evaluation et dTtermination de la pertinence pour des syntagmes candidats a la collocation. In JADT (pp. 1009–1020).\nSalton, G., & Buckley, C. (1990). Improving retrieval performance by relevance feedback. Journal of the American Society for Information Science, 288–297.\nSalton, G., & Mcgill, M. J. (1986). Introduction to modern information retrieval. New York, NY, USA: McGraw-Hill Inc.\nSmyth, B., & Bradley, K. (2003). Personalized information ordering: A case-study in online recruitment. Journal of Knowledge-Based Systems, 269–275.\nSparck Jones, K. (1970). Some thoughts on classiﬁcation for retrieval. Journal of Documentation, 89–101.\nSutton, R. S., & Barto, A. G. (1998). Reinforcement learning: An introduction (adaptive computation and machine learning). The MIT Press.\nTolksdorf,\nR.,\nMocho,\nM.,\nHeese,\nR.,\nOldakowski,\nR.,\n&\nChristian,\nB.\n(2006).\nSemantic-Web-Technologien\nim\nArbeitsvermittlungsprozess.\nWirtschaftsinformatik, 17–26.\nTorres-Moreno, J. M., Velázquez-Morales, P., & Meunier, M. (2001). CORTEX, un algorithme pour la condensation automatique de textes. In ARCo (Vol. 2, pp.\n365–371).\nTorres-Moreno, J. M., St-Onge, P.-L., Gagnon, M., El-Bèze, M., & Bellot, P. (2009). Automatic summarization system coupled with a question-answering\nsystem (qaas). In CoRR abs/0905.2990.\nTorres-Moreno, J. M., Velazquez-Morales, P., & Meunier, J. (2002). Condensés de textes par des méthodes numériques. JADT, St Malo, France, 2, 723–734.\nViterbi, A. J. (1967). Error bounds for convolutional codes and an asymptotically optimal decoding algorithm. IEEE Transactions on Information Theory, 13,\n260–269.\nYahiaoui, L., Boufaı¨da, Z., & Prié, Y. (2006). Semantic annotation of documents applied to e-recruitment. In SWAP 2006 – Semantic web applications and\nperspectives. ISSN: 1613-0073.\n', 1, 0)
(167.79177856445312, 51.29133224487305, 550.4164428710938, 59.866615295410156, 'R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135\n1135\n', 2, 0)

page suivante
