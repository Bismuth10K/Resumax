(141.1528778076172, 754.6322021484375, 454.1219787597656, 779.9996948242188, 'Proceedings of the Fifth Law Workshop (LAW V), pages 1–10,\nPortland, Oregon, 23-24 June 2011. c⃝2011 Association for Computational Linguistics\n', 0, 0)
(147.94064331054688, 81.38833618164062, 468.3780822753906, 97.55635833740234, 'On the Development of the RST Spanish Treebank \n', 1, 0)
(85.06016540527344, 111.71781158447266, 530.5537719726562, 199.2025146484375, 'Iria da Cunha \nJuan-Manuel Torres-Moreno \nGerardo Sierra \nInstitute for Applied \nLinguistics (UPF), Spain \nLaboratoire Informatique \nd’Avignon (UAPV), France \nInstituto de Ingeniería (UNAM), \nMexico \nInstituto de Ingeniería \n(UNAM), Mexico \nInstituto de Ingeniería (UNAM), \nMexico \ngsierram@iingen.unam.\nmx \nLaboratoire Informatique \nd’Avignon (UAPV), France \nÉcole Polytechnique de Montréal, \nCanada \n \n', 2, 0)
(80.74017333984375, 203.1137237548828, 464.46368408203125, 225.97586059570312, 'iria.dacunha@upf.edu juan-manuel.torres@univ-\navignon.fr \n \n', 3, 0)
(78.58016967773438, 229.66310119628906, 81.26493835449219, 252.6151885986328, ' \n \n', 4, 0)
(167.26063537597656, 259.31024169921875, 213.4965362548828, 272.24468994140625, 'Abstract \n', 5, 0)
(95.14016723632812, 284.0230712890625, 285.41973876953125, 406.8023681640625, 'In this article we present the RST Spanish \nTreebank, the first corpus annotated with \nrhetorical relations for this language. We \ndescribe the characteristics of the corpus, \nthe annotation criteria, the annotation \nprocedure, the inter-annotator agreement, \nand other related aspects. Moreover, we \nshow the interface that we have developed \nto carry out searches over the corpus’ \nannotated texts. \n', 6, 0)
(78.58016967773438, 428.8701477050781, 166.09454345703125, 441.8045959472656, '1 \nIntroduction \n', 7, 0)
(78.58016967773438, 449.86297607421875, 302.10467529296875, 683.1622924804688, 'The Rhetorical Structure Theory (RST) (Mann and \nThompson, 1988) is a language independent theory \nbased on the idea that a text can be segmented into \nElementary Discourse Units (EDUs) linked by \nmeans \nof \nnucleus-satellite \nor \nmultinuclear \nrhetorical relations. In the first case, the satellite \ngives additional information about the other one, \nthe nucleus, on which it depends (ex. Result, \nCondition, Elaboration or Concession). In the \nsecond case, several elements, all nuclei, are \nconnected at the same level, that is, there are no \nelements dependent on others and they all have the \nsame importance with regard to the intentions of \nthe author of the text (ex. Contrast, List, Joint or \nSequence). The rhetorical analysis of a text by \nmeans of RST includes 3 phases: segmentation, \ndetection of relations and building of hierarchical \nrhetorical trees. For more information about RST \nwe recommend the original article of Mann and \n', 8, 0)
(313.30047607421875, 251.80154418945312, 536.8283081054688, 683.2821655273438, 'Thompson (1988), the web site of RST1 and the \nRST review by Taboada and Mann (2006a). \nRST has been used to develop several \napplications, \nlike \nautomatic \nsummarization, \ninformation extraction (IE), text generation, \nquestion-answering, automatic translation, etc. \n(Taboada and Mann, 2006b). Nevertheless, most of \nthese works have been developed for English, \nGerman or Portuguese. This is due to the fact that \nat present corpora annotated with RST relations are \navailable only for these languages (for English: \nCarlson et al., 2002, Taboada and Renkema, 2008; \nfor German: Stede, 2004; for Portuguese: Pardo et \nal., 2008) and there are automatic RST parsers for \ntwo of them (for English: Marcu, 2000; for \nPortuguese: Pardo et al., 2008) or automatic RST \nsegmenters (for English: Tofiloski et al., 2009). \nScientific community working on RST applied to \nSpanish is very small. For example, Bouayad-Agha \net al. (2006) apply RST to text generation in \nseveral languages, Spanish among them. Da Cunha \net al. (2007) develop a summarization system for \nmedical texts in Spanish based on RST. Da Cunha \nand Iruskieta (2010) perform a contrastive analysis \nof Spanish and Basque texts. Romera (2004) \nanalyzes coherence relations by means of RST in \nspoken Spanish. Taboada (2004) applies RST to \nanalyze the resources used by speakers to elaborate \nconversations in English and Spanish.  \nWe consider that it is necessary to build a \nSpanish corpus annotated by means of RST. This \ncorpus should be useful for the development of a \nrhetorical parser for this language and several other \napplications related to computational linguistics, \nlike \nthose \ndeveloped \nfor \nother \nlanguages \n', 9, 0)
(313.3005676269531, 690.3194580078125, 455.8826599121094, 711.4129028320312, '                                                           \n1 http://www.sfu.ca/rst/index.html \n', 10, 0)
(293.2098388671875, 724.5390014648438, 298.6643981933594, 737.6844482421875, '1\n', 11, 0)

page suivante
(78.58016967773438, 80.86316680908203, 302.11053466796875, 215.762451171875, '(automatic translation, automatic summarization, \nIE, etc.). And that is what we pretend to achieve \nwith our work. We present the development of the \nRST Spanish Treebank, the first Spanish corpus \nannotated by means of RST. \nIn Section 2, we present the state of the art \nabout RST annotated corpora. In Section 3, we \nexplain the characteristics of the RST Spanish \nTreebank. In Section 4, we show the search \ninterface we have developed. In Section 5, we \nestablish some conclusions and future work. \n', 0, 0)
(78.58016967773438, 226.19024658203125, 179.29750061035156, 239.1247100830078, '2 \nState of the Art \n', 1, 0)
(78.58016967773438, 247.1830596923828, 302.103759765625, 677.2822875976562, "The most known RST corpus is the RST Discourse \nTreebank, for English (Carlson et al., 2002a, \n2002b). It includes 385 texts of the journalistic \ndomain, extracted from the Penn Treebank \n(Marcus et al., 1993), such as cultural reviews, \neditorials, economy articles, etc. 347 texts are used \nas a learning corpus and 38 texts are used as a test \ncorpus. It contains 176,389 words and 21,789 \nEDUs. 13.8% of the texts (that is, 53) were \nannotated by two people with a list of 78 relations. \nFor annotation, the annotation tool RSTtool 2 \n(O'Donnell, \n2000) \nwas \nused, \nwith \nsome \nadaptations. The principal advantages of this \ncorpus stand on the high number of annotated texts \n(for the moment it is the biggest RST corpus) and \nthe clarity of the annotation method (specified in \nthe annotation manual by Carlson and Marcu, \n2001). However, some drawbacks remain. The \ncorpus is not free, it is not on-line and it only \nincludes texts of one domain (journalistic).  \nFor English there is also the Discourse \nRelations \nReference \nCorpus \n(Taboada \nand \nRenkema, 2008). This corpus includes 65 texts \n(each one tagged by one annotator) of several types \nand from several sources: 21 articles from the Wall \nStreet Journal extracted from the RST Discourse \nTreebank, 30 movies and books’ reviews extracted \nfrom the epinions.com website, and 14 diverse \ntexts, including letters, webs, magazine articles, \nnewspaper editorials, etc. The tool used for \nannotation was also the RSTtool. The advantages \nof this corpus are that it is free and on-line, and it \nincludes texts of several types and domains. The \ndisadvantages are that the amount of texts is not \nvery high, the annotation methodology is not \n", 2, 0)
(78.58016967773438, 690.3194580078125, 221.16275024414062, 711.4129028320312, '                                                           \n2 http://www.wagsoft.com/RSTTool/ \n', 3, 0)
(313.3005676269531, 80.86316680908203, 536.8215942382812, 683.2824096679688, 'specified and it does not include texts annotated by \nseveral people. \nAnother well-known corpus is the Potsdam \nCommentary Corpus, for German (Stede, 2004; \nReitter and Stede, 2003). This corpus includes 173 \ntexts on politics from the on-line newspaper \nMärkische Allgemeine Zeitung. It contains 32,962 \nwords and 2,195 sentences. It is annotated with \nseveral data: morphology, syntax, rhetorical \nstructure, connectors, correference and informative \nstructure. Nevertheless, only a part of this corpus \n(10 texts), which the authors name "core corpus", \nis annotated with all this information. The texts \nwere annotated with the RSTtool. This corpus has \nseveral advantages: it is annotated at different \nlevels (the annotation of connectors is especially \ninteresting); all the texts were annotated by two \npeople (with a previous RST training phase); it is \nfree for research purposes, and there is a tool for \nsearching over the corpus (although it is not \navailable on-line). The disadvantages are: the \ngenre and domain of all the texts are the same, the \nmethodology of annotation was quite intuitive \n(without a manual or specific criteria) and the \ninter-annotator agreement is not given. \nFor Portuguese, there are 2 corpora, built in \norder to develop a rhetorical parser (Pardo et al., \n2008). The first one, the CorpusTCC (Pardo et al., \n2008), was used as learning corpus for detection of \nlinguistic patterns indicating rhetorical relations. It \ncontains 100 introduction sections of computer \nscience theses (53,000 words and 1,350 sentences). \nTo annotate the corpus a list of 32 rhetorical \nrelations was used. The annotation manual by \nCarlson and Marcu (2001) was adapted to \nPortuguese. The annotation tool was the ISI RST \nAnnotation Tool3, an extension of the RSTtool. \nThe advantages of this corpus are: it is free, it \ncontains an acceptable number of texts and words \nand it follows a specific annotation methodology. \nThe disadvantage is: it only includes texts of one \ngenre and domain, only annotated by one person. \nThe second one, Rhetalho (Pardo and Seno, \n2005), was used as reference corpus for the parser \nevaluation. It contains 50 texts: 20 introduction \nsections and 10 conclusion sections from computer \nscience scientific articles, and 20 texts from the on-\nline newspaper Folha de São Paulo (7 from the \nDaily section, 7 from the World section and 6 from \n', 4, 0)
(313.3005676269531, 690.3194580078125, 455.8826599121094, 711.614990234375, '                                                           \n3 http://www.isi.edu/~marcu/discourse/ \n', 5, 0)
(293.2098388671875, 724.5390014648438, 298.6643981933594, 737.6844482421875, '2\n', 6, 0)

page suivante
(78.58015441894531, 80.86316680908203, 302.0997314453125, 351.12225341796875, 'the Science section). It includes approximately \n5,000 words. The relations and the annotation tool \nare the same as those used in the CorpusTCC. The \nadvantages of this corpus are that it is free, it was \nannotated by 2 people (they both were RST experts \nand followed an annotation manual) and it contains \ntexts of several genres and domains. The main \ndisadvantage is the scarce amount of texts. \nThe Penn Discourse Treebank (Rashmi et al., \n2008)f for English includes texts annotated with \ninformation related to discourse structure and \nsemantics (without a specific theoretical approach). \nIts advantages are: its big size (it contains 40,600 \nannotated discourse relations) allows to apply \nmachine learning, and the discourse annotations \nare aligned with the syntactic constituency \nannotations of the Penn Treebank. Its limitations \nare: dependencies across relations are not marked, \nit only includes texts of the journalistic domain, \nand it is not free. Although there are several \ncorpora annotated with discourse relations, there is \nnot a corpus of this type for Spanish. \n', 0, 0)
(78.58016967773438, 361.5502014160156, 244.56741333007812, 374.4846496582031, '3 \nThe RST Spanish Treebank  \n', 1, 0)
(78.58016967773438, 382.4230041503906, 302.0988464355469, 455.88238525390625, 'As Sierra (2008) states, a corpus consists of a \ncompilation of a set of written and/or spoken texts \nsharing some characteristics, created for certain \ninvestigation purposes. According to Hovy (2010), \nwe use 7 core questions in corpus design, detailed \nin the next subsections. \n', 2, 0)
(78.58016967773438, 464.3901672363281, 194.54522705078125, 477.3246154785156, '3.1 \nSelecting a Corpus \n', 3, 0)
(78.57996368408203, 483.10296630859375, 302.0985412597656, 704.0422973632812, 'For the RST Spanish Treebank, we wanted to \ninclude short texts (finally, the average is 197 \nwords by text; the longest containing 1,051 words \nand the shortest, 25) in order to get a best on-line \nvisualization of the RST trees. Moreover, in the \nfirst stage of the project, we preferred to select \nspecialized texts of very different areas, although \nin the future we plan to include also non-\nspecialized texts (ex. blogs, news, websites) in \norder to guarantee the representativity of the \ncorpus. We did not find a pre-existing Spanish \ncorpus with these characteristics, so we decided to \nbuild our own corpus. Following Cabré (1999), we \nconsider that a text is specialized if it is written by \na professional in a given domain. According to this \nwork, specialized texts can be divided in three \nlevels: high (both the author and the potential \nreader of the text are specialists), average (the \n', 4, 0)
(313.2997741699219, 80.86310577392578, 536.8247680664062, 547.9219360351562, 'author of the text is a specialist, and the potential \nreader of that text is a student or someone \ninterested in or possessing some prior knowledge \nabout the subject) and low (the author of the text is \na specialist, and the potential reader is the general \npublic). The RST Spanish Treebank includes \nspecialized texts of the three mentioned levels: \nhigh (scientific articles, conference proceedings, \ndoctoral theses, etc.), average (textbooks) and low \n(articles and reports from popular magazines, \nassociations’ websites, etc.). The texts have been \ndivided in 9 domains (some of them including \nsubdivisions): \nAstrophysics, \nEarthquake \nEngineering, Economy, Law, Linguistics (Applied \nLinguistics, \nLanguage \nAcquisition, \nPLN, \nTerminology), Mathematics (Primary Education, \nSecondary \nEducation, \nScientific \nArticles), \nMedicine (Administration of Health Services, \nOncology, Orthopedy), Psychology and Sexuality \n(Clinical Perspective, Psychological Perspective). \nThe size of a corpus is also a polemic question. \nIf the corpus is developed for machine learning, its \nsize will be enough when the application we want \nto develop obtains acceptable percentages of \nprecision and recall (in the context of that \napplication). Nevertheless, if the corpus is built \nwith descriptive purposes, it is difficult to \ndetermine the corpus size. In the case of a corpus \nannotated with rhetorical relations, it is even more \ndifficult, because there are various factors \ninvolved: EDUs, SPANs (that is, a group of related \nEDUs), nuclearity and relations. In addition, \nrelations are multiple (we use 28). As Hovy (2010: \n13) mentions, one of the most difficult phenomena \nto annotate is the discourse structure. Our corpus \ncontains 52,746 words and 267 texts. Table 1 \nincludes RST Spanish Treebank statistics in terms \nof texts, words, sentences and EDUs. \n', 5, 0)
(313.3005676269531, 548.4037475585938, 525.1304321289062, 564.57080078125, ' \n \nTexts \nWords \nSentences \nEDUs \n', 6, 0)
(319.42059326171875, 569.94482421875, 524.1757202148438, 578.850830078125, 'Learning corpus \n183 \n41,555 \n1,759 \n2,655 \n', 7, 0)
(319.42059326171875, 584.224853515625, 521.1757202148438, 593.0108032226562, 'Test corpus  \n84 \n11,191 \n497 \n694 \n', 8, 0)
(319.42059326171875, 598.5048217773438, 524.1757202148438, 607.4108276367188, 'Total corpus  \n267 \n52,746 \n2,256 \n3,349 \n', 9, 0)
(343.300537109375, 610.0691528320312, 506.6630859375, 623.175048828125, ' \nTable 1: RST Spanish Treebank statistics \n', 10, 0)
(313.3005676269531, 623.6361694335938, 536.8141479492188, 700.3223876953125, ' \nTo increase the linear performance of a \nstatistical method, it is necessary that the training \ncorpus size grows exponentially (Zhao et al., \n2010). However, the RST Spanish Treebank is not \ndesigned only to use statistical methods; we think \nit will be useful to employ symbolic or hybrid \n', 11, 0)
(293.2098388671875, 724.5390014648438, 298.6643981933594, 737.6844482421875, '3\n', 12, 0)

page suivante
(78.5799331665039, 80.86316680908203, 304.73828125, 707.761962890625, 'algorithms (combining symbolic and statistical \nmethods). Moreover, this corpus will be dynamic, \nso we expect to have a bigger corpus in the future, \nuseful to apply machine learning methods. \nIf we measure the corpus size in terms of words \nor texts, we can take as a reference the other RST \ncorpora. Nevertheless, as Sierra states (2008), it is \n“absurd” to try to build an exhaustive corpus \ncovering all the aspects of a language. On the \ncontrary, \nthe \nlinguist \nlooks \nfor \nthe \nrepresentativeness of the texts, that is, tries to \ncreate a sample of the studied language, selecting \nexamples which represent the linguistic reality, in \norder to analyze them in a pertinent way. In this \nsense and in the frame of this work, we consider \nthat the size will be adequate if the rhetorical trees \nof the corpus include a representative number of \nexamples of rhetorical relations, at least 20 \nexamples of each one (taking into account that the \ncorpus contains 3115 relations, we consider that \nthis quantity is acceptable; however, we expect to \nhave even more examples when the corpus grows).  \nTable 2 shows the number of examples of each \nrelation currently included into the RST Spanish \nTreebank (N-S: nucleus-satellite relation; N-N: \nmultinuclear relation). As it can be observed, it \ncontains more than 20 examples of most  of the  \nrelations. The exceptions are the nucleus-satellite \nrelations of Enablement, Evaluation, Summary,  \nOtherwise and  Unless, and the multinuclear \nrelations of Conjunction and Disjunction, because \nit is not so usual to find these rhetorical relations in \nthe language, in comparison with others. Hovy \n(2010: 128) states that, given the lack of examples \nin the corpus, there are 2 possible strategies: a) to \nleave the corpus as it is, with few or no examples \nof some cases (but the problem will be the lack of \ntraining examples for machine learning systems), \nor b) to add low-frequency examples artificially to \n“enrich” the corpus (but the problem will be the \ndistortion of the native frequency distribution and \nperhaps the confusion of machine learning \nsystems). In the current state of our project, we \nhave chosen the first option. We think that, \nincluding specialized texts in a second stage, we \nwill get more examples of these less common \nrelations. If we carry out a more granulated \nsegmentation maybe we could obtain more \nexamples; however, we wanted to employ the \nsegmentation criteria used to develop the Spanish \nRST discourse segmenter (da Cunha et al., 2011). \n', 0, 0)
(313.3005676269531, 80.75643157958984, 495.85595703125, 95.97100067138672, ' \nQuantity \nRelation \nType \n', 1, 0)
(447.22039794921875, 101.7051010131836, 512.2937622070312, 110.37102508544922, 'Nº \n% \n', 2, 0)
(316.0605773925781, 115.62508392333984, 517.2208251953125, 124.29100799560547, 'Elaboration \nN-S \n765 \n24.56 \n', 3, 0)
(316.0605773925781, 130.02511596679688, 517.2181396484375, 138.6910400390625, 'Preparation \nN-S \n475 \n15.25 \n', 4, 0)
(316.0605773925781, 144.30508422851562, 515.2954711914062, 152.97100830078125, 'Background \nN-S \n204 \n6.55 \n', 5, 0)
(316.0605773925781, 158.70504760742188, 515.2957763671875, 167.3709716796875, 'Result \nN-S \n193 \n6.20 \n', 6, 0)
(316.0605773925781, 172.86502075195312, 515.29296875, 181.53094482421875, 'Means \nN-S \n175 \n5.62 \n', 7, 0)
(316.0605773925781, 187.14505004882812, 515.2957763671875, 195.81097412109375, 'List \nN-N \n172 \n5.52 \n', 8, 0)
(316.0605773925781, 201.54501342773438, 515.29443359375, 210.2109375, 'Joint \nN-N \n160 \n5.14 \n', 9, 0)
(316.0605773925781, 215.82504272460938, 515.300537109375, 224.490966796875, 'Circumstance \nN-S \n140 \n4.49 \n', 10, 0)
(316.0605773925781, 230.10501098632812, 515.2918090820312, 238.77093505859375, 'Purpose \nN-S \n122 \n3.92 \n', 11, 0)
(316.0605773925781, 244.38504028320312, 515.3018188476562, 253.05096435546875, 'Interpretation \nN-S \n88 \n2.83 \n', 12, 0)
(316.0605773925781, 258.7850036621094, 515.2958374023438, 267.450927734375, 'Antithesis \nN-S \n80 \n2.57 \n', 13, 0)
(316.0605773925781, 273.0650329589844, 515.2942504882812, 281.73095703125, 'Cause \nN-S \n77 \n2.47 \n', 14, 0)
(316.0605773925781, 287.3450012207031, 516.25537109375, 296.01092529296875, 'Sequency \nN-N \n74 \n 2.38 \n', 15, 0)
(316.0605773925781, 301.625, 515.2991943359375, 310.2909240722656, 'Evidence \nN-S \n59 \n1.89 \n', 16, 0)
(316.0605773925781, 315.9049987792969, 515.2955932617188, 324.5709228515625, 'Contrast \nN-N \n58 \n1.86 \n', 17, 0)
(316.0605773925781, 330.18499755859375, 515.2971801757812, 338.8509216308594, 'Condition \nN-S \n53 \n1.70 \n', 18, 0)
(316.0605773925781, 344.4649658203125, 515.2943725585938, 353.1308898925781, 'Concession \nN-S \n50 \n1.61 \n', 19, 0)
(316.0605773925781, 358.8649597167969, 515.299560546875, 367.5308837890625, 'Justification \nN-S \n39 \n1.25 \n', 20, 0)
(316.0605773925781, 373.14495849609375, 515.2959594726562, 381.8108825683594, 'Solution \nN-S \n32 \n1.03 \n', 21, 0)
(316.0605773925781, 387.4249572753906, 515.2984008789062, 396.09088134765625, 'Motivation \nN-S \n28 \n0.90 \n', 22, 0)
(316.0605773925781, 401.7049560546875, 515.30078125, 410.3708801269531, 'Reformulation \nN-S \n22 \n0.71 \n', 23, 0)
(316.0605773925781, 415.9849548339844, 515.2943115234375, 424.65087890625, 'Otherwise \nN-S \n3 \n0.10 \n', 24, 0)
(316.0605773925781, 430.38494873046875, 515.2982788085938, 439.0508728027344, 'Conjunction \nN-N \n11 \n0.35 \n', 25, 0)
(316.0605773925781, 444.5449523925781, 515.3007202148438, 453.21087646484375, 'Evaluation \nN-S \n11 \n0.35 \n', 26, 0)
(316.0605773925781, 458.9449462890625, 515.2969970703125, 467.6108703613281, 'Disjunction \nN-N \n9 \n0.29 \n', 27, 0)
(316.0605773925781, 473.2249450683594, 515.2957763671875, 481.890869140625, 'Summary \nN-S \n8 \n0.26 \n', 28, 0)
(316.0605773925781, 487.98492431640625, 515.3020629882812, 496.6508483886719, 'Enablement  \nN-S \n5 \n0.16 \n', 29, 0)
(316.0605773925781, 502.7449035644531, 515.2918701171875, 511.41082763671875, 'Unless \nN-S \n2 \n0.06 \n', 30, 0)
(313.3005676269531, 514.5637817382812, 533.0426635742188, 529.695068359375, ' \nTable 2: Rhetorical relations in RST Spanish Treebank \n', 31, 0)
(327.1005859375, 530.2837524414062, 328.06365966796875, 534.5518188476562, ' \n', 32, 0)
(313.3005676269531, 542.7501220703125, 455.6621398925781, 555.6845703125, '3.2 \nInstantiating the Theory \n', 33, 0)
(313.3006286621094, 561.4629516601562, 536.8258056640625, 696.3623657226562, 'Our segmentation and annotation criteria are very \nsimilar to the original ones used by Mann and \nThompson (1988) for English, and by da Cunha \nand Iruskieta (2010) for Spanish. We also explore \nthe annotation manual for English by Carlon and \nMarcu (2001). Though we use some of their \npostulates, we think that their analysis is too \nmeticulous in some aspects. Because of this, we \nconsider that it is not adjusted to our interest, \nwhich is the finding of the simplest and most \nobjective annotation method, orientated to the \n', 34, 0)
(293.2098388671875, 724.5390014648438, 298.6643981933594, 737.6844482421875, '4\n', 35, 0)

page suivante
(78.58016967773438, 80.86316680908203, 302.0920104980469, 105.00262451171875, 'future development of a rhetorical parser for \nSpanish. To sum up, our segmentation criteria are:  \n', 0, 0)
(78.58016967773438, 105.60394287109375, 302.0963439941406, 171.00250244140625, ' \na) All the sentences of the text are segmented as \nEDUs (we consider that a sentence is a textual \npassage between a period and another period, a \nsemicolon, a question mark or an exclamation \npoint; texts’ titles are also segmented). Exs.4 \n', 1, 0)
(78.57978820800781, 171.6038818359375, 302.0851745605469, 268.322509765625, ' \n[Éstas son las razones fundamentales que motivaron \neste trabajo.] \n      [These are the fundamental reasons which motivated this \nwork.] \n[Estudio de caso único sobre violencia conyugal] \n       [Study of a case on conjugal violence] \nb) Intra-sentence EDUs are segmented, using the \nfollowing criteria: \n', 2, 0)
(78.58016967773438, 268.80389404296875, 302.09075927734375, 297.362548828125, ' \nb1) An intra-sentence EDU has to include a finite \nverb, an infinitive or a gerund. Ex.  \n', 3, 0)
(78.58016967773438, 297.9638671875, 302.0876159667969, 373.4424743652344, ' \n[Siendo una variante de la eliminación Gaussiana,] \n[posee características didácticas ventajosas.] \n      [Being a variant of Gaussian elimination,] [it possesses \n didactic profitable characteristics.] \nb2) \nSubject/object \nsubordinate \nclauses \nor \nsubstantive sentences are not segmented. Ex.  \n', 4, 0)
(78.58016967773438, 373.923828125, 302.0652160644531, 470.762451171875, ' \n[Se muestra que el modelo discreto en diferencias finitas \nes convergente y que su realización se reduce a resolver \nuna sucesión de sistemas lineales tridiagonales.] \n      [It appears that the discreet model in finite differences is \nconvergent and that its accomplishment is to solve a \n succession of tridiagonal linear systems.] \nb3) Subordinate relative clauses are not segmented. \nEx. \n', 5, 0)
(78.58016967773438, 471.2437744140625, 302.0943908691406, 651.8424072265625, " \n[Durante el proceso, que utiliza solo aritmética entera, \nse obtiene el determinante de la matriz de coeficientes \ndel sistema, sin necesidad de cálculos adicionales.] \n       [During the process, which only uses entire arithmetic, the \ndeterminant of the system coefficient matrix is obtained, \n without  additional calculations.] \nb4) Elements in parentheses are only segmented if \nthey follow the criterion b1. Ex.  \n[Este año se cumple el bicentenario del nacimiento de \nNiels (Nicolás, en nuestro idioma) Henrik Abel.] \n       [This year is the bicentenary of Niels's birth (Nicolás, in \nour language) Henrik Abel.] \n \n   \nb5) Embedded units are segmented by means of \nthe non-relation Same-Unit proposed by Carlon \nand Marcu (2001). Figure 1 shows this structure. \n", 6, 0)
(78.58016967773438, 652.4436645507812, 301.8270263671875, 711.4129028320312, ' \n[En décadas precedentes se ha puesto de manifiesto,] [y \nasí lo han atestiguado muchos investigadores de la \n                                                           \n4 Spanish examples were extracted from the corpus. English \ntranslations are ours. \n', 7, 0)
(313.3005676269531, 80.83970642089844, 536.5606079101562, 137.71202087402344, 'terminología científica serbia,] [una tendencia a \nimportar préstamos del inglés.]  \n        [In previous decades it has been shown,] [and it has been \ntestified by many researchers of the scientific Serbian \nterminology,] [a trend to import loanwords from English.]  \n \n', 8, 0)
(327.58056640625, 217.66310119628906, 522.1488647460938, 237.97523498535156, ' \nFigure 1: Example of the non-relation Same-Unit \n', 9, 0)
(313.3005676269531, 246.59027099609375, 450.2669372558594, 259.52471923828125, '3.3 \nDesigning the Interface \n', 10, 0)
(313.30059814453125, 265.3031005859375, 536.8162841796875, 338.64251708984375, 'The annotation tool used in this work is the \nRSTtool, since it is free and easy to use. Therefore, \nwe preferred to use it instead of designing a new \none. Nevertheless, we have designed an on-line \ninterface to include the corpus and to carry out \nsearches over it (see Section 4). \n', 11, 0)
(313.3005676269531, 347.1501770019531, 519.26416015625, 360.0846252441406, '3.4 \nSelecting and Training the Annotators \n', 12, 0)
(313.3002624511719, 365.8630065917969, 536.823486328125, 636.122314453125, 'With regard to the corpus annotators, we have a \nteam of 10 people (last year Bachelor’s degree \nstudents, Master’s degree students and PhDs) 5 . \nBefore the annotation, they took a RST course of 6 \nmonths (100 hours), where the segmentation and \nannotation methodology used for the development \nof the RST Spanish Treebank was explained.6 We \ncalled this period "training phase". The course had \na theoretical and a practical part. In the theoretical \npart, some criteria with regard to the 3 phases of \nrhetorical analysis (segmentation, detection of \nrelations, and rhetorical trees building) were given \nto annotators. In the practical part, firstly, it was \nexplained how to use the RSTtool. Secondly, \nannotators extracted several texts from the web, \nfollowing their personal interests, as for example, \nmusic, video games, cookery or art webs. They \nsegmented those texts, using the established \nsegmentation criteria. Once segmented, all the \ndoubts and problematic examples were discussed, \nand they tried to get an agreement on the most \ncomplicated cases. Thirdly, the relations were \n', 13, 0)
(313.3004455566406, 639.9194946289062, 536.2957153320312, 711.4129028320312, '                                                           \n5  We thank annotators (Adriana Valerio, Brenda Castro, \nDaniel Rodríguez, Ita Cruz, Jessica Méndez, Josué Careaga, \nLuis Cabrera, Marina Fomicheva and Paulina De La Vega) \nand interface developers (Luis Cabrera and Juan Rolland). \n6 This course was given in the framework of a last-year subject \nin the Spanish Linguistics Degree at UNAM (Mexico City).  \n', 14, 0)
(293.2098388671875, 724.5390014648438, 298.6643981933594, 737.6844482421875, '5\n', 15, 0)

page suivante
(78.58016967773438, 80.86316680908203, 302.1014099121094, 215.762451171875, 'analyzed (using a given relations list) and, once \nagain, annotators discussed the difficult cases. \nAfter the discussion, texts were re-annotated to \nverify if the difficulties were solved. This process \nwas doubly interesting, since it helped to create \ncommon criteria for the annotation of the final \ncorpus and to define the annotation criteria more \nclearly and consensually, in order to include them \nin the RST Spanish Treebank annotation manual. \nOnce annotators agreed on the most difficult cases, \nwe consider that the training phase finished. \n', 0, 0)
(78.58016967773438, 224.3902587890625, 302.0556640625, 249.362548828125, '3.5 \nDesigning and Managing the Annotation \nProcedure \n', 1, 0)
(78.58020782470703, 255.3430938720703, 298.8247985839844, 267.2425537109375, 'We start from the following annotation definition:  \n', 2, 0)
(78.58016967773438, 267.723876953125, 301.8299560546875, 349.93511962890625, ' \nAnnotation (‘tagging’) is the process of adding new \ninformation into source material by humans \n(annotators) or suitably trained machines. [...]. The \naddition process usually requires some sort of \nmental decision that depends both on the source \nmaterial and on some theory or knowledge that the \nannotator has internalized earlier. (Hovy, 2010: 6) \n', 3, 0)
(78.57987213134766, 350.39630126953125, 302.1132507324219, 710.0421752929688, ' \nExactly, after our annotators internalized the \ntheory and annotation criteria during the training \nphase, the "annotation phase" of the final texts \nincluded in the RST Spanish Treebank started. In \nthis phase, the annotation tasks were assigned to \nannotators (the number of texts assigned to each \nannotator was different, depending on their \navailability). They were asked to carry out the \nannotation individually and without questions \namong them. We calculated that the average time \nto carry out the annotation of one text was between \n15 minutes and 1 hour. This time difference is due \nto the fact that the corpus includes both short and \nlong texts. The annotation process is the following: \nonce a text is segmented, rhetorical relations \nbetween EDUs are annotated. First, EDUs inside \nthe same sentence are annotated in a binary way. \nSecond, sentences inside the same paragraph are \nlinked. Finally, paragraphs are linked.  \nHovy (2010) states that it is difficult to \ndetermine if, for the same money (we add “for the \nsame time”), it is better to double-annotate less, or \nto single-annotate more. As he explains, Dligach et \nal. (2010) made an experiment with OntoNotes \n(Pradhan et al., 2007) verb sense annotation. The \nresult was that, assuming the annotation is stable \n(that is, inter-annotator agreement is high), it is \nbetter to annotate more, even with only one \nannotator. The problem with RST annotation is \n', 4, 0)
(313.2999267578125, 80.86298370361328, 536.818359375, 240.36224365234375, 'that there are so many categories to annotate, that \nis very difficult to obtain a stable annotation. \nTherefore, we consider it is necessary to have at \nleast some texts double-annotated (or even triple-\nannotated), in order to have an adequate discourse \ncorpus. This is the reason why, following the RST \nDiscourse Treebank methodology, we use some \ntexts as learning corpus and some others (from the \nMathematics, Psychology and Sexuality domains) \nas test corpus: 69% (183 texts) and 31% (84 texts), \nrespectively. The texts of the learning corpus were \nannotated by 1 person, whereas the texts of the test \ncorpus were annotated by 2 people. \n', 5, 0)
(313.3005676269531, 248.8702392578125, 427.94219970703125, 261.8046875, '3.6 \nValidating Results \n', 6, 0)
(313.30059814453125, 267.58306884765625, 536.8214721679688, 710.0420532226562, "Da Cunha and Iruskieta (2010) measure inter-\nannotator agreement by using the RST trees \ncomparison methodology by Marcu (2000). This \nmethodology evaluates the agreement on 4 \nelements \n(EDUs, \nSPANs, \nNuclearity \nand \nRelations), by means of precision and recall \nmeasures (an annotation with regard to the other \none). Following this methodology, we have \nmeasured inter-annotator agreement over the test \ncorpus. We employ an on-line automatic tool for \nRST trees comparison, RSTeval (Mazeiro and \nPardo, 2009), where Marcu’s methodology has \nbeen implemented (for 4 languages: English, \nPortuguese, Spanish and Basque). We know that \nthere are some other ways to measure agreement, \nsuch as Cohen's kappa (Cohen, 1960) or Fleiss's \nkappa (Fleiss, 1971), for example. Nevertheless, \nwe consider that Marcu's methodology (2000) is \nsuitable to compare adequately 2 annotations of the \nsame original text, because it has been designed \nspecifically for this task.  \nFor each trees pair from the test corpus, \nprecision and recall were measured separately. \nAfterwards, all those individual results were put \ntogether to obtain general results. Table 3 shows \nglobal results for the 4 categories. The category \nwith more agreement was EDUs (recall: 91.04% / \nprecision: 87.20%), that is, segmentation. This \nresult was expected, since the segmentation criteria \ngiven to the annotators were quite precise and the \npossibility of mistake was low. The lowest \nagreement was obtained for the category Relations \n(recall: 78.48% / precision: 76.81%). This result is \nlower than the other, but we think it is acceptable. \nIn the RST Discourse Treebank the trend was \nsimilar to the one detected in our corpus: the \n", 7, 0)
(293.2098388671875, 724.5390014648438, 298.6643981933594, 737.6844482421875, '6\n', 8, 0)

page suivante
(78.58016967773438, 80.86316680908203, 302.1033630371094, 105.00262451171875, 'highest agreement is obtained at the segmentation \nlevel and the lowest at the relations level. \n', 0, 0)
(78.58016967773438, 105.60394287109375, 274.1051025390625, 123.93102264404297, '  \nCategory \nPrecision \nRecall \n', 1, 0)
(87.46017456054688, 129.18508911132812, 275.6551818847656, 138.09100341796875, 'EDUs \n87.20% \n91.04% \n', 2, 0)
(87.46017456054688, 143.58511352539062, 275.6552429199219, 152.49102783203125, 'SPANs \n86% \n87.31% \n', 3, 0)
(87.46017456054688, 157.86502075195312, 275.6551818847656, 166.77093505859375, 'Nuclearity \n82.46% \n84.66% \n', 4, 0)
(87.46017456054688, 172.62503051757812, 275.6551818847656, 181.53094482421875, 'Relations \n76.81% \n78.48% \n', 5, 0)
(120.8206558227539, 184.80389404296875, 259.34869384765625, 199.93519592285156, ' \nTable 3: Inter-annotator agreement \n', 6, 0)
(78.58012390136719, 200.14927673339844, 302.1009216308594, 427.0822448730469, '  \nPrecision and recall have not been calculated \nwith respect to a gold standard because it does not \nexist for Spanish. Our future aim is to reach a \nconsensus on the annotation of the test corpus \n(using an external "judge"), in order to establish a \nset of texts considered as a preliminary gold \nstandard for this language. We consider that the \nannotations have quality at present, because inter-\nannotator agreement is quite high; however, this \nconsensus could solve the typical annotation \nmistakes we have detected or some ambiguities. \nWe have analyzed the main discrepancy reasons \nbetween \nannotators. \nWith \nregard \nto \nthe \nsegmentation, the main one was human mistake; \nex. segmenting EDUs without a verb (one \nannotator segmented the following passage into 2 \nEDUs because she detected a Means relation, but \nthe second EDU does not include any verb): \n', 7, 0)
(78.58012390136719, 427.44378662109375, 302.09771728515625, 597.0023803710938, ' \n[Además estudiamos el desarrollo de criterios para \ndeterminar si un semigrupo dado tiene dicha propiedad ] \n[mediante el estudio de desigualdades de curvatura-\ndimensión. ]  \n      [We also study the development of tests in order to \ndetermine if a given semi group has this property] [by means \n of curvature-dimension inequalities.]  \nThe second reason was that in the manual some \naspects were not explained in detail. For example, \nif a substantive sentence or a direct/object clause \n(which must not be segmented, according to the \npoint b2) includes two coordinated clauses, these \nmust not be segmented either. Thus, we found \nsome erroneous segmentations. For example: \n', 8, 0)
(78.58013916015625, 597.4837036132812, 302.0894775390625, 706.682373046875, ' \n[Los hombres adultos tienen miedo de fracasar] [y no \ncumplir con el rol masculino de ser proveedores del \nhogar y de proteger a su familia.]  \n      [Adult men are scared to fail] [and not to fulfill the \nmasculine role of being the suppliers of the home and to \n protect their family.]  \nThis kind of mistakes allowed us to refine our \nsegmentation manual a posteriori. In the future, we \nwill ask the test corpus annotators to make a new \n', 9, 0)
(313.30035400390625, 80.86316680908203, 536.8192749023438, 215.762451171875, 'annotation of the texts, using the refined manual, in \norder to check if the agreement increases, in the \nsame way as the RST Discourse Treebank. \nWith regard to rhetorical annotations, we \ndetected 2 main reasons of inter-annotator \ndisagreement. The first one was the ambiguity of \nsome relations and their corresponding connectors; \nfor example, Justification-Reason, Antithesis-\nConcession or Circumstance-Means relations, like \nin the following passage (in Spanish, “al” may \nindicate time or manner): \n', 10, 0)
(313.3005676269531, 216.243896484375, 536.813232421875, 306.36248779296875, ' \n[Los \nniños \naprenden \nmatemáticas] \n[al \nresolver \nproblemas.] \n       [Children learn mathematics] [when solving problems.] \nThe second one is due to differences between \nannotators when determining nuclearity. For \nexample, in the following passage, one annotator \nmarked Background and the other one Elaboration: \n', 11, 0)
(313.3005676269531, 306.8438415527344, 536.5341796875, 344.2951354980469, ' \n[Quedó \nun \nhueco \nen \nla \npared \nde \n60 \nx \n1.20cm.]S_Background [Norma y Andrés quieren \ncolocar en el hueco una pecera. ]N_Background \n', 12, 0)
(313.3005676269531, 344.6291809082031, 536.8172607421875, 453.9624328613281, ' \n[Quedó \nun \nhueco \nen \nla \npared \nde \n60 \nx \n1.20cm.]N_Elaboration [Norma y Andrés quieren \ncolocar en el hueco una pecera. ]S_Elaboration \n      [A hole of 60 x 1.20 cm remained in the wall.] [Norma and \n Andrés want to place a fish tank in the hole.]  \nIt is easier to solve segmentation disagreement \nthan relations disagreement, since in this case \nannotator subjectivity is more evident; we must \nconsider how to refine our manual in this sense. \n', 13, 0)
(313.3005676269531, 462.59014892578125, 526.9528198242188, 475.52459716796875, '3.7 \nDelivering and Maintaining the Product \n', 14, 0)
(313.3006286621094, 481.1829528808594, 536.82861328125, 702.2423095703125, 'Hovy (2010) mentions some technical issues \nregarding these points: licensing, distribution, \nmaintenance and updates. With regard to licensing \nand distribution, the RST Spanish Treebank will be \nfree for research purposes. We have a data \nmanager responsible for maintenance and updates.  \nThe description of the annotated corpus is also \na very important issue (Ide and Pustejovsky, 2010). \nIt is important to provide a high level description \nof the corpus, including the theoretical framework, \nthe methodology (annotators, annotation manual \nand tool, agreement, etc.), the means for resource \nmaintenance, the technical aspects, the project \nleader, the contact, the team, etc. The RST Spanish \nTreebank includes all this detailed information. \nXML (with a DTD) has been used, in order the \ncorpus can be reused for several aplications. In the \nfuture, we plan to use the standard XCES. \n', 15, 0)
(293.2098388671875, 724.5390014648438, 298.6643981933594, 737.6844482421875, '7\n', 16, 0)

page suivante
(78.58012390136719, 80.86316680908203, 302.0993957519531, 129.60260009765625, 'To know more about resources development, \nlinguistic annotation or inter-annotator agreement, \nwe recommend: Palmer et al. (on-line), Palmer and \nXue (2010), and Artstein and Poesio (2008). \n', 0, 0)
(78.58016967773438, 140.15032958984375, 302.2989807128906, 166.5247344970703, '4 \nThe Search Interface of the RST \nSpanish Treebank \n', 1, 0)
(78.579833984375, 174.3430938720703, 302.1054382324219, 678.3619995117188, "The RST Spanish Treebank interface is freely \navailable on-line7. It allows the visualization and \ndownloading of all the texts in txt format, with \ntheir corresponding annotated trees in RSTtool \nformat (rs3), as well as in image format (jpg). Each \ntext includes its title, its reference, its web link (if \nit is an on-line text) and its number of words. The \ninterface shows texts by areas and allows the user \nto select a subcorpus (including individual files or \nfolders containing several files). The selected \nsubcorpus can be saved on local disk (generating a \nxml file) for future analyses.  \nThe interface includes a statistical tool which \nallows obtaining statistics of rhetorical relations in \na subcorpus selected by the user. The RSTtool also \noffers this option but it can be only used for one \ntext. We consider that it is more useful for the user \nto obtain statistics from various texts, in order to \nget significant statistical results. As the RSTtool, \nour tool allows to count the multinuclear relations \nin two ways: a) one unit for each detected \nmultinuclear relation, and b) one unit for each \ndetected nucleus. If we use b), the statistics of the \nmultinuclear relations of Table 2 are higher: List \n(864), Joint (537), Sequence (289), Contrast (153), \nConjunction (28) and Disjunction (24).  \nWe are developing another tool, aimed to \nextract information from the annotated texts, which \nwe will soon include into the interface. This tool \nwill allow to the user to select a subcorpus and to \nextract from it the EDUs corresponding to the \nrhetorical relations selected, like a multidocument \nspecialized summarizer guided by user's interests.  \nThe RST Spanish Treebank interface also \nincludes a screen which permits the users to send \ntheir own annotated texts. Our aim is for the RST \nSpanish Treebank to become a dynamic corpus, in \nconstant evolution, being increased with texts \nannotated by users. This has a double advantage \nsince, on the one hand, the corpus will grow and, \non the other hand, users will profit from the \n", 2, 0)
(78.58016967773438, 690.3194580078125, 221.16275024414062, 711.4129028320312, '                                                           \n7 http://www.corpus.unam.mx/rst/ \n', 3, 0)
(313.300537109375, 80.86316680908203, 536.8186645507812, 154.32257080078125, "interface's \napplications, \nusing \ntheir \nown \nsubcorpora. The only requirement is to use the \nrelations and the segmentation and annotation \ncriteria of our project. Once the texts are sent, the \nRST Spanish Treebank data manager will verify if \nthe annotation corresponds to these criteria. \n", 4, 0)
(313.3005676269531, 164.750244140625, 488.77105712890625, 177.68470764160156, '5 \nConclusions and Future Work \n', 5, 0)
(313.3005676269531, 185.62306213378906, 536.8143310546875, 492.8421325683594, "We think that this work means an important step \nfor the RST research in Spanish, and that the RST \nSpanish Treebank will be useful to carry out \ndiverse researches about RST in this language, \nfrom a descriptive point of view (ex. analysis of \ntexts from different domains or genres) and an \napplied point of view (development of discourse \nparsers and NLP applications, like automatic \nsummarization, automatic translation, IE, etc.).  \nFor the moment the corpus' size is acceptable \nand, though the percentage of double-annotated \ntexts is not very high, we think that having 10 \nannotators (using the same annotation manual) \navoids the bias of only one annotator. In addition, \nthe corpus includes texts of diverse domains and \ngenres, which provides us with a heterogeneous \nSpanish corpus. Moreover, the corpus interface \nthat we have designed allows the user to select a \nsubcorpus and to analyze it statistically. In \naddition, we think that it is essential to release a \nfree corpus, on-line and dynamic, that is, in \ncontinuous growth. Nevertheless, we are conscious \nthat our work still has certain limitations, which we \nwill try to solve in the future. In the short term, we \nhave 5 aims:  \n", 6, 0)
(313.3005676269531, 493.2037658691406, 536.8201293945312, 607.92236328125, ' \na) To add one more annotator for the test corpus \nand to measure inter-annotator agreement. \nb) To use more agreement measures, like kappa. \nc) To reach a consensus on the annotation of the \ntest corpus, in order to establish a set of texts \nconsidered as a preliminary gold standard. \nd) To finish and to evaluate the IE tool. \ne) To analyze the corpus to extract linguistic \npatterns for the automatic relations detection. \n', 7, 0)
(313.3005676269531, 608.4037475585938, 505.96795654296875, 624.7223510742188, ' \nIn the long term, we consider other aims: \n', 8, 0)
(313.3005676269531, 625.2037353515625, 536.8204956054688, 701.89501953125, ' \nf) To increase the corpus, by adding non-\nspecialized texts, and new domains and genres. \ng) To annotate all the texts by 3 people, to get a \nrepresentative gold-standard for Spanish (this aim \nwill depend on the funding of the project). \n \n', 9, 0)
(293.2098388671875, 724.5390014648438, 298.6643981933594, 737.6844482421875, '8\n', 10, 0)

page suivante
(78.58016967773438, 81.23028564453125, 138.74322509765625, 94.16474914550781, 'References  \n', 0, 0)
(78.58016967773438, 100.15971374511719, 301.8314208984375, 144.3751983642578, 'Ron Artstein, and Massimo Poesio. 2008. Survey \nArticle: Inter-Coder Agreement for Computational \nLinguistics. Computational Linguistics, 34(4):555-\n596. \n', 1, 0)
(78.58486938476562, 150.67955017089844, 301.8230285644531, 194.8950958251953, 'Nadjet Bouayad-Agha, Leo Wanner, and Daniel \nNicklass. 2006. Discourse structuring of dynamic \ncontent. Procesamiento del lenguaje natural, 37:207-\n213. \n', 2, 0)
(78.58013153076172, 201.3195037841797, 301.82366943359375, 234.25502014160156, 'M. \nTeresa \nCabré \n(1999). \nLa \nterminología: \nrepresentación y comunicación. Barcelona: IULA-\nUPF. \n', 3, 0)
(78.58013153076172, 240.67942810058594, 301.8294372558594, 284.8948974609375, 'Lynn Carlson and Daniel Marcu. 2001. Discourse \nTagging Reference Manual. ISI Technical Report \nISITR-545. Los Ángeles: University of Southern \nCalifornia. \n', 4, 0)
(78.58013153076172, 291.1993103027344, 301.81884765625, 324.3748474121094, 'Lynn Carlson, Daniel Marcu, and Mary Ellen \nOkurowski. \n2002a. \nRST \nDiscourse \nTreebank. \nPennsylvania: Linguistic Data Consortium. \n', 5, 0)
(78.58013153076172, 330.5592956542969, 301.82049560546875, 397.21484375, 'Lynn Carlson, Daniel Marcu, and Mary Ellen \nOkurowski. 2002b. Building a Discourse-Tagged \nCorpus in the Framework of Rhetorical Structure \nTheory. In Proceedings of the 2nd SIGDIAL \nWorkshop on Discourse and Dialogue, Eurospeech \n2001. \n', 6, 0)
(78.58013153076172, 403.519287109375, 301.8301086425781, 436.5748291015625, 'Jacob Cohen. 1960. A coefficient of agreement for \nnominal scales. Educational and Psychological \nMeasurement, 20(1):37-46 \n', 7, 0)
(78.58013153076172, 442.8792724609375, 301.817626953125, 498.37481689453125, 'Iria da Cunha, Eric SanJuan, Juan-Manuel Torres-\nMoreno, Marina Lloberes, and Irene Castellón. 2010. \nDiscourse Segmentation for Spanish based on \nShallow Parsing. Lecture Notes in Computer \nScience, 6437:13-23.  \n', 8, 0)
(78.58011627197266, 504.6792297363281, 301.8299865722656, 549.0148315429688, 'Iria da Cunha, and Mikel Iruskieta. 2010. Comparing \nrhetorical structures of different languages: The \ninfluence of translation strategies. Discourse Studies, \n12(5):563-598.  \n', 9, 0)
(78.58072662353516, 555.3192749023438, 301.802490234375, 599.5347900390625, 'Iria da Cunha, Leo Wanner, and M. Teresa Cabré. 2007. \nSummarization of specialized discourse: The case of \nmedical articles in Spanish. Terminology, 13(2):249-\n286.  \n', 10, 0)
(78.58037567138672, 605.8392944335938, 301.8242492675781, 672.4948120117188, 'Dmitriy Dligach, Rodney D. Nielsen, and Martha \nPalmer. 2010. To Annotate More Accurately or to \nAnnotate More. In Proceedings of the 4th Linguistic \nAnnotation Workshop (LAW-IV). 48th Annual \nMeeting of the Association for Computational \nLinguistics. \n', 11, 0)
(313.29998779296875, 80.83952331542969, 536.546142578125, 113.89503479003906, 'Joseph L. Fleis. 1971. Measuring nominal scale \nagreement \namong \nmany \nraters. \nPsychological \nBulletin, 76(5):378-382. \n', 12, 0)
(313.29998779296875, 120.19944763183594, 536.5426025390625, 153.37501525878906, 'Eduard Hovy. 2010. Annotation. A Tutorial. Presented \nat the 48th Annual Meeting of the Association for \nComputational Linguistics. \n', 13, 0)
(313.30517578125, 159.5593719482422, 536.5484008789062, 226.21485900878906, 'Nancy Ide and Pustejovsky, J. (2010). What Does \nInteroperability \nMean, \nanyway? \nToward \nan \nOperational \nDefinition \nof \nInteroperability. \nIn \nProceedings of the Second International Conference \non Global Interoperability for Language Resources \n(ICGL 2010).  \n', 14, 0)
(313.30047607421875, 232.51927185058594, 536.5513305664062, 265.5748291015625, 'William C. Mann, and Sandra A. Thompson. 1988. \nRhetorical structure theory: Toward a functional \ntheory of text organization. Text, 8(3):243-281. \n', 15, 0)
(313.30096435546875, 271.8792419433594, 536.5438842773438, 305.0548095703125, 'Daniel Marcu. 2000. The Theory and Practice of \nDiscourse Parsing Summarization. Massachusetts: \nInstitute of Technology. \n', 16, 0)
(313.30096435546875, 311.2392272949219, 536.55029296875, 355.69476318359375, 'Mitchell P. Marcus, Beatrice Santorini, Mary A. \nMarcinkiewicz. 1993. Building a large annotated \ncorpus \nof \nEnglish: \nthe \nPenn \nTreenbank. \nComputational Linguistics, 19(2):313-330. \n', 17, 0)
(313.30096435546875, 361.87921142578125, 536.5531005859375, 406.21478271484375, 'Michael O’Donnell. 2000. RSTTOOL 2.4 – A markup \ntool for rhetorical structure theory. In Proceedings of \nthe International Natural Language Generation \nConference. 253-256. \n', 18, 0)
(313.30096435546875, 412.3992004394531, 536.5450439453125, 445.57476806640625, 'Martha Palmer, and Nianwen Xue. 2010. Linguistic \nAnnotation. Handbook of Computational Linguistics \nand Natural Language Processing.  \n', 19, 0)
(313.30096435546875, 451.87921142578125, 536.5473022460938, 506.4530029296875, 'Martha Palmer, Randee Tangi, Stephanie Strassel, \nChristiane Fellbaum, and Eduard Hovy (on-line). \nHistorical Development and Future Directions in \nData \nResource \nDevelopment. \nMINDS \nreport. \nhttp://www-nlpir.nist.gov/MINDS/FINAL/data.web.pdf \n', 20, 0)
(313.3005676269531, 512.4795532226562, 536.5516967773438, 579.2550659179688, 'Sameer Pradhan, Eduard Hovy, Mitch Marcus, Martha \nPalmer, Lance Ramshaw, Ralph Weischedel. 2007. \nOntoNotes: \nA \nUnified \nRelational \nSemantic \nRepresentation. In Proceedings of the First IEEE \nInternational Conference on Semantic Computing \n(ICSC-07). \n', 21, 0)
(313.3005676269531, 585.4395141601562, 536.54638671875, 652.0950317382812, 'Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni \nMiltsakaki, Livio Robaldo, Aravind Joshi, and \nBonnie Webber. 2008. The Penn Discourse Treebank \n2.0. In Proceedings of the 6th International \nConference on Language Resources and Evaluation \n(LREC 2008). \n', 22, 0)
(313.3005676269531, 658.3994750976562, 536.5565795898438, 691.4550170898438, 'David Reitter, and Mandred Stede. 2003. Step by step: \nunderspecified markup in incremental rhetorical \nanalysis. In Proceedings of the 4th International \n', 23, 0)
(293.2098388671875, 724.5390014648438, 298.6643981933594, 737.6844482421875, '9\n', 24, 0)

page suivante
(89.62017059326172, 80.83970642089844, 301.8236999511719, 102.73524475097656, 'Workshop on Linguistically Interpreted Corpora \n(LINC-03). \n', 0, 0)
(78.5802001953125, 109.03965759277344, 301.8211669921875, 142.21522521972656, 'Magdalena Romera. 2004. Discourse Functional Units: \nThe Expression of Coherence Relations in Spoken \nSpanish. Munich: LINCOM. \n', 1, 0)
(78.5807876586914, 148.51963806152344, 301.8284912109375, 203.8950958251953, 'Thiago Alexandre Salgueiro Pardo, and Lucia Helena \nMachado Rino. 2001. A summary planner based on a \nthree-level discourse model. In Proceedings of \nNatural \nLanguage \nProcessing \nPacific \nRim \nSymposium. 533-538. \n', 2, 0)
(78.5807876586914, 210.1995086669922, 301.83197021484375, 265.57501220703125, 'Thiago Alexandre Salgueiro Pardo, Maria das Graças \nVolpe Nunes, and Lucia Helena Machado Rino. \n2008. DiZer: An Automatic Discourse Analyzer for \nBrazilian Portuguese. Lecture Notes in Artificial \nIntelligence, 3171:224-234.  \n', 3, 0)
(78.5807876586914, 271.8794250488281, 301.8282775878906, 316.2149658203125, 'Thiago Alexandre Salgueiro Pardo, and Eloize Rossi \nMarques Seno. 2005. Rhetalho: um corpus de \nreferência anotado retoricamente. In Anais do V \nEncontro de Corpora. São Carlos-SP, Brasil. \n', 4, 0)
(78.5807876586914, 322.5194091796875, 301.8041076660156, 366.7349548339844, 'Gerardo Sierra. 2008. Diseño de corpus textuales para \nfines lingüísticos. In Proceedings of the IX Encuentro \nInternacional de Lingüística en el Noroeste 2. 445-\n462. \n', 5, 0)
(78.58039093017578, 373.0393981933594, 301.8133544921875, 417.3750915527344, 'Manfred Stede. 2004. The Potsdam commentary corpus. \nIn Proceedings of the Workshop on Discourse \nAnnotation, 42nd Meeting of the Association for \nComputational Linguistics. \n', 6, 0)
(78.58074188232422, 423.6795349121094, 301.8258056640625, 456.8551025390625, 'Maite \nTaboada. \n2004. \nBuilding \nCoherence \nand \nCohesion: Task-Oriented Dialogue in English and \nSpanish. Amsterdam/Philadelphia: John Benjamins. \n', 7, 0)
(78.58074188232422, 463.03955078125, 301.82080078125, 518.5350952148438, 'Maite Taboada, and Jan Renkema. 2008. Discourse \nRelations Reference Corpus [Corpus]. Simon Fraser \nUniversity \nand \nTilburg \nUniversity. \nhttp://www.sfu.ca/rst/06tools/discourse_relations_cor\npus.html. \n', 8, 0)
(78.5809326171875, 524.8395385742188, 301.8291931152344, 558.01513671875, 'Maite Taboada, and William C. Mann. 2006a. \nRhetorical Structure Theory: Looking Back and \nMoving Ahead. Discourse Studies, 8(3):423-459.  \n', 9, 0)
(78.5809326171875, 564.1995239257812, 301.826171875, 597.3750610351562, 'Maite Taboada, and William C. Mann. 2006b. \nApplications \nof \nRhetorical \nStructure \nTheory. \nDiscourse Studies, 8(4):567-588.  \n', 10, 0)
(78.5809326171875, 603.6795043945312, 301.82781982421875, 659.0550537109375, 'Milan Tofiloski, Julian Brooke, and Maite Taboada. \n2009. A Syntactic and Lexical-Based Discourse \nSegmenter. In Proceedings of the 47th Annual \nMeeting of the Association for Computational \nLinguistics.  \n', 11, 0)
(78.5809326171875, 665.3594970703125, 301.8180236816406, 698.4150390625, 'Hai Zhao, Yan Song, and Chunyu Kit. 2010. How Large \na Corpus Do We Need: Statistical Method Versus \nRule-based Method. In Proceedings of the Seventh \n', 12, 0)
(327.1011047363281, 80.83970642089844, 536.5498046875, 102.73524475097656, "conference on International Language Resources and \nEvaluation (LREC'10). \n", 13, 0)
(313.3011474609375, 109.03965759277344, 315.7232971191406, 119.77522277832031, ' \n', 14, 0)
(290.4825439453125, 724.5390014648438, 301.39166259765625, 737.6844482421875, '10\n', 15, 0)

page suivante
