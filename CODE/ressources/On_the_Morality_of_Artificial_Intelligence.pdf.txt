(171.3179931640625, 135.7279815673828, 452.9449157714844, 156.4725341796875, 'On the Morality of Artiﬁcial Intelligence\n', 0, 0)
(216.5909881591797, 172.46743774414062, 411.901123046875, 186.87344360351562, 'Alexandra Luccioni and Yoshua Bengio∗\n', 1, 0)
(242.64100646972656, 186.41543579101562, 381.62017822265625, 200.82144165039062, 'Université de Montréal, Mila\n', 2, 0)
(274.1190185546875, 212.65243530273438, 350.1421203613281, 227.05844116210938, 'December 2019\n', 3, 0)
(295.4480285644531, 263.8923034667969, 328.8119812011719, 275.5576171875, 'Abstract\n', 4, 0)
(124.11903381347656, 280.6460876464844, 500.14312744140625, 390.0804748535156, 'Much of the existing research on the social and ethical impact of Artiﬁcial Intelligence has been\nfocused on deﬁning ethical principles and guidelines surrounding Machine Learning (ML) and other\nArtiﬁcial Intelligence (AI) algorithms [IEEE, 2017, Jobin et al., 2019]. While this is extremely useful for\nhelping deﬁne the appropriate social norms of AI, we believe that it is equally important to discuss both\nthe potential and risks of ML and to inspire the community to use ML for beneﬁcial objectives. In the\npresent article, which is speciﬁcally aimed at ML practitioners, we thus focus more on the latter, carrying\nout an overview of existing high-level ethical frameworks and guidelines, but above all proposing both\nconceptual and practical principles and guidelines for ML research and deployment, insisting on concrete\nactions that can be taken by practitioners to pursue a more ethical and moral practice of ML aimed at\nusing AI for social good.\n', 5, 0)
(99.2130355834961, 410.3995666503906, 406.4657287597656, 429.06396484375, '1\nArtiﬁcial Intelligence Leaves the Research Lab\n', 6, 0)
(99.2130355834961, 440.2214660644531, 525.04736328125, 754.09326171875, 'Progress in ML in the last decade has been extraordinary and has rekindled the notion that AI systems could\neventually reach human levels of performance, which was abandoned for several decades. Even if we are\nstill currently far from this achievement, technological progress in ML has passed a threshold which enables\nit to have a huge economic impact, estimated to be close to 16 trillion US dollars by 2030 [Szczepa´nski,\n2019]. This contrasts with the ﬁrst few decades of ML progress, when researchers had the luxury of fo-\ncusing purely on the fundamental aspects of their work, not worrying too much about its potential societal\nimpacts – an object recognition algorithm could be tested on a common dataset like MNIST [LeCun et al.,\n1998] or ImageNet [Deng et al., 2009], and an objective performance metric would be obtained in order to\nmeasure progress, without having to think about the messiness and complexity of deployment and social\nimpact. Something crucial has changed in recent years, as algorithms initially developed in the lab are\nincreasingly being improved and deployed in society, in real-world applications such as healthcare, trans-\nportation and industrial production with real-life consequences, and we are likely seeing just the tip of the\niceberg in terms of social impact. Along the way, this deployment in society has forced the realization that\nthese algorithms have social impacts which could be positive or negative. For example, we have realized\nthat biases hidden in data and algorithms could lead to more discrimination, in the simplest case simply\nbecause of the data imbalance: facial recognition algorithms have been found to underperform on gender\nand racial minorities [Buolamwini and Gebru, 2018]. Furthermore, above and beyond hidden biases, given\nthe high impact potential of ML research, the question stands of whether practitioners are acting with the\nbest interests of humanity and society in mind when developing their tools and applications.\nAs ML researchers and engineers, we believe that we have a shared responsibility to consider both ethics\nand moral values when we choose what we work on, for what organization, and whether the products we\ncontribute to directly or indirectly will be beneﬁcial to humanity or more likely to end up hurting more\nthan helping. Unfortunately, very few of us have been trained to think about these questions. Instead,\nmost of us have focused from a very young age on mathematics and computer science and not so much\non philosophy and other humanities. A good step towards learning about these issues is to consult the\ndocuments proposing ethical guidelines for AI, which we will cover in Section 2. Furthermore, in order\n', 7, 0)
(109.24199676513672, 761.5276489257812, 200.22584533691406, 771.8927612304688, '∗Also CIFAR Senior Fellow\n', 8, 0)
(309.6390075683594, 791.0145263671875, 314.62030029296875, 803.0194702148438, '1\n', 9, 0)
(10.940000534057617, 259.67999267578125, 37.619998931884766, 610.739990234375, 'arXiv:1912.11945v1  [cs.CY]  26 Dec 2019\n', 10, 0)

page suivante
(99.21299743652344, 100.5865478515625, 525.0443115234375, 124.54650115966797, 'to offer a guiding direction for such debates and soul-searching within the scope of ML, we propose the\nfollowing self-directed questions:\n', 0, 0)
(111.66600036621094, 135.45458984375, 372.25762939453125, 147.4595184326172, '1. How is the technology that I am working on going to be used?\n', 1, 0)
(111.66600036621094, 155.37957763671875, 261.66290283203125, 167.38450622558594, '2. Who will beneﬁt or suffer from it?\n', 2, 0)
(111.66600036621094, 175.30560302734375, 313.3388366699219, 187.31053161621094, '3. How much and what social impact will it have?\n', 3, 0)
(111.66600036621094, 195.2305908203125, 272.7810974121094, 207.2355194091797, '4. How does my job ﬁt with my values?\n', 4, 0)
(99.21299743652344, 218.14361572265625, 525.04443359375, 373.610595703125, 'We are conscious that the questions listed above are subjective and the answers will depend highly on the\nvalues and ethics of the individual answering them. Nonetheless, we hope that work on some applications,\nsuch as the design and deployment of lethal autonomous weapons and automatic surveillance, will clearly\nbe seen to contradict fundamental rights and dignity, as deﬁned in, among other places, the UN Declaration\nof Human Rights [1948]. Other applications of ML, such as those increasing the efﬁciency of advertising or\nbeating the stock market, are less clear-cut in their moral value, and merit informed debate and discussion\nwithin the scientiﬁc community and society at large. As some of us become more conscious of the potential\nor deﬁnite social impact of ML, we have the opportunity, if not the duty, to make our voices heard. A good\nexample of this is a recent letter signed by numerous scientists calling for an international treaty banning\nlethal autonomous weapon systems, e.g., killer drones which can decide to shoot at a person without human\ninvolvement, which would make it possible to take the broad social, moral and psychological context into\naccount and potentially decide to abort the mission (for instance, when the target is in a school or at a family\ndinner surrounded by women and children).\n', 5, 0)
(99.21298217773438, 376.5496520996094, 525.0477294921875, 606.7354125976562, 'Finally, while the legal frameworks to oversee and limit research and development violating these prin-\nciples are often and unfortunately updated in a reactive rather than a proactive manner, we believe that\nwe should not wait until all of the dots between ML and ethics are formally connected by legislation and\nregulation. We believe that we have a responsibility to educate ourselves, to think ahead about potential\nconsequences, to use our internal moral compasses and to consciously choose the direction of the research\nor engineering that we practice. This is important because we believe that we are faced with a wisdom\nrace: as technology becomes more powerful, its impact can be proportionally greater, either positively or\nnegatively.\nTo curb the negative impact, we need to become wiser individually (as reﬂected in our personal deci-\nsions) and collectively (through social norms, laws and regulations). Unfortunately, technological progress\nin AI has accelerated faster than the current rate of progress of personal and social wisdom, ultimately mak-\ning it possible for unwise humans or organizations, even those with good intentions and acting legally, to\nhave large-scale, major destructive effects. This is comparable to a world in which nuclear bombs (i.e. very\npowerful technology) were accessible and usable by children (i.e., persons with insufﬁcient maturity and\nwisdom), which could easily result in global nuclear war. This highlights the importance of the discussions\nstill to be had by large numbers of ML practitioners about ethics and social impact, as well as the safeguards\nthat need to be put in place to protect especially the most vulnerable members of our society. We will dis-\ncuss some of the most advanced efforts to introduce these safeguards in the next section, followed by some\nexamples of socially beneﬁcial applications of ML.\n', 6, 0)
(99.21298217773438, 626.7755737304688, 332.08050537109375, 645.43994140625, '2\nEthics and AI - Existing Initiatives\n', 7, 0)
(99.21298217773438, 656.596435546875, 525.0442504882812, 716.4224243164062, 'In recent years, there have been numerous initiatives which have taken one of two major approaches to\nfostering the ethical practice of AI: (1) Proposing principles guiding the socially responsible development\nof AI or (2) Raising concerns about the social impact of AI. We will describe both approaches in the current\nsection, as well as giving examples of notable initiatives and projects which have adopted either of the\napproaches.1\n', 8, 0)
(110.0719985961914, 723.2756958007812, 470.89056396484375, 733.8516235351562, '1For a more complete overview of different global ML ethics initiatives, see a recent review in Jobin et al. [2019]\n', 9, 0)
(309.6390075683594, 791.0145263671875, 314.62030029296875, 803.0194702148438, '2\n', 10, 0)

page suivante
(99.21299743652344, 98.31500244140625, 377.87677001953125, 113.86871337890625, '2.1\nDeﬁning Principles for Practicing AI Responsibly\n', 0, 0)
(99.21299743652344, 122.2545166015625, 525.0444946289062, 241.85557556152344, 'The topic of ethical research and practice in technology has been gaining momentum in different corners of\nthe computing community in recent years, and the various initiatives that have been proposed are indicative\nof the interest and the concern that many members share. For instance, in the United States, the Association\nfor Computing Machinery (ACM) has proposed a Code of Ethics and Professional Conduct, to be followed\nby all members of the association and to guide them in their usage of computer science [Gotterbarn et al.,\n2018]. A similar initiative was undertaken by the Royal Statistical Society (RSS) in the United Kingdom,\nwhich has created a practical guide for practitioners regarding the ethical use of mathematics [RSS, 2019].\nIn the present section, we will address the two most relevant and extensive initiatives to establish ethical\nguidelines for AI research and practice: the Montreal Declaration for Responsible Development of AI and\nthe IEEE report for Ethically Aligned Design.\n', 1, 0)
(99.21299743652344, 259.0059814453125, 477.35345458984375, 271.9673156738281, '2.1.1\nThe Montreal Declaration for a Responsible Development of Artiﬁcial Intelligence\n', 2, 0)
(99.21299743652344, 281.0325927734375, 525.0493774414062, 559.0393676757812, 'One of the most notable approaches to establishing guidelines for AI deployment is the Montreal Declara-\ntion for a Responsible Development of Artiﬁcial Intelligence, developed in 2017 and revised in 2018 based\non public feedback2. It was elaborated under the premise that given the assumption that since AI will even-\ntually affect all sectors of society, it requires principles to guide its development to ensure its adherence to\nhuman values and social progress. The resulting Declaration has ten principles, ranging from protection\nof privacy to equal representation, with some principles touching responsibility and ethics directly; for in-\nstance, the principle of Prudence stipulates that “Every person involved in AI development must exercise\ncaution by anticipating, as far as possible, the adverse consequences of AIS [Artiﬁcial Intelligent Systems]\nuse and by taking the appropriate measures to avoid them.” These principles were deﬁned after extensive\ndebates and dialogue between both specialists and non-specialists from different domains and parts of the\nworld to ensure representability and cohesion. The overall aim of the declaration was to spark public debate\nand to encourage a progressive and inclusive orientation to the development of AI.\nHowever, the Montreal declaration goes further than theoretical ethical principles, proposing recom-\nmendations to accomplish an ethical digital transition that includes all of the different levels of society,\nfrom researchers to policy-makers. For instance, it includes a proposition for auditing and validating the\nuse of AIS using concrete frameworks and certiﬁcations in order to prevent biases and discrimination. Spe-\nciﬁc steps were also proposed for ensuring the protection of democracy and reducing the environmental\nfootprint of AI, all within the framework of a democratic and citizen-led process. This is important given\nthat the effects of AI will permeate all levels of society, from the programmers and engineers who write\nthe code, to the leaders who will legislate it, and the businesses who will make products with it that will be\nused by all. The process of creation of the Montreal declaration was consequently the keystone to building\na way of including all of these different stakeholders in the elaboration of an ethical AI, and paves the way\nfor subsequent work on the topic.\n', 3, 0)
(99.21299743652344, 576.1887817382812, 260.57720947265625, 589.1500854492188, '2.1.2\nIEEE Ethically Aligned Design\n', 4, 0)
(99.21298217773438, 598.2154541015625, 525.0475463867188, 744.7153930664062, 'A more recent effort, initiated by the IEEE Global Initiative on Ethics of Autonomous and Intelligent Sys-\ntems, carried out an in-depth study on the issue of the ethics surrounding the design of AI systems [IEEE,\n2017]. In particular, aspects that are relevant to the topics covered in the present paper include: the usage of\nA/IS [autonomous and intelligent systems] in service to sustainable development for all, and more specif-\nically for the attainment of the United Nations Sustainable Development Goals (SDGs) [UNHCR, 2017].\nThe authors of the study speciﬁcally underline the potential of AI to contribute to resolving some of the\nworld’s most urgent problems, such as climate change and poverty, given the necessary will and orientation\ntowards these problems. Furthermore, they highlight the fact that despite their great potential, current AI\ndeployment and development is currently not aligned with these goals and impacts [IEEE, 2017, p. 144],\nwhich is unsettling given the myriad of ML project and initiatives worldwide.\nThe IEEE report also lays down principles to guide “the ethical and values-based design, development,\nand implementation of autonomous and intelligent systems”, many of which are similar to those deﬁned\n', 5, 0)
(110.0719985961914, 750.6282348632812, 350.29327392578125, 761.8975219726562, '2 https://www.montrealdeclaration-responsibleai.com/\n', 6, 0)
(309.63897705078125, 791.0145263671875, 314.6202697753906, 803.0194702148438, '3\n', 7, 0)

page suivante
(99.2129898071289, 100.5865478515625, 525.0488891601562, 354.68267822265625, 'by the Montreal Declaration: respect of human rights, data agency, transparency, accountability, etc. They\ngo further in proposing that “A/IS creators shall adopt increased human well-being as a primary success\ncriterion for development” instead of focusing on isolated metrics such as accuracy, and, from a deployment\nperspective, offering alternative metrics to quantify meaningful progress, for instance by evaluating social,\neconomic and environmental factors instead of proﬁt and other common success metrics. The report also\nincludes propositions for policymakers, legislators and other stakeholders from the extended AI community\nand, as such, represents the most extensive effort of establishing ethical boundaries and guidelines for AI\nresearch to date.\nIn a recent survey of the various global ethics guidelines proposed around AI, the authors observed that\ndespite a conceptual overlap between the many existing guidelines, including the two mentioned above,\nthere are major differences regarding how the principles are interpreted [Jobin et al., 2019]. This underlines\nthe complexity and nuance of applying theoretical, philosophical principles in practice, and raises questions\nsuch as: what aspects of the AI research and deployment pipeline do ethics principles affect? how would it\nbe possible to resolve conﬂicts between, for instance, fairness and sustainability (i.e. training an algorithm\nlonger and with more data - thus potentially leading to more greenhouse gas emissions - to ensure that it\nis not discriminatory and covers all demographic groups equally well)? And, above all, how is it possible\nto translate ethical principles into a programming language? In any case, the bridge between theory and\npractice has yet to be built and there are different ways in which that can happen. This underlines the\nnecessity of involving actors from different levels of the AI ecosystem (and neighboring ones) in order to\nensure that experts in policy-making work in tandem with experts in coding and engineering to create tools\nand frameworks that are coherent and usable by all.\n', 0, 0)
(99.2129898071289, 371.26318359375, 369.7352600097656, 386.81689453125, '2.2\nIdentifying Ethical Concerns of AI Applications\n', 1, 0)
(99.2129898071289, 395.2027282714844, 525.04443359375, 697.1195068359375, 'There are several types of ethical concerns regarding AI applications and, in this paper, we will focus more\nconcretely on bias leading to potential discrimination. While it is true that on the one hand, AI-infused\ntechnology such as computer vision can enhance public security, for instance by identifying crime in real-\ntime based on CCTV cameras, but the trade-off is that can also be abused to track individuals and to establish\na surveillance state where privacy is greatly threatened by those who control the technology. On the military\nside, similar technology can be used to design autonomous drones which use computer vision to identity\ntheir target, representing a grave threat to global security and democracy due to the lack of human oversight.\nIn addition to the security risk, such weapons would be moral and legal hazard: AI technology is not yet\ncapable to comprehend and represent the social and psychological context in which such a targeted attack\ncould take place in a manner that is coherent with international laws regarding war as well as with human\nmorality.\nUnfortunately, the most common argument brought in favour of developing lethal autonomous weapons\nis that they are needed as a precautionary measure (i.e. since other countries are undeniably working on\nthem, each country needs to do the same). In reality, the weapons needed to defend against killer drones\nwould be very different from the drones themselves, and do not need to be lethal autonomous weapons since\nthey would be designed to destroy weapons rather than to target people, similar to the Iron Dome used by\nIsrael. Another common argument is that an international treaty would be useless since some countries will\nrefuse to sign it. But we have seen in the past that even when major powers do not sign a treaty (such as\nthe one on anti-personnel mines, signed by 133 countries, excluding the US, in 1997), the treaty can still be\nused to create a moral stigma, as well as a decline in demand; in the case of anti-personnel mines, the result\nhas been that U.S. companies have stopped building them, even though their government never signed the\ntreaty. Another ﬂawed argument is that regulating lethal autonomous weapons could threaten the innovation\nin AI, whereas in fact AI has been developed very successfully in a civilian setting (mostly in academia and\nmajor technology companies) and its continued development does not require neither data nor engineering\nwhich would come from AI military development.\n', 2, 0)
(99.2129898071289, 700.05859375, 525.0445556640625, 771.8395385742188, 'Another potential threat to democracy stemming from AI could come not simply from the increased\nability to monitor and to target individuals, but also from the more subtle power to inﬂuence them, e.g. via\nAI-driven advertising, automated online trolls and other psychological manipulations via the internet and\nsocial media. The recent use of AI to inﬂuence political campaigns such as the 2016 US election or Brexit\nis just the beginning of what can be done when machines learn how to “press our buttons” in a personalized\nway. This is due to the fact that micro-targeting makes it possible for ads to be truly bespoke depending\n', 3, 0)
(309.63897705078125, 791.0155639648438, 314.6202697753906, 803.0205078125, '4\n', 4, 0)

page suivante
(99.21299743652344, 100.5865478515625, 525.0443115234375, 232.1426239013672, 'on your political views, network of friends and personal history. While we may not mind being inﬂuenced\nwhen it comes to choosing a brand of soft drinks, when the proﬁt or power motives of a corporation or\npolitical organization go against our individual and collective interests, it becomes important to establish\nsocial norms, laws and regulations to protect us from such psychological manipulation. But where should\nthe line be drawn between, for example, manipulation and education? These are difﬁcult questions but\nthere are clues which can be used (like whether the organization that stands to proﬁt is paying for the\nadvertisement or social network inﬂuence), so human judgement remains key for judging the ethical aspect,\ne.g. in balancing different values (like autonomy vs well-being, when considering an ad campaign against\ncigarettes, for example). In the case of advertising, what is interesting is that in addition to the moral hazard\nassociated with psychological manipulation, it is not even clear that advertising is beneﬁcial to society from\na purely economic perspective, as it tends to favour established brands and thus slow down innovation.\n', 0, 0)
(99.21299743652344, 235.0816650390625, 525.04443359375, 342.7276916503906, 'Closely related to the political misuse and manipulation with AI is also increasing concern about AI-\ngenerated false images, videos and news. Thanks to rapid progress in generative neural networks such as\nthe GANs [Goodfellow et al., 2014], it is becoming possible to synthesize images and sounds in a controlled\nway, e.g., using “deep fakes” for making a video of a president declaring war, or with the face of a celebrity\nseamlessly integrated on the body and behavior of a pornography actor. Other commonly discussed concerns\nof AI deployment include the effect on the job market [Perisic, 2018], which means that governments and\ncommunities must prepare, e.g. by adapting the education system and the social safety net, which can\ntake decades, as well as the potential concentration of power which it may lead to in speciﬁc individuals,\ncorporations and countries, and the bias and discrimination it may contribute to increase, as we discuss next.\n', 1, 0)
(99.21299743652344, 359.87811279296875, 262.78887939453125, 372.8394470214844, '2.2.1\nIdentifying and Mitigating Bias\n', 2, 0)
(99.21298217773438, 381.9047546386719, 525.044921875, 453.68463134765625, 'In recent years, we have been confronted numerous times with the fact that biased algorithmic systems can\nperpetuate injustice and discrimination, whether we are aware of it or not. There are many different ways\nthat this kind of bias can creep into algorithms: it can be from the data itself, or the implicit bias that the\ncreator programmed into the system, and even the way the problem is framed3. Therefore, in order to ensure\nthat the models that we develop and the systems that they are later used in are as fair and ethical as possible,\nthere are steps to take to identify bias and to reduce it as much as possible.\n', 3, 0)
(99.21298217773438, 470.8350524902344, 164.79678344726562, 483.79638671875, 'Numerical Bias\n', 4, 0)
(99.21298217773438, 498.0917053222656, 525.0443725585938, 569.8726196289062, 'A major challenge in designing ML systems is understanding how they work during training and deploy-\nment, and what factors and features they use to make decisions. However, diagnosing the presence of bias\nin these systems is not a straightforward task, since it is not always obvious during a model’s construction\nwhat the downstream impacts of design choices may be; therefore, upstream efforts are needed to reduce\nthis risk as much as possible. To this end, there have been several proposals to help practitioners identify\nand mitigate bias in ML models, some of which we will describe in the current section.\n', 5, 0)
(99.21298217773438, 572.8116455078125, 525.04443359375, 704.3676147460938, 'More concretely, exploring, analyzing and visualizing the data used for training a model is a key part\nof the ML process. But it is not straightforward to identify bias simply by looking at the data; often, more\nin-depth probing is needed to ﬁgure out what features and implicit information is present and, once a model\nis developed, how this will inﬂuence the model’s behavior. For instance, it was recently found that the\nCOMPAS system, a criminal risk assessment tool developed widely used in the United States, is often\nbiased with respect to race [Angwin et al., 2016]. Whereas the bias in the COMPAS system was identiﬁed\nafter its deployment, once the data was made public, this bias is an aspect of the model that should have been\nidentiﬁed much earlier, during development and certainly before deployment. Similarly, off-the-shelf facial\nrecognition technology used by police forces has been shown to perform much worse on racial and gender\nminorities, with a difference of up to 34.4% in error rate between lighter-skinned males and darker-skinned\nfemales, mostly due to the lack of reliable training data [Buolamwini and Gebru, 2018].\n', 6, 0)
(99.21298217773438, 707.306640625, 525.0444946289062, 743.2216186523438, 'To address these types of issues, several approaches exist: for instance, researchers have recently re-\nleased a tool called ‘What-If’, an open-source application that lets practitioners not only visualize their\ndata, but also test the performance of their ML model in hypothetical situations, for instance modifying\n', 7, 0)
(99.21299743652344, 750.07470703125, 525.0474853515625, 770.1146240234375, '3For a more hands-on presentation of bias and fairness in AI, we suggest Google’s Online course designed speciﬁcally for ML\npractitioners\n', 8, 0)
(309.63897705078125, 791.0145263671875, 314.6202697753906, 803.0194702148438, '5\n', 9, 0)

page suivante
(99.21299743652344, 100.5865478515625, 525.0443725585938, 244.09861755371094, 'some characteristics of data points and analyzing subsequent model behavior, by measuring fairness met-\nrics such as Equal Opportunity and Demographic Parity [Wexler et al., 2019]. Other approaches address\nbias by changing the training procedure or the structure of ML models themselves, for instance by trans-\nforming the raw data in a space in which discriminatory information cannot be found [Zemel et al., 2013]\nor using a variational autoencoder to learn the latent structure from the dataset and using this structure to\nre-weight the importance of speciﬁc data points during model training [Ribeiro et al., 2016]. Whatever the\napproach chosen, using these kinds of tools during ML model development and deployment can change the\nlife of individual people, who could go from unfairly spending decades in prison to having the chance of a\nbetter life – an immensely important difference when multiplied by the thousands of people whose lives can\nbe affected by the deployment of these tools. This multiplication of bias is especially important to consider\nsince ML is being used more and more, and therefore even edge cases and small minorities can be ampliﬁed\nin real-world applications.\n', 0, 0)
(99.21299743652344, 261.248046875, 151.7158966064453, 274.2093811035156, 'Textual Bias\n', 1, 0)
(99.21299743652344, 288.50567626953125, 525.0444946289062, 724.9174194335938, 'Bias is not always in numbers, it can also manifest itself in the words that we use to describe the\nworld around us. For instance, in 2018, Reuters reported that Amazon was forced to decommission an\nML-powered recruiting engine when it was discovered that it penalized any mention of female-related\nvocabulary, including applicants who attended all-women colleges [Dastin, 2018]. This is not surprising\ngiven the gender disparity that exists in the technology sector and since the data used to develop this tool\nwas comprised of resumes submitted (and accepted) to Amazon over a 10-year period. It is nonetheless\ndisturbing in terms of algorithmic fairness, especially if algorithms such as this one make ﬁltering or hiring\ndecisions that can ultimately affect an entire gender’s lives and careers. This can potentially create a negative\nfeedback loop, as such a system would reduce the number of female workers and thus the number of\npositive role models for girls interested in technology. A similar type of gender bias was also found in\npretrained word embedding models, which were found to exhibit gender stereotypes in terms of higher\ncosine similarity between, for instance, ‘woman’ and ‘homemaker’ or ‘receptionist’ as opposed to ‘woman’\nand ‘doctor’ or ‘lawyer’, notably due to these biases existing in the corpus that they were trained on, which\nconsisted of mainstream news articles [Bolukbasi et al., 2016].\nIn order to reduce and eventually remove gender bias in written text, researchers have proposed ap-\nproaches such as identifying the gender subspace of vectors and adjusting the dimensions in a way that\neither neutralizes or entirely removes gender bias [Bolukbasi et al., 2016]. Others have deﬁned a formal\ngender bias taxonomy in order to capture gender bias and to train ML models to later identify this bias in\ntexts [Hitti et al., 2019]. Debiasing the computational representation of language, notably word embedding\nmodels, is especially important because of the extent of their usage; pretrained embedding models trained\non corpora such as Google News and the Common Crawl are used in a variety of applications and systems,\nand can therefore continue perpetuating gender bias in downstream usages in Natural Language Processing\n(NLP) applications such as dialogue systems. This is a challenge given the complex and sub-symbolic na-\nture of modern NLP, which makes it difﬁcult to analyze speciﬁc features and aspects of data and identify\nlatent connections and bias between words and concepts. Therefore, more work is needed to explore and\nanalyse these issues, which constitutes an interesting research direction in itself, and one that is important\nto pursue and to integrate into mainstream ML research.\nDespite the research initiatives described above to carve appropriate social norms about AI, there re-\nmains a noticeable gap between the recommendations they make and ways to ensure that these are respected.\nLegislation of AI is still catching up to the progress made in research and practice, and there have not yet\nbeen any country-level laws governing AI research speciﬁcally. However, there have been, on the one hand,\nmore high-level legislative frameworks such as the European Union (EU) General Data Protection Regula-\ntion (GDPR), which aims to ensure data privacy and protection and, on the other hand, more local initiatives\nsuch as San Francisco’s Facial Recognition Software Ban. Nonetheless, more complete legal frameworks\nare needed to control nefarious use of AI and to ensure that the principles deﬁned in theory are applied and\nenforced in practice.\n', 2, 0)
(309.63897705078125, 791.0154418945312, 314.6202697753906, 803.0203857421875, '6\n', 3, 0)

page suivante
(99.21299743652344, 96.01963806152344, 259.962158203125, 114.68404388427734, '3\nAI for Good Initiatives\n', 0, 0)
(99.21299743652344, 125.840576171875, 525.0443725585938, 269.3526611328125, 'Whereas the proﬁt motive is the main driver behind much of the commercial deployment of AI today, there\nare nonetheless many projects going on in academia, government organizations, civil society and industry\nlabs motivated by more noble objectives, often called AI for Social Good (AISG) projects. In addition\nto the speciﬁc projects being undertaken in areas such as healthcare, education or the environment, it is\ninteresting to highlight higher-level efforts which aim to foster and facilitate these projects. For example,\nthe AI Commons projec aims to construct a hub where different kinds of actors can connect and collaborate\non AISG projects, e.g., ML graduate students or engineers, problem owners in NGOs or local governments,\nphilanthropy organizations, or startups which could deploy the ML solutions. Their interaction is to be\nfacilitated by online tools and datasets as well as a standardized description of the status, progress and\nexpected impact of each project. We hope that initiatives like this will help solidify and amplify the impact\nof AISG; in the meantime, there are also many profoundly positive uses of AI that are emerging and we\nwould like to highlight and applaud such efforts in the present section.\n', 1, 0)
(99.21299743652344, 286.5821533203125, 211.56796264648438, 302.1358642578125, '3.1\nAI in Healthcare\n', 2, 0)
(99.21299743652344, 310.521728515625, 525.04443359375, 465.988525390625, 'Achieving universal health coverage is one of the 17 UN Sustainable Development Goals [UNHCR, 2017]\nand although major progress has been made in numerous domains, such as maternal health as well as\nHIV/AIDS reduction, there are still many problems that are far from being solved. While ML is not a cure-\nall, there are many challenges that it can help with such as personalized medicine, diagnosis of medical\nimagery, and improved drug discovery [Ghassemi et al., 2018]. ML in the health sector is in fact a thriving\ndomain of research, with its own workshops at major ML conferences and research published in major\nmedical journals read by practitioners worldwide. In the last ﬁve years alone, groundbreaking work has\nbeen done in improving the diagnosis of diabetic retinopathy from a single visit [Arcadu et al., 2019],\ndetecting breast cancer in lymph nodes [Golden, 2017] and large-scale discovery of diseases based on health\nrecords [Pivovarov et al., 2015]. There is also an increasing number of startups and companies working in\nthe space, either by commercializing research done in academia or by developing products speciﬁcally\ncatered to the medical sector, with the most advanced applications harnessing the power of deep learning\nfor analyzing and classifying medical imagery.\n', 3, 0)
(99.21299743652344, 468.9275817871094, 525.0476684570312, 624.3944091796875, 'Despite the many exciting advances that are being made, there are many hurdles in ML research in\nhealthcare, starting from data privacy and control (who owns the data? Can patients share their own data, or\nshould the process be centralized? How to ﬁnd the right balance between privacy and the lives which will\nbe saved by applying ML on the aggregated health records from many different sources?), to the manner\nin which medical data should be processed (Should it contain information such as race and postal/zip code,\nwhich can impact diagnoses, be included in electronic heath records, or does that open the door to discrim-\nination and bias?) and how should such systems be deployed (human-in-the-loop or fully automated?)4.\nThere are also often questions of responsibility and interpretability that arise, given the high stakes of de-\nploying ML systems in situations of life and death. In order to make meaningful progress in this sector, it is\ntherefore important to continue existing research on fair and ethical usage of ML in healthcare [Wiens et al.,\n2019] and to ensure that Hippocratic principles are a solid part of the research and development process,\nas well as working with stakeholders of the domain (e.g. radiologists, clinicians, patient organizations and\nhospital administrators) to propose solutions to the hurdles proposed above.\n', 4, 0)
(99.2130126953125, 641.6239013671875, 212.8232879638672, 657.1776123046875, '3.2\nAI for Education\n', 5, 0)
(99.2130126953125, 665.5634765625, 525.0443725585938, 749.2994384765625, 'The promise of using adaptive intelligent systems and agents for education has been around since the\n1960s [Suppes and Morningstar, 1969], but access to personalized digital education tools has yet to be-\ncome a reality in most countries, especially in the developing world, where it could have the most impact\nto democratize education and knowledge [Nye, 2015]. In recent years, given the increasing global shortage\nof qualiﬁed teachers along with the increasing number of students, the issue of access to education has\nbecome a global one, a fact highlighted by its presence among the UN SDGs. And yet, the usage of ML\nin the education sector has been limited to speciﬁc, narrow applications such as predicting the probability\n', 6, 0)
(110.0719985961914, 756.1516723632812, 497.9330749511719, 766.7276000976562, '4For a more extensive overview of the opportunities and challenges of using ML in healthcare, see Ghassemi et al. [2018]\n', 7, 0)
(309.6390075683594, 791.0145263671875, 314.62030029296875, 803.0194702148438, '7\n', 8, 0)

page suivante
(99.21299743652344, 100.5865478515625, 525.0443115234375, 160.4115447998047, 'of learner attrition [Chaplot et al., 2015] or improving learner evaluation [Abbott, 2006]. There are many\nreasons for this, starting from the difﬁculty in representing learning content in a domain-agnostic way to\nfacilitate scalability, to overcoming cultural and linguistic barriers to deploying tutors worldwide, but also\nmore fundamental issues such as the lack of large-scale educational datasets and the inherent technological\nconstraints in developing countries.\n', 0, 0)
(99.21299743652344, 163.3505859375, 525.0443725585938, 318.81768798828125, 'Despite these hurdles, there are many new and longstanding efforts to create intelligent tutors, be it using\nsymbolic AI approaches such as ontologies and knowledge modeling [Nkambou et al., 2010], educational\ndata mining [Dutt et al., 2017] or, more recently, ML-driven approaches [Conati et al., 2018]. However,\nthere are very high stakes in the ﬁeld, since technological interventions have the potential to make consider-\nable, long-term impact on human livelihoods, for example lifting people out of poverty by endowing them\nwith linguistic and numerical literacy, but these can be hindered by bias and technological constraints. We\ntherefore agree with recent proposals to improve and support human learning at scale and believe that ML\nhas a key role to play in this endeavour. This can be done, for instance, by partnering up with existing\neducation initiatives and organizations in order to learn what their speciﬁc needs are and how ML can be\nused to meet them, or else by collaborating with Massive Open Online Course (MOOC) creators in order\nto gather data and make it available to the ML community, and ﬁnally by sharing learning materials and\nactivities used in local education initiatives (e.g. university courses in Machine Learning) so that they proﬁt\nlearners in places where access to high-quality technical education is limited.\n', 1, 0)
(99.21299743652344, 336.0472106933594, 246.3217315673828, 351.6009216308594, '3.3\nAI for the Environment\n', 2, 0)
(99.21299743652344, 359.98675537109375, 525.0444946289062, 515.4535522460938, 'Climate change is, without a doubt, one of the biggest challenges that humanity has faced, and we are at\nan important point in history when we are both aware of the issue and still have the possibility to change\nits course. Climate change has been described as a ‘wicked’ problem, due to features such as the difﬁculty\nin deﬁning the problem itself and in developing and deploying solutions to it, the lack of central authority\nthat can solve it, the incentives for individual countries or companies to not do their share, and the cognitive\nbiases that discount the future impacts of our actions [Head et al., 2008, Levin et al., 2012]. Furthermore,\nwhile we do not know of any single technological silver bullet as solution to climate change, there are\nnonetheless numerous technical challenges for which ML can be helpful, and which can be combined to\nmake a signiﬁcant impact on the overall issue. These challenges and the ongoing ML approaches to tackle\nthem were presented in a recent survey paper [Rolnick et al., 2019]. We will not go into all of these at\nlength, but we will focus on a few examples that are particularly salient and that we hope will give an idea\nof both the relevance of deploying ML in environmental applications and the opportunities that this can\ngenerate.\n', 3, 0)
(99.21299743652344, 532.6029663085938, 215.72557067871094, 545.5642700195312, 'Energy and Transportation\n', 4, 0)
(99.21299743652344, 559.860595703125, 525.0444946289062, 766.1365356445312, 'Together, electricity and transportation systems are estimated to produce close to half of anthropogenic\ngreenhouse gas (GHG) emissions [Allen et al., 2019] and both sectors have their own unique challenges for\ndecarbonization. For instance, one of the major obstacles to building and using renewable energy sources\nsuch as solar and wind is the variability of their output, which is inherently problematic since the power\ngenerated by an energy grid must equal the power used by its consumers at any given moment. Currently,\nthis means that despite the existence of solar panels and wind turbines, these must be complemented by\ncontrollable but highly polluting energy sources such as coal and natural gas plants. ML methods that are\nappropriate for time-series predictions, such as Recurrent Neural Networks are particularly suited for these\ntypes of tasks [Voyant et al., 2017] and can dramatically lower the barrier to entry for renewable energy\nglobally. Furthermore, even in cases where controllable energy sources are used, demand on the energy\ngrid will still ﬂuctuate based on usage; in this case, ML techniques such as Reinforcement Learning and\nDynamic Scheduling can be used to balance the grid in real time [Vázquez-Canteli and Nagy, 2019].\nIn transportation, reducing activity is a key part in reducing GHG emissions; however, given the highly\nregional nature of transportation methods (i.e. high-speed trains are only an option in Europe, whereas\nmany major US cities have limited public transportation), custom solutions are needed to make a signiﬁcant\nimpact. ML can be of particular help in estimating and predicting vehicle ﬂow to minimize it, for example\nby helping to optimize the design of new roads and hubs [Sommer et al., 2017] and monitoring trafﬁc [Kaack\n', 5, 0)
(309.63897705078125, 791.0155639648438, 314.6202697753906, 803.0205078125, '8\n', 6, 0)

page suivante
(99.21299743652344, 100.5865478515625, 525.04443359375, 208.2325897216797, 'et al., 2019], as well as estimating carbon emissions in real-time [Nocera et al., 2018]. ML can also be used\nfor designing more energy-efﬁcient batteries [Hoffmann et al., 2019] which will become an increasingly\nimportant concern as more people switch to electric vehicles. In both cases of energy and transportation,\nML can be used to make systems more efﬁcient and to improve predictions of complex phenomena based\non large amounts of data; nonetheless, it remains only one part of the solution, and as tempting as it is to halt\nresearch projects once a theoretically plausible solution has been found (and a research paper published),\nwhat is key here is working with domain experts to bring projects towards deployment, where concrete\nimpact can be made. Transversal connections between disciplines are therefore key, and must be established\nand fostered for projects to ﬂourish.\n', 0, 0)
(99.21299743652344, 225.3829803466797, 204.8563995361328, 238.34432983398438, 'Individuals and Societies\n', 1, 0)
(99.21299743652344, 252.6396484375, 525.04443359375, 420.0615539550781, 'While changes in our climate can be abstract, quantiﬁed in degrees of warming or tons of CO2, climate\nchange will also have very concrete impacts on society, for instance by decreasing crop yield, increasing\nthe frequency of extreme weather events such as hurricanes and storms, and impacting biodiversity. There\nare a myriad of ways in which ML can help face these, whether it be by analyzing real-time images and\nrecordings of ecosystems to detect species [Duhart et al., 2018] and deforestation [McDowell et al., 2015],\nimproving disaster preparation and response by generating real-time maps from satellite imagery [Voigt\net al., 2007] and even setting an optimal price on carbon to accelerate the transition to a low-carbon energy\neconomy [Wei et al., 2018]. Finally, while we are far from being able to predict the exact impact that\nincreasing the carbon tax will have on the different levels of society and industry (i.e. federal and regional\ngovernments, local and international companies, and individuals), this is a worthwhile area of research and\nexploration, with potentially huge consequences in helping political leaders make more informed choices\nin addressing the climate crisis. It is therefore useful to continue gathering data and building trust between\nmembers of the political ecosystem and ML practitioners to learn from each other and to facilitate the\ndeployment of technological solutions in setting government policies.\n', 2, 0)
(99.21299743652344, 423.0006103515625, 525.04443359375, 566.5114135742188, 'On an individual level, there are many reasons why individuals cannot, or will not, act on climate change,\neither common misconceptions regarding the fact that individuals cannot make meaningful impact on a\nglobal problem, or cognitive biases that increase an individual’s psychological distance to climate change.\nIn the ﬁrst case, ML-infused tools to estimate the carbon footprint of individuals and households [Jones and\nKammen, 2011] and to model individual behavior with regards to sustainable lifestyle choices and technolo-\ngies [Carr-Cornish et al., 2011] can be very useful if they are sufﬁciently accurate and deployed on a large\nscale. Finally, minimizing psychological distance to the future effects of climate change is a promising way\nto reduce cognitive bias – in this regard, it is possible to use images generated using Generative Adversarial\nNetworks (GANs) which represent the impacts of extreme events on locations that have personal value to\nthe viewer [Schmidt et al., 2019]. A crucial part of developing ML tools for individuals is, once again,\nworking with multidisciplinary experts in psychology, scientiﬁc communication, and user design to ensure\nthat the tools created reach the largest possible audience and maximize their positive impact.\n', 3, 0)
(99.21299743652344, 586.5515747070312, 189.2928009033203, 605.2159423828125, '4\nConclusion\n', 4, 0)
(99.21299743652344, 616.3734741210938, 525.0443725585938, 724.0194091796875, 'Technology in general, and ML more speciﬁcally, carries a great potential for change and disruption. While\nneither of these is guaranteed to make the world a better place, this potential can most deﬁnitely be used\nto have a positive impact on the world. In the present article, we have illustrated some inspiring projects\nthat aim to make the world a better place and by using the powerful techniques and approaches that ML has\nbrought forward. We believe that as ML researchers and practitioners, we have the responsibility to leverage\nour (super)powers to contribute to these efforts. This can be done by connecting with established actors from\nindustry and policy or experts from other relevant disciplines, by learning from their past experiences, and\nby working together to propose innovative solutions to major problems, deployed in places where they will\nhave a positive impact.\n', 5, 0)
(99.21299743652344, 726.95849609375, 525.04443359375, 762.8734130859375, 'We live in a world with many global and local challenges and issues that are in constant evolution, and\nit is easy to be overwhelmed by this ﬂux of information and focus on a small sandbox in which we feel\nsafe and in control, in order to develop and study the aspects of ML that interest us most. But it is naive\n', 6, 0)
(309.63897705078125, 791.0155029296875, 314.6202697753906, 803.0204467773438, '9\n', 7, 0)

page suivante
(99.21299743652344, 100.5865478515625, 525.04443359375, 208.2325897216797, 'to believe that our sandbox is an isolated isle that is not connected to the rest of the world – since even in\nthe case of theoretical work, communication and cross-pollination are unavoidable – and each of us is also\na citizen who is concerned collective debates, while many of us could worry about the world in which our\ndescendants will live. We believe that there are thought processes that should take place in the head of every\nML practitioner regarding the nature of the work they are doing and the potential pitfalls and impacts of\nthis work in the world around them, some of which we have listed in the ﬁrst part of the current paper. And\nwhile we do not claim to have all the answers to all of these tough questions, we hope that we can start a\nconversation that will accompany ML research and practice throughout its infancy towards its tumultuous\nteenage years in the coming decades, and eventually towards mature adulthood beyond that.\n', 0, 0)
(99.21299743652344, 227.9347381591797, 165.865478515625, 246.59915161132812, 'References\n', 1, 0)
(99.21299743652344, 254.7686767578125, 525.0482177734375, 278.7286376953125, 'Robert G Abbott. Automated expert modeling for automated student evaluation. In International Confer-\nence on Intelligent Tutoring Systems, pages 1–10. Springer, 2006.\n', 2, 0)
(99.21296691894531, 285.898681640625, 525.0516357421875, 345.7236328125, 'M Allen, P Antwi-Agyei, F Aragon-Durand, M Babiker, P Bertoldi, M Bind, S Brown, M Buckeridge,\nI Camilloni, A Cartwright, et al. Technical summary: Global warming of 1.5c. an ipcc special report\non the impacts of global warming of 1.5c above pre-industrial levels and related global greenhouse gas\nemission pathways, in the context of strengthening the global response to the threat of climate change,\nsustainable development, and efforts to eradicate poverty, 2019.\n', 3, 0)
(99.21296691894531, 352.8936767578125, 525.0443115234375, 388.80859375, 'Julia\nAngwin,\nJeff\nLarson,\nSurya\nMattu,\nand\nLauren\nKirchner.\nMachine\nbias,\npropub-\nlica.\nhttps://www.propublica.org/article/machine-bias-risk-assessments-\nin-criminal-sentencing, 2016. Accessed: 2019-11-25.\n', 4, 0)
(99.21295166015625, 395.9786376953125, 525.050048828125, 431.8935546875, 'Filippo Arcadu, Fethallah Benmansour, Andreas Maunz, Jeff Willis, Zdenka Haskova, and Marco Prunotto.\nDeep learning algorithm predicts diabetic retinopathy progression in individual patients. NPJ digital\nmedicine, 2(1):1–9, 2019.\n', 5, 0)
(99.21293640136719, 439.0635986328125, 500.0256652832031, 451.06854248046875, 'UN General Assembly. Universal declaration of human rights. UN General Assembly, 302(2), 1948.\n', 6, 0)
(99.21295166015625, 458.23858642578125, 525.0443115234375, 494.15350341796875, 'Tolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai. Man is to\ncomputer programmer as woman is to homemaker? debiasing word embeddings. In Advances in neural\ninformation processing systems, pages 4349–4357, 2016.\n', 7, 0)
(99.21293640136719, 501.32354736328125, 525.0443115234375, 525.2835083007812, 'Joy Buolamwini and Timnit Gebru. Gender shades: Intersectional accuracy disparities in commercial gen-\nder classiﬁcation. In Conference on fairness, accountability and transparency, pages 77–91, 2018.\n', 8, 0)
(99.21292114257812, 532.4534912109375, 525.047607421875, 568.3684692382812, 'Simone Carr-Cornish, Peta Ashworth, John Gardner, and Stephen J Fraser.\nExploring the orientations\nwhich characterise the likely public acceptance of low emission energy technologies. Climatic change,\n107(3-4):549–565, 2011.\n', 9, 0)
(99.21294403076172, 575.5384521484375, 525.044189453125, 599.4984130859375, 'Devendra Singh Chaplot, Eunhee Rhim, and Jihie Kim. Predicting student attrition in moocs using senti-\nment analysis and neural networks. In AIED Workshops, volume 53, pages 54–57, 2015.\n', 10, 0)
(99.21292114257812, 606.66845703125, 525.044189453125, 630.62841796875, 'Cristina Conati, Kaska Porayska-Pomsta, and Manolis Mavrikis. Ai in education needs interpretable ma-\nchine learning: Lessons from open learner modelling. arXiv preprint arXiv:1807.00154, 2018.\n', 11, 0)
(99.21292114257812, 637.7984619140625, 525.0442504882812, 685.66845703125, 'Jeffrey Dastin. Amazon scraps secret ai recruiting tool that showed bias against women, reuters business\nnews.\nhttps://www.reuters.com/article/us-amazon-com-jobs-automation-\ninsight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-\nagainst-women-idUSKCN1MK08G, 2018. Accessed: 2019-11-25.\n', 12, 0)
(99.21290588378906, 692.8385009765625, 525.0467529296875, 728.7534790039062, 'Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical\nimage database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248–255.\nIeee, 2009.\n', 13, 0)
(99.2129135131836, 735.9235229492188, 525.0510864257812, 771.8384399414062, 'Clement Duhart, Gershon Dublon, Brian Mayton, and Joseph Paradiso.\nDeep learning locally trained\nwildlife sensing in real acoustic wetland environment. In International Symposium on Signal Processing\nand Intelligent Recognition Systems, pages 3–14. Springer, 2018.\n', 14, 0)
(307.14892578125, 791.0145263671875, 317.11151123046875, 803.0194702148438, '10\n', 15, 0)

page suivante
(99.21299743652344, 100.5865478515625, 525.0445556640625, 124.54650115966797, 'Ashish Dutt, Maizatul Akmar Ismail, and Tutut Herawan. A systematic review on educational data mining.\nIEEE Access, 5:15991–16005, 2017.\n', 0, 0)
(99.2129898071289, 132.466552734375, 525.04443359375, 156.42649841308594, 'Marzyeh Ghassemi, Tristan Naumann, Peter Schulam, Andrew L Beam, and Rajesh Ranganath. Opportu-\nnities in machine learning for healthcare. arXiv preprint arXiv:1806.00388, 2018.\n', 1, 0)
(99.21298217773438, 164.34759521484375, 525.0443115234375, 188.3075408935547, 'Jeffrey Alan Golden. Deep learning algorithms for detection of lymph node metastases from breast cancer:\nhelping artiﬁcial intelligence be seen. Jama, 318(22):2184–2186, 2017.\n', 2, 0)
(99.21299743652344, 196.22760009765625, 525.052001953125, 232.14256286621094, 'Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron\nCourville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing\nsystems, pages 2672–2680, 2014.\n', 3, 0)
(99.21299743652344, 240.06365966796875, 525.0442504882812, 264.02362060546875, 'Don W Gotterbarn, Amy Bruckman, Catherine Flick, Keith Miller, and Marty J Wolf. Acm code of ethics:\na guide for positive action, 2018.\n', 4, 0)
(99.21299743652344, 271.94366455078125, 442.1136169433594, 283.9486083984375, 'Brian W Head et al. Wicked problems in public policy. Public policy, 3(2):101, 2008.\n', 5, 0)
(99.2130126953125, 291.86865234375, 525.0487060546875, 327.78460693359375, 'Yasmeen Hitti, Eunbee Jang, Ines Moreno, and Carolyne Pelletier. Proposed taxonomy for gender bias in\ntext; a ﬁltering methodology for the gender generalization subtype. In Proceedings of the First Workshop\non Gender Bias in Natural Language Processing, pages 8–17, 2019.\n', 6, 0)
(99.2130126953125, 335.70465087890625, 525.0476684570312, 371.61956787109375, 'Jordan Hoffmann, Louis Maestrati, Yoshihide Sawada, Jian Tang, Jean Michel Sellier, and Yoshua Bengio.\nData-driven approach to encoding and decoding 3-d crystal structures. arXiv preprint arXiv:1909.00949,\n2019.\n', 7, 0)
(99.21300506591797, 379.5406188964844, 525.048583984375, 415.4555358886719, 'IEEE. Ieee standard review — ethically aligned design: A vision for prioritizing human wellbeing with\nartiﬁcial intelligence and autonomous systems. In 2017 IEEE Canada International Humanitarian Tech-\nnology Conference (IHTC), pages 197–201. IEEE, 2017.\n', 8, 0)
(99.21300506591797, 423.3755798339844, 525.0443725585938, 447.33551025390625, 'Anna Jobin, Marcello Ienca, and Effy Vayena. Artiﬁcial intelligence: the global landscape of ethics guide-\nlines. arXiv preprint arXiv:1906.11668, 2019.\n', 9, 0)
(99.2130126953125, 455.2565612792969, 525.0441284179688, 479.21649169921875, 'Christopher M Jones and Daniel M Kammen. Quantifying carbon footprint reduction opportunities for us\nhouseholds and communities. Environmental science & technology, 45(9):4088–4095, 2011.\n', 10, 0)
(99.2130126953125, 487.13653564453125, 525.0443115234375, 511.0964660644531, 'Lynn H Kaack, George H Chen, and M Granger Morgan. Truck trafﬁc monitoring with satellite images. In\nProceedings of the Conference on Computing & Sustainable Societies, pages 155–164. ACM, 2019.\n', 11, 0)
(99.2130126953125, 519.0175170898438, 525.0442504882812, 542.9774780273438, 'Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner, et al.\nGradient-based learning applied to\ndocument recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.\n', 12, 0)
(99.2130126953125, 550.8974609375, 525.0444946289062, 586.8124389648438, 'Kelly Levin, Benjamin Cashore, Steven Bernstein, and Graeme Auld. Overcoming the tragedy of super\nwicked problems: constraining our future selves to ameliorate global climate change. Policy sciences, 45\n(2):123–152, 2012.\n', 13, 0)
(99.2130355834961, 594.7334594726562, 525.0516967773438, 642.6033935546875, 'Nate G McDowell, Nicholas C Coops, Pieter SA Beck, Jeffrey Q Chambers, Chandana Gangodagamage,\nJeffrey A Hicke, Cho-ying Huang, Robert Kennedy, Dan J Krofcheck, Marcy Litvak, et al.\nGlobal\nsatellite monitoring of climate-induced vegetation disturbances. Trends in plant science, 20(2):114–123,\n2015.\n', 14, 0)
(99.2130355834961, 650.5244750976562, 525.0477294921875, 674.4844360351562, 'Roger Nkambou, Riichiro Mizoguchi, and Jacqueline Bourdeau. Advances in intelligent tutoring systems,\nvolume 308. Springer Science & Business Media, 2010.\n', 15, 0)
(99.21306610107422, 682.4044799804688, 525.0477294921875, 718.3193969726562, 'Silvio Nocera, Cayetano Ruiz-Alarcón-Quintero, and Federico Cavallaro. Assessing carbon emissions from\nroad transport through trafﬁc ﬂow estimators. Transportation Research Part C: Emerging Technologies,\n95:125–148, 2018.\n', 16, 0)
(99.21306610107422, 726.240478515625, 525.046875, 762.1553955078125, 'Benjamin D Nye. Intelligent tutoring systems by and for the developing world: A review of trends and\napproaches for educational technology in a global context. International Journal of Artiﬁcial Intelligence\nin Education, 25(2):177–203, 2015.\n', 17, 0)
(307.1490478515625, 791.0155029296875, 317.11163330078125, 803.0204467773438, '11\n', 18, 0)

page suivante
(99.21299743652344, 100.5865478515625, 525.0471801757812, 136.5015106201172, 'I Perisic.\nHow artiﬁcial intelligence is shaking up the job market.\nhttps://www.weforum.org/\nagenda/2018/09/artificial-intelligence-shaking-up-job-market/, 2018. Ac-\ncessed: 2019-11-25.\n', 0, 0)
(99.21297454833984, 143.89556884765625, 525.0443115234375, 179.81150817871094, 'Rimma Pivovarov, Adler J Perotte, Edouard Grave, John Angiolillo, Chris H Wiggins, and Noémie Elhadad.\nLearning probabilistic phenotypes from heterogeneous ehr data. Journal of biomedical informatics, 58:\n156–165, 2015.\n', 1, 0)
(99.21297454833984, 187.20556640625, 525.04931640625, 223.1215057373047, 'Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. Why should i trust you?: Explaining the predic-\ntions of any classiﬁer. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge\ndiscovery and data mining, pages 1135–1144. ACM, 2016.\n', 2, 0)
(99.21297454833984, 230.51556396484375, 525.0517578125, 266.4305419921875, 'David Rolnick, Priya L Donti, Lynn H Kaack, Kelly Kochanski, Alexandre Lacoste, Kris Sankaran, An-\ndrew Slavin Ross, Nikola Milojevic-Dupont, Natasha Jaques, Anna Waldman-Brown, Alexandra Luc-\ncioni, et al. Tackling climate change with machine learning. arXiv preprint arXiv:1906.05433, 2019.\n', 3, 0)
(99.21295166015625, 273.82562255859375, 525.0469970703125, 309.7406005859375, 'RSS.\nA guide for ethical data science.\nhttps://www.actuaries.org.uk/system/files/\nfield/document/An%20Ethical%20Charter%20for%20Date%20Science%20WEB%\n20FINAL.PDF., 2019. Accessed: 2019-11-25.\n', 4, 0)
(99.21297454833984, 317.13568115234375, 525.0515747070312, 353.05059814453125, 'Victor Schmidt, Alexandra Luccioni, S Karthik Mukkavilli, Narmada Balasooriya, Kris Sankaran, Jennifer\nChayes, and Yoshua Bengio. Visualizing the consequences of climate change using cycle-consistent\nadversarial networks. arXiv preprint arXiv:1905.03709, 2019.\n', 5, 0)
(99.21295166015625, 360.44464111328125, 525.0496215820312, 396.3605651855469, 'Lars Wilko Sommer, Tobias Schuchert, and Jürgen Beyerer. Fast deep vehicle detection in aerial images.\nIn 2017 IEEE Winter Conference on Applications of Computer Vision (WACV), pages 311–319. IEEE,\n2017.\n', 6, 0)
(99.21294403076172, 403.7546081542969, 525.0494995117188, 415.7595520019531, 'Patrick Suppes and Mona Morningstar. Computer-assisted instruction. Science, 166(3903):343–350, 1969.\n', 7, 0)
(99.21295166015625, 423.0545959472656, 525.05224609375, 459.06951904296875, 'M Szczepa´nski.\nEconomic impacts of artiﬁcial intelligence (ai), european parliamentary research ser-\nvice, pe 637.967. http://europarl.europa.eu/RegData/etudes/BRIE/2019/637967/\nEPRS_BRI(2019)637967_EN.pdf, 2019. Accessed: 2019-11-25.\n', 8, 0)
(99.21293640136719, 466.46356201171875, 525.0474243164062, 490.42449951171875, 'UNHCR.\nThe\nsustainable\ndevelopment\ngoals\nand\naddressing\nstatelessness.\nhttps://\nwww.refworld.org/docid/58b6e3364.html, 2017. Accessed: 2019-11-25.\n', 9, 0)
(99.21295166015625, 497.81854248046875, 525.0443115234375, 521.7785034179688, 'José R Vázquez-Canteli and Zoltán Nagy.\nReinforcement learning for demand response: A review of\nalgorithms and modeling techniques. Applied energy, 235:1072–1089, 2019.\n', 10, 0)
(99.21295166015625, 529.1735229492188, 525.0510864257812, 565.0884399414062, 'Stefan Voigt, Thomas Kemper, Torsten Riedlinger, Ralph Kieﬂ, Klaas Scholte, and Harald Mehl. Satellite\nimage analysis for disaster and crisis-management support. IEEE transactions on geoscience and remote\nsensing, 45(6):1520–1528, 2007.\n', 11, 0)
(99.21295928955078, 572.4824829101562, 525.047607421875, 608.3984375, 'Cyril Voyant, Gilles Notton, Soteris Kalogirou, Marie-Laure Nivet, Christophe Paoli, Fabrice Motte, and\nAlexis Fouilloy. Machine learning methods for solar radiation forecasting: A review. Renewable Energy,\n105:569–582, 2017.\n', 12, 0)
(99.21294403076172, 615.79248046875, 525.0516357421875, 651.7074584960938, 'Sun Wei, Zhang Chongchong, and Sun Cuiping. Carbon pricing prediction based on wavelet transform\nand k-elm optimized by bat optimization algorithm in china ets: the case of shanghai and hubei carbon\nmarkets. Carbon Management, 9(6):605–617, 2018.\n', 13, 0)
(99.21293640136719, 659.1024780273438, 525.0443115234375, 695.0173950195312, 'James Wexler, Mahima Pushkarna, Tolga Bolukbasi, Martin Wattenberg, Fernanda Viégas, and Jimbo Wil-\nson. The what-if tool: Interactive probing of machine learning models. IEEE transactions on visualiza-\ntion and computer graphics, 26(1):56–65, 2019.\n', 14, 0)
(99.21293640136719, 702.4124755859375, 525.0518188476562, 738.3274536132812, 'Jenna Wiens, Suchi Saria, Mark Sendak, Marzyeh Ghassemi, Vincent X Liu, Finale Doshi-Velez, Kenneth\nJung, Katherine Heller, David Kale, Mohammed Saeed, et al. Do no harm: a roadmap for responsible\nmachine learning for health care. Nature medicine, 25(9):1337–1340, 2019.\n', 15, 0)
(99.21295166015625, 745.7214965820312, 525.0441284179688, 769.6824340820312, 'Rich Zemel, Yu Wu, Kevin Swersky, Toni Pitassi, and Cynthia Dwork. Learning fair representations. In\nInternational Conference on Machine Learning, pages 325–333, 2013.\n', 16, 0)
(307.1489562988281, 791.0155029296875, 317.1115417480469, 803.0204467773438, '12\n', 17, 0)

page suivante
