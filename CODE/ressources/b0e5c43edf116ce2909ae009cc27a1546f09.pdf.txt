(89.77999877929688, 804.5470581054688, 503.2516174316406, 823.801513671875, 'Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,\npages 1025–1036, Dublin, Ireland, August 23-29 2014.\n', 0, 0)
(79.85900115966797, 67.63768005371094, 517.6908569335938, 86.30208587646484, 'Inclusive yet Selective: Supervised Distributional Hypernymy Detection\n', 1, 0)
(180.06600952148438, 97.65606689453125, 416.9788818359375, 113.20977783203125, 'Stephen Roller∗, Katrin Erk†, Gemma Boleda†\n', 2, 0)
(123.03197479248047, 107.6954574584961, 474.5151672363281, 181.81446838378906, '∗ Department of Computer Science\n† Department of Linguistics\nThe University of Texas at Austin\nroller@cs.utexas.edu, katrin.erk@mail.utexas.edu,\ngemma.boleda@upf.edu\n', 3, 0)
(276.5299987792969, 206.61212158203125, 321.0152893066406, 222.16583251953125, 'Abstract\n', 4, 0)
(89.00899505615234, 232.53810119628906, 508.5403137207031, 299.8805847167969, 'We test the Distributional Inclusion Hypothesis, which states that hypernyms tend to occur in\na superset of contexts in which their hyponyms are found. We ﬁnd that this hypothesis only\nholds when it is applied to relevant dimensions. We propose a robust supervised approach that\nachieves accuracies of .84 and .85 on two existing datasets and that can be interpreted as selecting\nthe dimensions that are relevant for distributional inclusion.\n', 5, 0)
(72.0009994506836, 310.26513671875, 154.81468200683594, 325.81884765625, '1\nIntroduction\n', 6, 0)
(72.00093841552734, 333.1351013183594, 525.55029296875, 726.3355712890625, 'One of the main criticisms of distributional models has been that they fail to distinguish between semantic\nrelations: Typical nearest neighbors of dog are words like cat, animal, puppy, tail, or owner, all obviously\nrelated to dog, but through very different types of semantic relations. On these grounds, Murphy (2002)\nargues that distributional models cannot be a valid model of conceptual representation. Distinguishing\nsemantic relations are also crucial for drawing inferences from distributional data, as different semantic\nrelations lead to different inference rules (Lenci, 2008). This is of practical import for tasks such as\nRecognizing Textual Entailment or RTE (Geffet and Dagan, 2004).\nFor these reasons, research has in recent years started to attempt the detection of speciﬁc semantic\nrelationships, and current results suggest that distributional models can, in fact, distinguish between\nsemantic relations, given the right similarity measures (Weeds et al., 2004; Kotlerman et al., 2010; Lenci\nand Benotto, 2012; Herbelot and Ganesalingam, 2013; Santus, 2013). Because of its relevance for RTE\nand other tasks, much of this work has focused on hypernymy. Hypernymy is the semantic relation\nbetween a superordinate term in a taxonomy (e.g. animal) and a subordinate term (e.g. dog).\nDistributional approaches to date for detecting hypernymy, and the related but broader relation of\nlexical entailment, have been unsupervised (except for Baroni et al. (2012)) and have mostly been based\non the Distributional Inclusion Hypothesis (Zhitomirsky-Geffet and Dagan, 2005; Zhitomirsky-Geffet\nand Dagan, 2009), which states that more speciﬁc terms appear in a subset of the distributional contexts\nin which more general terms appear. So, animal can occur in all the contexts in which dog can occur,\nplus some contexts in which dog cannot – for instance, rights can be a typical cooccurrence for animal\n(e.g. “animal rights”), but not so much for dog (e.g. #“dog rights”).\nThis paper takes a closer look at the Distributional Inclusion Hypothesis for hypernymy detection. We\nshow that the current best unsupervised approach is brittle in that their performance depends on the space\nthey are applied to. This raises the question of whether the Distributional Inclusion Hypothesis is correct,\nand if so, under what circumstances it holds. We use a simple supervised approach to relation detection\nthat has good performance (accuracy .84 on BLESS, .85 on the lexical entailment dataset of Baroni et\nal. (2012)) and works well across different spaces.1 Furthermore, we show that it can be interpreted\nas selecting dimensions for which the Distributional Inclusion Hypothesis does hold. So, our answer is\nto propose the Selective Distributional Inclusion Hypothesis: The Distributional Inclusion Hypothesis\nholds, but only for relevant dimensions.\n', 7, 0)
(72.0009994506836, 733.8430786132812, 525.540771484375, 765.4845581054688, 'This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer\nare added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/\n1Code and data are available at http://stephenroller.com/research/coling14.\n', 8, 0)
(287.8630065917969, 786.9010009765625, 309.6812438964844, 800.0464477539062, '1025\n', 9, 0)

page suivante
(72.0009994506836, 62.2890625, 152.8301239013672, 77.8427734375, '2\nBackground\n', 0, 0)
(72.00099182128906, 83.89933776855469, 525.5474853515625, 165.18356323242188, 'Distributional models.\nDistributional models represent a word through the contexts in which it has\nbeen observed, usually in the form of a vector representation (Turney and Pantel, 2010). A target word\nis represented as a vector in a high-dimensional space in which the dimensions are context items (for\nexample, other words) and the coordinates of the vector indicate the target’s degree of association with\neach context item. In this paper, we also use dimensionality reduced spaces in which dimensions do not\nstand for individual context items anymore.\n', 1, 0)
(72.00098419189453, 172.25035095214844, 525.5466918945312, 294.1825866699219, 'Pattern-based approaches to inducing semantic relations.\nEarly work on automatically inducing se-\nmantic relations between words, starting with Hearst (1992), uses textual patterns. For example, “[NP1]\nand other [NP2]” implies that NP2 is a hypernym of NP1. Pattern-based approaches have been applied\nto meronymy (Berland and Charniak, 1999; Girju et al., 2003; Girju et al., 2006), synonymy (Lin et al.,\n2003), co-hyponymy (Snow et al., 2005), hypernymy (Cimiano et al., 2005), and several relations be-\ntween verbs (Chklovski and Pantel, 2004). Pantel and Pennachiotti (2006) generalize the idea to a wide\nvariety of relations. Turney (2006) uses vectors of patterns to determine similarity of semantic relations.\nA task related to semantic relation induction is the extension of an existing taxonomy (Buitelaar et al.,\n2005). Snow et al. (2006) do this by using hypernymy and co-hyponymy detectors.\n', 2, 0)
(72.00098419189453, 301.2493591308594, 525.5498046875, 518.025634765625, 'Lexical entailment, hypernymy, and the Distributional Inclusion Hypothesis.\nWeeds et al. (2004)\nintroduce the notion of distributional generality, where v is distributionally more general than u if u\nappears in a subset of the contexts in which v is found, and speculate that hypernyms (v) should be more\ndistributionally general than hyponyms (u). Zhitomirsky-Geffet and Dagan (2005; 2009) introduce the\nterm Distributional Inclusion Hypothesis for the idea that distributional generality encodes hypernymy\nor the more loosely deﬁned relation of lexical entailment.\nWeeds and Weir (2003) measure distributional generality using a notion of precision (eq. 1). Here and\nin all equations below, u is the narrower term, and v the more general one. Abusing notation, we write u\nfor both a word and its associated vector ⟨u1, . . . , un⟩. Kotlerman et al. (2010) predict lexical entailment\nwith the balAPinc measure, a modiﬁcation of the Average Precision (AP) measure (eq. 2). The general\nnotion is that scores should increase with the number of dimensions of v that u shares, and also give more\nweight to the highly ranked dimensions (i.e. largest magnitude) of the narrower term u. This is captured\nin APinc by computing precision P(r) at every rank r among u’s dimensions – where precision is the\nfraction of dimensions shared with v –, and weighting by the rank of the same dimension in the broader\nterm, rel′(v, r, u). The ﬁnal measure, balAPinc, smooths using the LIN similarity measure (Lin, 1998).\n(We only sketch this measure here due to its complexity; details are given in Kotlerman et al. (2010).)\n', 3, 0)
(245.66912841796875, 538.0252685546875, 277.3647766113281, 551.323486328125, '1(x) =\n', 4, 0)
(280.38812255859375, 521.5203857421875, 339.7726745605469, 562.233154296875, '(\n1 if x > 0;\n0 otherwise\n', 5, 0)
(215.69512939453125, 553.1163940429688, 525.5440063476562, 608.7919921875, 'WeedsPrec(u, v) =\nPn\ni=1 ui · 1(vi)\nPn\ni=1 ui\n(1)\n', 6, 0)
(204.0880126953125, 592.4092407226562, 392.2643127441406, 633.1220092773438, 'APinc(u, v) =\nP|1(u)|\nr=1 P(r) · rel′(v, r, u))\n', 7, 0)
(319.1880187988281, 606.3130493164062, 525.5440063476562, 634.3487548828125, '|1(u)|\n(2)\n', 8, 0)
(201.19500732421875, 630.7492065429688, 292.5101013183594, 671.4619750976562, 'balAPinc(u, v) =\np\n', 9, 0)
(292.510009765625, 638.4600830078125, 396.3516845703125, 659.5037231445312, 'APinc(u, v) · LIN(u, v)\n', 10, 0)
(72.00102996826172, 658.0400390625, 525.5505981445312, 766.0304565429688, 'The ClarkeDE measure (Clarke, 2009) computes degree of entailment as the degree to which the nar-\nrower term u has lower values than v across all dimensions (eq. 3). Lenci and Benotto (2012) introduce\nthe invCL measure, which uses ClarkeDE to measure both distributional inclusion of u in v and distri-\nbutional non-inclusion of v in u (eq. 4). While all other measures interpret the Distributional Inclusion\nHypothesis as the degree to which a ⊆ relation holds, Lenci and Benotto test the degree to which proper\ninclusion ⊊ holds. They consider not only the degree to which the contexts of the narrower terms are\nincluded in the contexts of the wider term, but also determine the degree to which the wider term has\ncontexts that the narrower term does not have.\n', 11, 0)
(287.8630065917969, 786.9010009765625, 309.6812438964844, 800.0464477539062, '1026\n', 12, 0)

page suivante
(232.63600158691406, 69.39823913574219, 525.5440063476562, 125.07395935058594, 'CL(u, v) =\nPn\ni=1 min(ui, vi)\nPn\ni=1 ui\n(3)\n', 0, 0)
(202.91799926757812, 115.72526550292969, 281.07708740234375, 156.4380340576172, 'invCL(u, v) =\np\n', 1, 0)
(281.0769958496094, 123.43610382080078, 525.5440063476562, 144.47975158691406, 'CL(u, v) · (1 − CL(v, u))\n(4)\n', 2, 0)
(72.0009994506836, 148.1230010986328, 525.546875, 243.49050903320312, 'Like Lenci and Benotto, we focus on the stricter hypernymy relation, rather than lexical entailment.\nWe believe that the different relations that make up lexical entailment have different distributional indi-\ncations and that, for that reason, it will be easier to detect the relations separately than together.\nBaroni et al. (2012) proposes a supervised approach to hypernymy detection that represents two words\nas the concatenation of their vectors. They also mention in passing another supervised approach that\nrepresents two words as the component-wise difference of their vectors. These are broadly the two\napproaches that we test, though we introduce signiﬁcant modiﬁcations.\n', 3, 0)
(72.0009994506836, 255.924072265625, 114.5017318725586, 271.477783203125, '3\nData\n', 4, 0)
(72.0009994506836, 280.1383361816406, 229.16842651367188, 294.3310852050781, '3.1\nDistributional Vector Spaces\n', 5, 0)
(72.0009994506836, 299.84808349609375, 299.9574890136719, 312.9935607910156, 'We use three standard types of distributional spaces.\n', 6, 0)
(72.0009994506836, 323.5783386230469, 525.5468139648438, 418.4115905761719, 'U+W2:\nThis space is based on a concatenation of the Gigaword, BNC, English Wackypedia and\nukWaC corpora (Baroni et al., 2009). The corpora are POS-tagged and lemmatized. We keep only\ncontent words (nouns, proper nouns, adjectives and verbs) with a corpus frequency of 500 or larger. The\nresulting U+ corpus has roughly 133K word types and 2.8B word tokens. We created a vector space by\ncounting co-occurrences of these word types within a window of two words on the left and the right,\nusing the top 20k most frequent content words as dimensions. The space was transformed using Positive\nPointwise Mutual Information (PPMI).\n', 7, 0)
(72.0009994506836, 428.9963684082031, 525.5460205078125, 456.0845642089844, 'U+Sent:\nThe U+Sent space is constructed the same way as U+W2, but uses full sentence contexts\ninstead of 2-word windows.\n', 8, 0)
(72.00096893310547, 466.6693420410156, 525.546630859375, 547.9535522460938, 'TypeDM:\nThis space is extracted from the TypeDM tensors (Baroni and Lenci, 2011). TypeDM con-\ntains a list of weighted tuples, ⟨⟨w1, l, w2⟩, σ⟩, where w1 and w2 are content words, l is a corpus-derived\nsyntagmatic relationship between the words, and σ is a weight estimating saliency of the relationship. We\nconstruct vectors for every unique w1 using the set of ⟨l, w2⟩ pairs as dimensions and corresponding σ\nvalues as dimension weights. We select TypeDM for its excellent performance in previous comparisons\nof distributional hypernymy measures (Lenci and Benotto, 2012).\n', 9, 0)
(72.00096130371094, 558.5383911132812, 525.5486450195312, 626.836669921875, 'Reduced Spaces:\nIn some experiments, we use dimensionality reduced spaces. We reduce all three\nspaces to 300 dimensions using Singular Value Decomposition. We use a subscript to denote reduced\nspaces, e.g. U+W2300. When necessary, we use the term original dimensions to refer to the vector\ndimensions from the original, non-reduced spaces (e.g. U+W2); the term latent dimensions refers to the\ndimensions in the reduced spaces (e.g. U+W2300).\n', 10, 0)
(72.0009536743164, 638.3313598632812, 194.01925659179688, 652.5241088867188, '3.2\nEvaluation Data Sets\n', 11, 0)
(72.00093841552734, 657.6473999023438, 525.54833984375, 766.030517578125, 'BLESS:\nThe BLESS data set (Baroni and Lenci, 2011) covers 200 concepts, or concrete and unambigu-\nous terms (divided into 17 different general concept classes, including vehicle and ground mammal), and\ntheir relationships to other nouns, called relata. Example concepts include van and horse. Each concept\nis related to several relata through different semantic relations. Following Lenci and Benotto (2012), we\nfocus on the four semantic relations where both concepts and relata are nouns, for a total 14K data points:\nHypernymy, denoting a superset relationship (e.g. animal-dog); Co-hyponymy, denoting words that share\na common hypernym (e.g. dog-cat); Meronymy, denoting a part-whole relationship (e.g. tail-dog); and\nRandom, denoting no relationship between the words (e.g. dog-computer).\n', 12, 0)
(287.8630065917969, 786.9010009765625, 309.6812438964844, 800.0464477539062, '1027\n', 13, 0)

page suivante
(118.39314270019531, 144.8934783935547, 120.74099731445312, 147.8616943359375, 'G\n', 0, 0)
(118.39314270019531, 134.44175720214844, 120.74099731445312, 139.98007202148438, 'G\nG\n', 1, 0)
(118.39314270019531, 82.58130645751953, 120.74099731445312, 85.54951477050781, 'G\n', 2, 0)
(118.39314270019531, 153.42518615722656, 120.74099731445312, 156.39340209960938, 'G\n', 3, 0)
(118.39314270019531, 82.55610656738281, 120.74099731445312, 85.5243148803711, 'G\n', 4, 0)
(118.39314270019531, 141.52716064453125, 120.74099731445312, 144.49537658691406, 'G\n', 5, 0)
(118.39314270019531, 149.96815490722656, 120.74099731445312, 152.93637084960938, 'G\n', 6, 0)
(118.39314270019531, 84.41061401367188, 120.74099731445312, 87.37882232666016, 'G\n', 7, 0)
(118.39314270019531, 153.9996795654297, 120.74099731445312, 156.9678955078125, 'G\n', 8, 0)
(118.39314270019531, 84.0729751586914, 120.74099731445312, 87.46952819824219, 'GG\n', 9, 0)
(118.39314270019531, 173.88514709472656, 120.74099731445312, 176.85336303710938, 'G\n', 10, 0)
(118.39314270019531, 82.76272583007812, 120.74099731445312, 85.7309341430664, 'G\n', 11, 0)
(198.93283081054688, 113.52826690673828, 201.2806854248047, 116.49647521972656, 'G\n', 12, 0)
(198.93283081054688, 119.17742919921875, 201.2806854248047, 122.14563751220703, 'G\n', 13, 0)
(198.93283081054688, 131.21653747558594, 201.2806854248047, 134.18475341796875, 'G\n', 14, 0)
(198.93283081054688, 136.8203582763672, 201.2806854248047, 139.78857421875, 'G\n', 15, 0)
(198.93283081054688, 122.74028778076172, 201.2806854248047, 125.70849609375, 'G\n', 16, 0)
(198.93283081054688, 134.1041259765625, 201.2806854248047, 137.0723419189453, 'G\n', 17, 0)
(198.93283081054688, 108.95752716064453, 201.2806854248047, 111.92573547363281, 'G\n', 18, 0)
(198.93283081054688, 120.56326293945312, 201.2806854248047, 123.5314712524414, 'G\n', 19, 0)
(198.93283081054688, 136.70445251464844, 201.2806854248047, 139.67266845703125, 'G\n', 20, 0)
(89.9406967163086, 184.66908264160156, 99.88846588134766, 191.5932159423828, '−1.5\n', 21, 0)
(89.9406967163086, 167.2882080078125, 99.88846588134766, 174.21234130859375, '−1.0\n', 22, 0)
(89.9406967163086, 149.9022674560547, 99.88846588134766, 156.82640075683594, '−0.5\n', 23, 0)
(92.88370513916016, 132.51634216308594, 99.88846588134766, 139.4404754638672, '0.0\n', 24, 0)
(92.88370513916016, 115.13544464111328, 99.88846588134766, 122.05958557128906, '0.5\n', 25, 0)
(92.88370513916016, 97.74951934814453, 99.88846588134766, 104.67366027832031, '1.0\n', 26, 0)
(92.88370513916016, 80.36358642578125, 99.88846588134766, 87.28772735595703, '1.5\n', 27, 0)
(110.88948059082031, 195.26695251464844, 209.6314697265625, 202.1910858154297, 'Co−hyp\nHyper\nMero\nRandom\n', 28, 0)
(81.62568664550781, 134.6127471923828, 89.93464660644531, 137.63638305664062, 'z\n', 29, 0)
(139.03453063964844, 69.35753631591797, 180.64585876464844, 79.05132293701172, 'U+W2, invCL\n', 30, 0)
(266.25714111328125, 161.2009735107422, 268.60498046875, 164.169189453125, 'G\n', 31, 0)
(266.25714111328125, 177.8813934326172, 268.60498046875, 180.849609375, 'G\n', 32, 0)
(266.25714111328125, 158.79718017578125, 268.60498046875, 163.1411590576172, 'GG\n', 33, 0)
(266.25714111328125, 168.9364471435547, 268.60498046875, 171.9046630859375, 'G\n', 34, 0)
(266.25714111328125, 174.0665740966797, 268.60498046875, 177.0347900390625, 'G\n', 35, 0)
(266.25714111328125, 179.75604248046875, 268.60498046875, 182.72425842285156, 'G\n', 36, 0)
(266.25714111328125, 157.3861541748047, 268.60498046875, 160.3543701171875, 'G\n', 37, 0)
(319.95196533203125, 174.36892700195312, 322.2998046875, 177.84107971191406, 'GG\n', 38, 0)
(319.95196533203125, 182.7998504638672, 322.2998046875, 188.70098876953125, 'G\nG\n', 39, 0)
(319.95196533203125, 175.70941162109375, 322.2998046875, 178.67762756347656, 'G\n', 40, 0)
(237.8046875, 184.66908264160156, 322.2998046875, 191.5932159423828, 'G\n−1.5\n', 41, 0)
(237.8046875, 167.2882080078125, 247.75247192382812, 174.21234130859375, '−1.0\n', 42, 0)
(237.8046875, 149.9022674560547, 247.75247192382812, 156.82640075683594, '−0.5\n', 43, 0)
(240.74769592285156, 132.51634216308594, 247.75247192382812, 139.4404754638672, '0.0\n', 44, 0)
(240.74769592285156, 115.13544464111328, 247.75247192382812, 122.05958557128906, '0.5\n', 45, 0)
(240.74769592285156, 97.74951934814453, 247.75247192382812, 104.67366027832031, '1.0\n', 46, 0)
(240.74769592285156, 80.36358642578125, 247.75247192382812, 87.28772735595703, '1.5\n', 47, 0)
(258.75347900390625, 195.26695251464844, 357.4954833984375, 202.1910858154297, 'Co−hyp\nHyper\nMero\nRandom\n', 48, 0)
(229.48968505859375, 134.6127471923828, 237.79864501953125, 137.63638305664062, 'z\n', 49, 0)
(284.93316650390625, 69.35753631591797, 330.4742126464844, 79.05132293701172, 'U+Sent, invCL\n', 50, 0)
(440.9660339355469, 156.68063354492188, 443.3138732910156, 164.93014526367188, 'GG\nG\n', 51, 0)
(440.9660339355469, 173.09396362304688, 443.3138732910156, 176.0621795654297, 'G\n', 52, 0)
(440.9660339355469, 178.48611450195312, 443.3138732910156, 181.45433044433594, 'G\n', 53, 0)
(440.9660339355469, 151.3842315673828, 443.3138732910156, 157.6381378173828, 'G\nG\n', 54, 0)
(440.9660339355469, 158.8475799560547, 443.3138732910156, 161.8157958984375, 'G\n', 55, 0)
(440.9660339355469, 150.608154296875, 443.3138732910156, 154.31716918945312, 'GG\n', 56, 0)
(440.9660339355469, 159.69419860839844, 443.3138732910156, 162.66241455078125, 'G\n', 57, 0)
(440.9660339355469, 148.76878356933594, 443.3138732910156, 151.73699951171875, 'G\n', 58, 0)
(440.9660339355469, 163.1663360595703, 443.3138732910156, 166.13455200195312, 'G\n', 59, 0)
(440.9660339355469, 170.62464904785156, 443.3138732910156, 173.59286499023438, 'G\n', 60, 0)
(440.9660339355469, 176.127685546875, 443.3138732910156, 179.0959014892578, 'G\n', 61, 0)
(440.9660339355469, 168.99693298339844, 443.3138732910156, 171.96514892578125, 'G\n', 62, 0)
(440.9660339355469, 153.0018768310547, 443.3138732910156, 155.9700927734375, 'G\n', 63, 0)
(467.8159484863281, 84.05281066894531, 470.1637878417969, 91.07270050048828, 'G\nG\nG\n', 64, 0)
(494.66082763671875, 119.99884796142578, 497.0086669921875, 122.96705627441406, 'G\n', 65, 0)
(494.66082763671875, 101.1111831665039, 497.0086669921875, 108.32256317138672, 'G\nG\nG\n', 66, 0)
(494.66082763671875, 118.04356384277344, 497.0086669921875, 125.36077117919922, 'G\nGG\n', 67, 0)
(494.66082763671875, 88.01881408691406, 497.0086669921875, 90.98702239990234, 'G\n', 68, 0)
(494.66082763671875, 133.74632263183594, 497.0086669921875, 136.71453857421875, 'G\n', 69, 0)
(494.66082763671875, 116.10340118408203, 497.0086669921875, 123.65745544433594, 'GG\nG\n', 70, 0)
(494.66082763671875, 95.38642120361328, 497.0086669921875, 98.35462951660156, 'G\n', 71, 0)
(385.668701171875, 184.66908264160156, 395.6164855957031, 191.5932159423828, '−1.5\n', 72, 0)
(385.668701171875, 167.2882080078125, 395.6164855957031, 174.21234130859375, '−1.0\n', 73, 0)
(385.668701171875, 149.9022674560547, 395.6164855957031, 156.82640075683594, '−0.5\n', 74, 0)
(388.6116943359375, 132.51634216308594, 395.6164855957031, 139.4404754638672, '0.0\n', 75, 0)
(388.6116943359375, 115.13544464111328, 395.6164855957031, 122.05958557128906, '0.5\n', 76, 0)
(388.6116943359375, 97.74951934814453, 395.6164855957031, 104.67366027832031, '1.0\n', 77, 0)
(388.6116943359375, 80.36358642578125, 395.6164855957031, 87.28772735595703, '1.5\n', 78, 0)
(406.6174621582031, 195.26695251464844, 505.3594665527344, 202.1910858154297, 'Co−hyp\nHyper\nMero\nRandom\n', 79, 0)
(377.3536682128906, 134.6127471923828, 385.6626281738281, 137.63638305664062, 'z\n', 80, 0)
(431.7539978027344, 69.35753631591797, 479.3763427734375, 79.05132293701172, 'TypeDM, invCL\n', 81, 0)
(72.00100708007812, 226.35401916503906, 525.5432739257812, 253.04849243164062, 'Figure 1: Distributions of relata invCL scores for the U+W2, U+Sent, and TypeDM spaces for each of\nthe semantic relations, after per-concept z-normalization.\n', 82, 0)
(72.00094604492188, 274.0102844238281, 525.5469360351562, 341.7455139160156, 'ENTAILMENT:\n(Baroni et al., 2012): The ENTAILMENT data set consists of 2,770 word pairs, bal-\nanced between positive (house-building) and negative (leader-rider) examples of hypernymy, with 1376\nunique hyponyms and 1016 unique hypernyms. The positive examples were generated by selecting direct\nhypernym relationships from WordNet, the negative examples by randomly permuting the hypernyms of\nthe positive examples, and then manually checking correctness.\n', 83, 0)
(72.00094604492188, 353.14007568359375, 283.7753601074219, 368.69378662109375, '4\nDistributional Inclusion across Spaces\n', 84, 0)
(72.00094604492188, 377.0040588378906, 525.546630859375, 485.6205749511719, 'We test several unsupervised distributional approaches to hypernymy detection from the literature, fo-\ncusing on the underlying vector space representation as the main parameter that we vary. We use the\nthree spaces described in Section 3. We test four hypernymy detection approaches, all of them similarity\nmeasures based on the Distributional Inclusion Hypothesis: WeedsPrec, balAPinc, ClarkeDE, and invCL.\nOur baseline is the standard cosine measure. We evaluate on the BLESS dataset.\nTo evaluate on BLESS, we follow the evaluation scheme laid out in Baroni and Lenci (2011). Given a\nspace and similarity measure, we compute similarity for each concept and relatum. For each concept, we\nselect its nearest neighbors (according to the given similarity measure) in each of the four relations (CO-\n', 85, 0)
(72.00100708007812, 486.02410888671875, 525.547119140625, 744.30859375, 'HYP, HYPER, MERO, RANDOM), and transform the corresponding four similarities to z-scores. Across\nall concepts, this yields four sets of z-normalized similarity scores, one for each relation. These four sets\ndescribe the relative similarity of concepts to their nearest neighbors in different relations. Tukey’s Hon-\nestly Signiﬁcant Difference test is used for testing whether scores differ signiﬁcantly between relations\n(threshold: p < 0.05).\nFigure 1 shows the distributions of z-scores for invCL for the four relations, with one graph for each\nof the three spaces we consider. For this illustration, we focus on invCL because it shows the overall best\nperformance at identifying hypernymy. The rightmost plot in Figure 1 replicates the analysis of Lenci\nand Benotto (2012), who used the TypeDM space. It conﬁrms their ﬁnding that invCL gives signiﬁcantly\nhigher values to hypernyms than co-hyponyms – at least on this space. However, in the U+W2 and\nU+Sent spaces (leftmost and middle plot), invCL clearly loses any ability to rank hypernyms the highest;\nindeed, in both spaces, co-hyponymy and meronymy both have signiﬁcantly higher z-scores than hyper-\nnymy. Concerning the other measures, we found that they patterned with invCL. On TypeDM, ClarkeDE\nand WeedsPrec had signiﬁcantly higher nearest-neighbor values for hypernyms than co-hyponyms.2 On\nU+W2 and U+Sent, all measures ranked co-hyponyms signiﬁcantly higher than hypernyms. With the\nbaseline measure, cosine, the similarity ratings for the CO-HYP relation are always the highest, no matter\nthe space, followed by HYPER, MERO, RANDOM in this order.\nFollowing Kotlerman et al. (2010) and Lenci and Benotto (2012), we also report the performance of\nthe measures using Mean Average Precision (MAP). Average Precision (AP) is a measure often used in\n', 86, 0)
(84.65400695800781, 753.6326904296875, 353.6982421875, 765.4845581054688, '2balAPinc could not be evaluated on TypeDM due to computational issues.\n', 87, 0)
(287.8630065917969, 786.9010009765625, 309.6812438964844, 800.0464477539062, '1028\n', 88, 0)

page suivante
(193.9350128173828, 62.61005401611328, 403.3876037597656, 75.75552368164062, 'Measure\nCO-HYP\nHYPER\nMERO\nRANDOM\n', 0, 0)
(283.88201904296875, 78.55103302001953, 313.66387939453125, 91.69650268554688, 'U+W2\n', 1, 0)
(193.9350128173828, 92.49805450439453, 392.5563659667969, 105.64352416992188, 'cosine\n.68\n.20\n.27\n.27\n', 2, 0)
(193.9350128173828, 106.04700469970703, 392.5563659667969, 119.19247436523438, 'ClarkeDE\n.66\n.19\n.28\n.28\n', 3, 0)
(193.9350128173828, 119.59705352783203, 392.5563659667969, 132.74252319335938, 'invCL\n.60\n.18\n.31\n.28\n', 4, 0)
(282.05999755859375, 133.5440216064453, 315.4854736328125, 146.68948364257812, 'U+Sent\n', 5, 0)
(193.9350128173828, 147.4920196533203, 392.5563659667969, 160.63748168945312, 'cosine\n.66\n.18\n.28\n.28\n', 6, 0)
(193.9350128173828, 161.04103088378906, 392.5563659667969, 174.18649291992188, 'ClarkeDE\n.66\n.15\n.29\n.28\n', 7, 0)
(193.9350128173828, 174.5900421142578, 392.5563659667969, 187.73550415039062, 'invCL\n.59\n.13\n.34\n.29\n', 8, 0)
(279.2130126953125, 188.5380401611328, 318.3330383300781, 201.68350219726562, 'TypeDM\n', 9, 0)
(193.9350128173828, 202.4860382080078, 392.5563659667969, 215.63150024414062, 'cosine\n.78\n.19\n.20\n.29\n', 10, 0)
(193.9350128173828, 216.03504943847656, 392.5563659667969, 229.18051147460938, 'ClarkeDE\n.45\n.35\n.25\n.32\n', 11, 0)
(193.9350128173828, 229.5840606689453, 392.5563659667969, 242.72952270507812, 'invCL\n.38\n.36\n.27\n.33\n', 12, 0)
(122.44599914550781, 257.427001953125, 475.1044006347656, 270.5724792480469, 'Table 1: Mean Average Precision for the unsupervised measures on three spaces.\n', 13, 0)
(72.0009994506836, 292.76702880859375, 525.5491943359375, 742.6285400390625, 'the Information Retrieval community with a maximal AP score of 1 when all relevant documents (relata\nwith the right relationship, in our case) are ranked at the top. We compute AP on a per-concept basis and\nreport the mean over all 200 AP values. An advantage of MAP is that, while the BLESS analysis method\nfocuses on nearest neighbors, MAP evaluates the ranking of all relata. A disadvantage of MAP is that it\ndoes not test the degree to which a similarity measure separates different semantic relations, like Tukey\ndoes, so it may overstate the discriminative power of a particular measure. However, it provides a more\nintuitive accuracy-like number compared to the BLESS evaluation.\nTable 1 shows the Mean Average Precision values for cosine, ClarkeDE, and invCL on all three spaces.\nWe also computed WeedsPrec and balAPinc results, obtaining the same picture; we focus on ClarkeDE\nand invCL because ClarkeDE is a component of invCL, and invCL is the current best measure. The results\ncorresponding to Lenci and Benotto’s are shown in the lowest part of Table 1, where we report numbers\nfor TypeDM. Like Lenci and Benotto, we ﬁnd that unsupervised measures other than invCL rank co-\nhyponyms the highest, and obtain relatively low results for hypernyms. For invCL in TypeDM, Lenci\nand Benotto obtain 0.38 MAP for co-hyponyms and a slightly higher 0.40 for hypernyms, though they\ndo not report signiﬁcance testing results. We obtain 0.38 for co-hyponyms and 0.36 for hypernyms, and\nthe difference is not signiﬁcant.3 Even though our results are slightly different from those in Lenci and\nBenotto (2012), both our results and theirs point to at most a weak preference of invCL for hypernyms\nover co-hyponyms. Moreover, in the U+W2 and U+Sent spaces we see that all three measures are very\npoor at identifying hypernyms, and the co-hyponymy relation stubbornly persists as most relevant to all\nthree measures, by a large margin.\nOur results thus constitute a puzzle for the Distributional Inclusion Hypothesis. It seems that there\nmust be some merit to the hypothesis: On one particular space, namely TypeDM, the nearest neighbors\nin the hypernymy relation had higher similarity scores than any other relation by a signiﬁcant margin.\nThis was true for all the hypernymy detectors we studied. But even on TypeDM, the MAP evaluation\nshowed at most a weak hypernymy signal, and when spaces other than TypeDM were used, the effect\nvanished altogether. So how strong an indication for hypernymy can we expect from distributional\ninclusion measures in general? We will return to this question below, where our answer will be: The\nDistributional Inclusion Hypothesis seems to hold after all, but it needs to be applied to the right kind of\ndimensions – and a supervised approach can help in picking the right dimensions.\nAs the unsupervised approaches struggle to detect hypernymy and do not seem robust to changes in\nstandard space parameters, we think it is time to consider supervised approaches. In the next section, we\nexplore two simple supervised approaches that show good performance and are robust to changes in the\nunderlying space.\n', 14, 0)
(84.65399932861328, 753.6326904296875, 184.65432739257812, 765.4845581054688, '3Wilcoxon signed-rank test.\n', 15, 0)
(287.8630065917969, 786.9010009765625, 309.6812438964844, 800.0464477539062, '1029\n', 16, 0)

page suivante
(72.0009994506836, 62.2890625, 261.6463317871094, 77.8427734375, '5\nSupervised Hypernymy Detection\n', 0, 0)
(72.0009994506836, 85.06507110595703, 525.5492553710938, 179.50558471679688, 'We use two simple, supervised models for predicting BLESS and ENTAILMENT relations. The ﬁrst\n(Concat) is a model previously proposed by Baroni et al. (2012). The second (Diff) takes up an idea\nfrom a footnote in Baroni et al. (2012), but while that footnote stated that the approach in question did\nnot work, we ﬁnd that, with a few modiﬁcations, it obtains the best performance – and can be interpreted\nas a supervised version of the Distributional Inclusion Hypothesis. Note that while we used unreduced\nspaces in the previous section, we now use reduced spaces throughout (these are the spaces with the 300\nsubscript), in order not to have more features than data points.\n', 1, 0)
(72.00102996826172, 189.00437927246094, 238.19032287597656, 203.19711303710938, '5.1\nModels, Features, and Method\n', 2, 0)
(72.00101470947266, 206.85435485839844, 525.5468139648438, 423.8186340332031, 'Concat:\nWe use a standard Support Vector Machine (SVM) classiﬁer with a concatenation of vectors as\ninput features. SVMs are binary classiﬁers which learn the maximum margin hyperplane separating the\ntwo classes. SVMs employ kernel functions to ﬁnd the hyperplanes in higher dimensional spaces which\nare nonlinear in the original space. As feature vectors for the classiﬁer, we follow Baroni et al. (2012)\nand use the concatenation of the latent dimension vectors representing words. For the ENTAILMENT\ndataset, we use the concatenation of the hyponym latent vector and the hypernym latent vector for each\nword pair as training features, and the entails/doesn’t entail annotations as binary targets. For BLESS,\nwe use the concatenation of the concept latent vector and the relatum latent vector as training features,\nand the four relationship classes as targets. We choose the four-way task rather than a “hypernymy vs.\nother” classiﬁcation because BLESS contains many more co-hyponymy and random than hypernymy\npairs, which would give a very high baseline in the two-way task. Additionally, the other relations in\nBLESS, in particular meronymy, may be interesting in their own right.\nSince SVMs are binary classiﬁers, we use SciKit-Learn’s default setting to train 6 pairwise-relation\none-vs-one classiﬁers which vote on the ﬁnal answer. We use a polynomial kernel with a degree of 3\nand a penalty term of C = 1.0, and all other hyperparameters are chosen using the SciKit-Learn default\nvalues (Pedregosa et al., 2011). No hyperparameters are tuned in any experiment.\n', 3, 0)
(72.00096893310547, 431.8434143066406, 525.5466918945312, 602.0189208984375, 'Diff:\nOur second classiﬁer is a Logistic Regression (aka MaxEnt) model trained on difference vectors.\nLogistic Regression is a statistical model for binary classiﬁcation. It learns a linear hyperplane sepa-\nrating the classes and estimates a probability for classes using a logistic function. We selected Logistic\nRegression over other possible linear classiﬁers for its natural ability to give likelihood estimates, which\nwe believe will be useful in future work in an application of hypernymy classiﬁcation to RTE.\nAs feature vectors, we use a Mikolov-inspired method of representing word pairs as the difference\nvectors between the two words.4 Baroni et al. (2012) suggested the use of difference vectors as input\nto a classiﬁer, but reported them as unsuccessful. We found difference vectors to be excellent features,\nwith three important modiﬁcations: a linear classiﬁer is better than a nonlinear one; vectors must be\nnormalized to have a magnitude of 1 before taking the difference; and squared difference vectors must\nalso be included as features. So, we represent each word pair with latent vectors (u, v) as a two part\nvector ⟨f; g⟩, where\n', 4, 0)
(259.6949768066406, 603.307373046875, 297.0521545410156, 623.2325439453125, 'fi = ui\n', 5, 0)
(284.15802001953125, 603.3071899414062, 329.169189453125, 636.8247680664062, '∥u∥ − vi\n', 6, 0)
(317.0360107421875, 610.6871948242188, 337.8526916503906, 636.8247680664062, '∥v∥,\n', 7, 0)
(259.83197021484375, 632.1340942382812, 299.9697265625, 648.1293334960938, 'gi = f 2\ni .\n', 8, 0)
(72.00102996826172, 653.926025390625, 525.5499267578125, 725.2274169921875, 'These differences features5 are analogous to a supervised distributional inclusion measure. The dif-\nference between two words on a particular dimension captures the degree of distributional inclusion on\nthat dimension. The primary distinction between the difference features and the unsupervised measures\nis that the supervised classiﬁer learns to weight the importance of different dimensions. The f features\nencode directional aspects of distributional inclusion: that the hyponym contexts should be included in\n', 9, 0)
(72.0009994506836, 732.7957153320312, 525.5477905273438, 765.4845581054688, '4After recent work using subtraction to represent analogy in certain neural-network spaces (Mikolov et al., 2013).\n5We also tried variations, such as not normalizing vectors and removing the difference squared vector, but found this setting\nthe best. We also tried the Diff features with an SVM and other nonlinear classiﬁers, but they performed worse.\n', 10, 0)
(287.8630065917969, 786.9010009765625, 309.6812438964844, 800.0464477539062, '1030\n', 11, 0)

page suivante
(199.20201110839844, 62.61005401611328, 398.07635498046875, 75.75552368164062, 'Data set\nBLESS\nENTAILMENT\n', 0, 0)
(199.20201110839844, 76.55805206298828, 374.08740234375, 89.70352172851562, 'Baseline\n.46\n.50\n', 1, 0)
(199.20201110839844, 90.50605010986328, 397.6459045410156, 103.65151977539062, 'Classiﬁer\nConcat\nDiff\nConcat\nDiff\n', 2, 0)
(199.20201110839844, 104.06028747558594, 395.51739501953125, 118.25302124023438, 'U+W2300\n.76\n.84\n.81\n.85\n', 3, 0)
(199.20201110839844, 118.00299835205078, 395.5126953125, 131.71151733398438, 'U+Sent300\n.73\n.80\n.78\n.82\n', 4, 0)
(199.20201110839844, 131.15928649902344, 395.51739501953125, 145.35202026367188, 'TypeDM300\n-\n.82\n.65\n.85\n', 5, 0)
(72.0009994506836, 159.39503479003906, 525.5402221679688, 186.08950805664062, 'Table 2: Average accuracy of Concat and Diff on BLESS and ENTAILMENT using different spaces for\nfeature generation.\n', 6, 0)
(72.00093841552734, 206.82801818847656, 525.5468139648438, 342.5545349121094, 'those of the hypernym (the weight learned is positive), and the hypernym contexts should not be in-\ncluded in those of the hyponym (the weight learned is negative). So like invCL, this model uses a “proper\nsubset” interpretation of the Distributional Inclusion Hypothesis, but only considers selected dimensions\n(i.e. those that the model assigns nonzero weights).\nThe difference-squared features (g), on the other hand, typically identify dimensions that are not in-\ndicative of hypernymy, by learning negative weights on them (more about this in Section 6). Thus, rather\nthan helping identify hypernyms, they help separate random relations from the rest.\nWe use a L1 regularizer with a strength of C = 1.0. All other hyperparameters are chosen using\nthe SciKit-Learn defaults. Since Diff is also a binary classiﬁer, we use SciKit-Learn’s default setting of\ntraining 4 one-vs-all classiﬁers for BLESS, with the most conﬁdent classiﬁer choosing the ﬁnal answer.\n', 7, 0)
(72.00093841552734, 351.0343322753906, 525.5465698242188, 445.8675842285156, 'Method:\nFor evaluation on BLESS, we hold out one concept and train on the remaining 199 concepts.\nWe also exclude from the training set any pair containing a relatum which appears in the test set. This\nway, no word that appears in the test set has been seen in training. We report the average accuracy across\nall concepts. We use the most frequent relation type (random) as our baseline. For the ENTAILMENT data\nset, we hold out one hyponym and train on all remaining hyponyms. Again, we exclude from training\nany pair containing a hypernym which appears in the test set. We report average accuracy across all\nhyponyms. The data set is balanced, so the baseline is 0.5.\n', 8, 0)
(72.00096893310547, 455.8193664550781, 130.4846649169922, 470.0121154785156, '5.2\nResults\n', 9, 0)
(72.00096893310547, 474.32208251953125, 525.271728515625, 487.4675598144531, 'Table 2 shows the performance of the two classiﬁers, Concat and Diff, on both the BLESS and ENTAIL-\n', 10, 0)
(72.00096893310547, 487.87109375, 525.5496826171875, 745.54052734375, 'MENT datasets, using three underlying spaces. We use the reduced versions of the three spaces, indicated\nby the subscript 300. Note that the Concat classiﬁer could not converge using features from TypeDM300,\nso we omit the result. With both methods, we obtain a high accuracy on the two datasets, with results\naround .8 against baselines around .5. Our best result is .84 on BLESS and .85 on ENTAILMENT. More-\nover, both approaches are in general robust to changes in space parameters (with TypeDM/Concat an\noutlier). Still, the U+W2300 space seems to be the best for this task: Its scores are signiﬁcantly6 higher\nthan the rest, except for TypeDM on ENTAILMENT, which achieves the same score as U+W2300. Diff\nachieves signiﬁcantly higher results than Concat.\nWhen provided more information, Concat outperforms Diff. For instance, if cross-validation is done\nover all pairs in BLESS in the U+W2300 space, Concat achieves .98 accuracy, while Diff obtains .90.\nHowever, in this setting the same words appear in the training and test sets (albeit in different pairs).\nWe take this to mean that Concat is memorizing, rather than learning the hypernymy relation. This\nemphasizes the need for our stricter evaluation that prevents repetition between training and test sets.\nClearly, both classiﬁers do fairly well at predicting hypernymy relations between words, regardless\nof space. Naturally, one should ask what are the classiﬁers capturing that the unsupervised measures\nare missing? We propose that the supervised classiﬁers perform essentially the same operation as the\nunsupervised measures, but are learning to determine the relevance of dimensions. In particular, Diff\nis learning weights on vector difference features. This is equivalent to doing selective distributional\ninclusion. In the next section, we test this Selective Distributional Inclusion Hypothesis.\n', 11, 0)
(84.65399932861328, 753.6326904296875, 222.4326171875, 765.4845581054688, '6Wilcoxon signed-rank test, p < .001.\n', 12, 0)
(287.8630065917969, 786.9010009765625, 309.6812438964844, 800.0464477539062, '1031\n', 13, 0)

page suivante
(118.39314270019531, 139.8792724609375, 120.74099731445312, 142.8474884033203, 'G\n', 0, 0)
(118.39314270019531, 173.57774353027344, 120.74099731445312, 176.54595947265625, 'G\n', 1, 0)
(118.39314270019531, 133.92271423339844, 120.74099731445312, 136.89093017578125, 'G\n', 2, 0)
(118.39314270019531, 142.5703125, 120.74099731445312, 145.5385284423828, 'G\n', 3, 0)
(118.39314270019531, 129.30662536621094, 120.74099731445312, 132.27484130859375, 'G\n', 4, 0)
(118.39314270019531, 138.24147033691406, 120.74099731445312, 141.20968627929688, 'G\n', 5, 0)
(145.238037109375, 178.9547882080078, 147.5858917236328, 184.14537048339844, 'GG\n', 6, 0)
(145.238037109375, 174.0312957763672, 147.5858917236328, 176.99951171875, 'G\n', 7, 0)
(198.93283081054688, 135.87295532226562, 201.2806854248047, 138.84117126464844, 'G\n', 8, 0)
(198.93283081054688, 110.95816802978516, 201.2806854248047, 113.92637634277344, 'G\n', 9, 0)
(89.9406967163086, 184.66908264160156, 99.88846588134766, 191.5932159423828, '−1.5\n', 10, 0)
(89.9406967163086, 167.2882080078125, 99.88846588134766, 174.21234130859375, '−1.0\n', 11, 0)
(89.9406967163086, 149.9022674560547, 99.88846588134766, 156.82640075683594, '−0.5\n', 12, 0)
(92.88370513916016, 132.51634216308594, 99.88846588134766, 139.4404754638672, '0.0\n', 13, 0)
(92.88370513916016, 115.13544464111328, 99.88846588134766, 122.05958557128906, '0.5\n', 14, 0)
(92.88370513916016, 97.74951934814453, 99.88846588134766, 104.67366027832031, '1.0\n', 15, 0)
(92.88370513916016, 80.36358642578125, 99.88846588134766, 87.28772735595703, '1.5\n', 16, 0)
(110.88948059082031, 195.26695251464844, 209.6314697265625, 202.1910858154297, 'Co−hyp\nHyper\nMero\nRandom\n', 17, 0)
(81.62568664550781, 134.6127471923828, 89.93464660644531, 137.63638305664062, 'z\n', 18, 0)
(130.9210968017578, 69.35753631591797, 188.75222778320312, 79.05132293701172, 'U+W2 proj, cosine\n', 19, 0)
(266.25714111328125, 149.76658630371094, 268.60498046875, 155.3099365234375, 'G\nG\n', 20, 0)
(266.25714111328125, 84.4156494140625, 268.60498046875, 87.38385772705078, 'G\n', 21, 0)
(266.25714111328125, 138.55894470214844, 268.60498046875, 141.52716064453125, 'G\n', 22, 0)
(266.25714111328125, 144.2736358642578, 268.60498046875, 147.24185180664062, 'G\n', 23, 0)
(266.25714111328125, 155.37542724609375, 268.60498046875, 158.34364318847656, 'G\n', 24, 0)
(266.25714111328125, 166.7795867919922, 268.60498046875, 169.747802734375, 'G\n', 25, 0)
(266.25714111328125, 144.07205200195312, 268.60498046875, 147.04026794433594, 'G\n', 26, 0)
(266.25714111328125, 139.43077087402344, 268.60498046875, 142.39898681640625, 'G\n', 27, 0)
(266.25714111328125, 162.7329559326172, 268.60498046875, 165.701171875, 'G\n', 28, 0)
(266.25714111328125, 84.95990753173828, 268.60498046875, 87.92811584472656, 'G\n', 29, 0)
(266.25714111328125, 138.24147033691406, 268.60498046875, 141.20968627929688, 'G\n', 30, 0)
(266.25714111328125, 153.6267547607422, 268.60498046875, 156.594970703125, 'G\n', 31, 0)
(266.25714111328125, 139.4962921142578, 268.60498046875, 142.46450805664062, 'G\n', 32, 0)
(266.25714111328125, 83.24651336669922, 268.60498046875, 86.2147216796875, 'G\n', 33, 0)
(266.25714111328125, 137.80809020996094, 268.60498046875, 141.66323852539062, 'GG\n', 34, 0)
(293.1020202636719, 174.4293975830078, 295.4498596191406, 177.39761352539062, 'G\n', 35, 0)
(293.1020202636719, 151.02642822265625, 295.4498596191406, 155.47119140625, 'GG\n', 36, 0)
(293.1020202636719, 158.90301513671875, 295.4498596191406, 163.93234252929688, 'GG\n', 37, 0)
(293.1020202636719, 162.1634979248047, 295.4498596191406, 169.5613555908203, 'G\nG\n', 38, 0)
(293.1020202636719, 172.75128173828125, 295.4498596191406, 175.71949768066406, 'G\n', 39, 0)
(293.1020202636719, 181.11668395996094, 295.4498596191406, 184.08489990234375, 'G\n', 40, 0)
(293.1020202636719, 173.31568908691406, 295.4498596191406, 176.28390502929688, 'G\n', 41, 0)
(293.1020202636719, 161.3068084716797, 295.4498596191406, 164.2750244140625, 'G\n', 42, 0)
(293.1020202636719, 175.83035278320312, 295.4498596191406, 180.8244171142578, 'GG\n', 43, 0)
(293.1020202636719, 153.86865234375, 295.4498596191406, 156.8368682861328, 'G\n', 44, 0)
(293.1020202636719, 177.1154022216797, 295.4498596191406, 180.0836181640625, 'G\n', 45, 0)
(293.1020202636719, 167.33392333984375, 295.4498596191406, 170.30213928222656, 'G\n', 46, 0)
(346.7968444824219, 112.021484375, 349.1446838378906, 114.98969268798828, 'G\n', 47, 0)
(346.7968444824219, 136.88084411621094, 349.1446838378906, 143.32119750976562, 'G\nG\n', 48, 0)
(346.7968444824219, 131.2820587158203, 349.1446838378906, 136.94635009765625, 'G\nG\nG\n', 49, 0)
(346.7968444824219, 100.35022735595703, 349.1446838378906, 103.31843566894531, 'G\n', 50, 0)
(346.7968444824219, 119.16735076904297, 349.1446838378906, 122.13555908203125, 'G\n', 51, 0)
(237.8046875, 184.66908264160156, 247.75247192382812, 191.5932159423828, '−1.5\n', 52, 0)
(237.8046875, 167.2882080078125, 247.75247192382812, 174.21234130859375, '−1.0\n', 53, 0)
(237.8046875, 149.9022674560547, 247.75247192382812, 156.82640075683594, '−0.5\n', 54, 0)
(240.74769592285156, 132.51634216308594, 247.75247192382812, 139.4404754638672, '0.0\n', 55, 0)
(240.74769592285156, 115.13544464111328, 247.75247192382812, 122.05958557128906, '0.5\n', 56, 0)
(240.74769592285156, 97.74951934814453, 247.75247192382812, 104.67366027832031, '1.0\n', 57, 0)
(240.74769592285156, 80.36358642578125, 247.75247192382812, 87.28772735595703, '1.5\n', 58, 0)
(258.75347900390625, 195.26695251464844, 357.4954833984375, 202.1910858154297, 'Co−hyp\nHyper\nMero\nRandom\n', 59, 0)
(229.48968505859375, 134.6127471923828, 237.79864501953125, 137.63638305664062, 'z\n', 60, 0)
(273.9069519042969, 69.35753631591797, 341.4953918457031, 79.05132293701172, 'U+W2 proj, ClarkeDE\n', 61, 0)
(414.12115478515625, 174.61082458496094, 416.468994140625, 181.69119262695312, 'G\nG\nGG\n', 62, 0)
(440.9660339355469, 156.14646911621094, 443.3138732910156, 159.11972045898438, 'GG\n', 63, 0)
(440.9660339355469, 135.90823364257812, 443.3138732910156, 138.87644958496094, 'G\n', 64, 0)
(440.9660339355469, 152.15525817871094, 443.3138732910156, 155.12347412109375, 'G\n', 65, 0)
(440.9660339355469, 157.9556121826172, 443.3138732910156, 160.923828125, 'G\n', 66, 0)
(440.9660339355469, 166.60321044921875, 443.3138732910156, 169.57142639160156, 'G\n', 67, 0)
(440.9660339355469, 139.1939239501953, 443.3138732910156, 142.16213989257812, 'G\n', 68, 0)
(440.9660339355469, 149.6456298828125, 443.3138732910156, 152.6138458251953, 'G\n', 69, 0)
(440.9660339355469, 161.1656951904297, 443.3138732910156, 164.1339111328125, 'G\n', 70, 0)
(440.9660339355469, 167.26841735839844, 443.3138732910156, 170.23663330078125, 'G\n', 71, 0)
(440.9660339355469, 148.86956787109375, 443.3138732910156, 152.20565795898438, 'GG\n', 72, 0)
(440.9660339355469, 168.6139373779297, 443.3138732910156, 175.7698974609375, 'G\nG\n', 73, 0)
(440.9660339355469, 161.9720001220703, 443.3138732910156, 164.94021606445312, 'G\n', 74, 0)
(440.9660339355469, 154.0702362060547, 443.3138732910156, 157.0384521484375, 'G\n', 75, 0)
(440.9660339355469, 172.84703063964844, 443.3138732910156, 175.81524658203125, 'G\n', 76, 0)
(440.9660339355469, 178.06280517578125, 443.3138732910156, 181.03102111816406, 'G\n', 77, 0)
(440.9660339355469, 164.00791931152344, 443.3138732910156, 166.97613525390625, 'G\n', 78, 0)
(440.9660339355469, 155.1940155029297, 443.3138732910156, 158.1622314453125, 'G\n', 79, 0)
(440.9660339355469, 143.9359893798828, 443.3138732910156, 146.90420532226562, 'G\n', 80, 0)
(440.9660339355469, 137.68714904785156, 443.3138732910156, 144.97412109375, 'G\nG\n', 81, 0)
(440.9660339355469, 160.48538208007812, 443.3138732910156, 163.45359802246094, 'G\n', 82, 0)
(440.9660339355469, 155.10833740234375, 443.3138732910156, 158.07655334472656, 'G\n', 83, 0)
(494.66082763671875, 96.26831817626953, 497.0086669921875, 99.23652648925781, 'G\n', 84, 0)
(494.66082763671875, 90.46796417236328, 497.0086669921875, 93.43617248535156, 'G\n', 85, 0)
(494.66082763671875, 124.48391723632812, 497.0086669921875, 127.4521255493164, 'G\n', 86, 0)
(494.66082763671875, 100.03275299072266, 497.0086669921875, 103.00096130371094, 'G\n', 87, 0)
(494.66082763671875, 82.81312561035156, 497.0086669921875, 88.40181732177734, 'G\nG\n', 88, 0)
(494.66082763671875, 122.65461730957031, 497.0086669921875, 127.95606231689453, 'GG\n', 89, 0)
(494.66082763671875, 128.5355987548828, 497.0086669921875, 131.50381469726562, 'G\n', 90, 0)
(494.66082763671875, 112.65140533447266, 497.0086669921875, 115.61961364746094, 'G\n', 91, 0)
(494.66082763671875, 82.9189453125, 497.0086669921875, 85.88715362548828, 'G\n', 92, 0)
(494.66082763671875, 90.8106460571289, 497.0086669921875, 93.77885437011719, 'G\n', 93, 0)
(385.668701171875, 184.66908264160156, 395.6164855957031, 191.5932159423828, '−1.5\n', 94, 0)
(385.668701171875, 167.2882080078125, 395.6164855957031, 174.21234130859375, '−1.0\n', 95, 0)
(385.668701171875, 149.9022674560547, 395.6164855957031, 156.82640075683594, '−0.5\n', 96, 0)
(388.6116943359375, 132.51634216308594, 395.6164855957031, 139.4404754638672, '0.0\n', 97, 0)
(388.6116943359375, 115.13544464111328, 395.6164855957031, 122.05958557128906, '0.5\n', 98, 0)
(388.6116943359375, 97.74951934814453, 395.6164855957031, 104.67366027832031, '1.0\n', 99, 0)
(388.6116943359375, 80.36358642578125, 395.6164855957031, 87.28772735595703, '1.5\n', 100, 0)
(406.6174621582031, 195.26695251464844, 505.3594665527344, 202.1910858154297, 'Co−hyp\nHyper\nMero\nRandom\n', 101, 0)
(377.3536682128906, 134.6127471923828, 385.6626281738281, 137.63638305664062, 'z\n', 102, 0)
(427.89886474609375, 69.35753631591797, 483.23248291015625, 79.05132293701172, 'U+W2 proj, invCL\n', 103, 0)
(72.00100708007812, 226.35401916503906, 525.5447998046875, 254.68551635742188, 'Figure 2: Distributions of relata scores across concepts using the cosine, ClarkeDE, and invCL measures\n(after per-concept z-normalization). Here we use the selected dimensions of the U+W2proj space.\n', 104, 0)
(72.00100708007812, 272.84405517578125, 258.8368835449219, 288.39776611328125, '6\nSelective Distributional Inclusion\n', 105, 0)
(72.00100708007812, 295.48504638671875, 525.546630859375, 376.3765563964844, 'In order to test how well our supervised model is capturing the notion of selective distributional inclusion,\nwe test each of the unsupervised measures on a smaller space, limited only to the dimensions preferred\nby the classiﬁer. We emphasize that we do not aim to show that our supervised method outperforms\nunsupervised methods, but rather that the unsupervised methods beneﬁt greatly from feature selection.\nAdditionally, we analyze which dimensions are selected by the classiﬁer to facilitate understanding of\nwhy these dimensions are important.\n', 106, 0)
(72.00100708007812, 385.6873474121094, 151.69200134277344, 399.8800964355469, '6.1\nExperiment\n', 107, 0)
(72.00100708007812, 403.82208251953125, 525.5467529296875, 471.7276306152344, 'We train the Diff classiﬁer using the dimensionality-reduced U+W2300 space with the same method we\nuse in Section 5. We take the classiﬁer’s learned hyperplane separating hypernyms from other relations,\nand project the hyperplane back into the original U+W2 space.7 We select the 500 dimensions in the orig-\ninal space that are most relevant according to the classiﬁer weights, and test the unsupervised measures\non this new space, which we denote as U+W2proj.8\n', 108, 0)
(72.00100708007812, 471.7010803222656, 525.5493774414062, 674.8035278320312, 'The 500 most relevant dimensions are selected as follows: We select the 250 most negatively weighted\noriginal dimensions using the difference features f. These are the features that have smaller values for\nhyponyms (e.g. dog) than for hypernyms (e.g. animal), so they characterize hypernymy. We further select\nthe 250 most positively weighted original dimensions using the squared-differences features g. These\nare the ones where a large difference does not indicate hypernymy.\nFigure 2 shows the boxplots for the BLESS analysis: the distributions of nearest-neighbor similarity\nscores for the four different semantic relations, for the measures cosine, ClarkeDE, and invCL. We see\nthat invCL now easily discriminates hypernymy from the other relations in the backprojected space. (The\ndifference of HYPER and CO-HYP is signiﬁcant.) This is even though the space is based on U+W2, where\ninvCL failed to rate hypernyms higher than co-hypernyms in Section 4. Unsurprisingly, cosine, which\ndoes not measure distributional inclusion, still prefers CO-HYP.\nTable 3 shows the MAP scores for three of the measures in the new U+W2proj space. (The results\nfor balAPinc and WeedsPrec are slightly worse than ClarkeDE.) All measures except for cosine assign\nhigher scores to hypernyms than they did in the original space (compare to U+W2 part of Table 1). But\nit is only invCL that ranks hypernyms signiﬁcantly higher than co-hyponyms.9\n', 109, 0)
(72.00100708007812, 682.0707397460938, 525.5482788085938, 765.4845581054688, '7Ideally we would train on the original space to inspect the relevant dimensions. However, there are more dimensions than\nexamples, so we train on the SVD space and backproject.\n8Note that U+W2proj varies slightly from concept to concept, since the hyperplane is learned on a per-concept basis. It is\nimportant that we use the linear Diff classiﬁer for this reverse-projection procedure, as the separating hyperplane must be linear\nin order to complete the projection. In particular, the hyperplane in the Concat classiﬁer cannot be easily backprojected, since\nit exists in a higher dimensional space than the projection matrix. Furthermore, it is important that we use a classiﬁer trained\nusing the difference features because of its analogy to the Distributional Inclusion Hypothesis.\n9Wilcoxon signed-rank test, p < .001. To check that the measures are being improved by the dimension selection and not\n', 110, 0)
(287.8630065917969, 786.9010009765625, 309.6812438964844, 800.0464477539062, '1032\n', 111, 0)

page suivante
(193.9350128173828, 62.61005401611328, 403.3876037597656, 75.75552368164062, 'Measure\nCO-HYP\nHYPER\nMERO\nRANDOM\n', 0, 0)
(275.4850158691406, 78.55103302001953, 321.1185607910156, 92.25955200195312, 'U+W2proj\n', 1, 0)
(193.9350128173828, 92.49805450439453, 392.5563659667969, 105.64352416992188, 'cosine\n.69\n.20\n.24\n.28\n', 2, 0)
(193.9350128173828, 106.04700469970703, 392.5563659667969, 119.19247436523438, 'ClarkeDE\n.55\n.39\n.24\n.29\n', 3, 0)
(193.9350128173828, 119.20433044433594, 392.5577087402344, 133.39706420898438, 'invCL\n.42\n.58\n.24\n.29\n', 4, 0)
(72.0009994506836, 147.4400177001953, 525.5466918945312, 174.13449096679688, 'Table 3: Mean Average Precision for the unsupervised measures after selecting the top dimensions from\na supervised model.\n', 5, 0)
(72.0009994506836, 195.2930450439453, 525.5467529296875, 303.8115539550781, 'For this experiment, we train on all of BLESS except for one concept and then evaluate the unsuper-\nvised models on the held-out concept – that is a setting that could, in principle, be used as a hypernymy\ndetector. If we instead train the supervised model on all of BLESS to determine an upper bound of how\nwell dimension selection can do on this dataset, MAP for invCL rises to .67.\nOverall, these experiments provide strong evidence for the Selective Distributional Inclusion Hypoth-\nesis: The Distributional Inclusion Hypothesis holds, but only for relevant dimensions. In addition, hy-\npernymy detectors need to test for “proper inclusion” of distributional contexts in order to really ﬁnd\nhypernyms.\n', 6, 0)
(72.00096893310547, 313.0183410644531, 525.5487060546875, 653.3245849609375, 'Analysis of Selected Dimensions.\nWe examine the 500 dimensions selected by the above procedure,\nin order to see what the classiﬁer is learning. As this is for analysis only, the dimensions were selected\nby training on all data.\nRecall that the difference-squared g features can be interpreted as dimensions that the classiﬁer deems\nnot indicative of hypernymy. 200 out of the 250 most relevant dimensions by g are Computer Science\nrelated terms like software, conﬁgure, or Linux. Since ukWaC, the largest corpus we use, is web-based,\nit makes sense that it has many CS-related terms, which are noise when it comes to hypernymy detection\nfor BLESS concepts. Also, we ﬁnd that while the supervised approach needs the negative information\nfrom the g features (for Diff in the U+W2300 space, omitting g features yields a drop from .84 to .8),\nthe unsupervised measures cannot use it. Dropping g features improves invCL results from .58 to .61.\nThe g-based dimensions are explicitly those for which distributional inclusion should not hold, so they\nconstitute noise to the unsupervised approaches.\nThe f features can be interpreted as dimensions that characterize hypernyms. An inspection reveals\ntwo clear patterns. First, the features are topically relevant for the BLESS dataset. The 17 concept classes\nin the dataset belong to three broader groups: animals, plants, and artifacts. An annotation of the 250\ndimensions by one of the authors showed that 58 dimensions are typical of animals (parasite, extinct), 14\ntypical of vegetables (ﬂora, nutrient), 80 typical of artifacts (repair, mechanical), 49 are general terms\n(ﬁnd, worthy), and 49 have no clear interpretation (thee, enigmatic). Second, the features are general\nterms. For instance, for animals we ﬁnd terms like animal, insect, creature, fauna, species, evolutionary,\npathogen, nature, ecology. We also ﬁnd many hypernyms, including many concept class names.\nClearly, the selected features are domain dependent; most are directly related to the concepts and\nconcept classes of BLESS. We expect that our method should work well for other data sets, given its high\naccuracy and the strict training procedure. However, these features are unlikely to be global indicators of\nhypernymy. This emphasizes the need, in future work, to ﬁnd a way to automatically determine relevance\non a per-word basis.\n', 7, 0)
(72.0009994506836, 664.3801879882812, 147.06771850585938, 679.9338989257812, '7\nConclusion\n', 8, 0)
(72.0009994506836, 688.0011596679688, 525.5467529296875, 728.24462890625, 'In this paper, we have tested the Distributional Inclusion Hypothesis, the basis for distributional ap-\nproaches to hypernymy. We have found that the hypothesis only works if inclusion is selectively applied\nto a set of relevant dimensions.\n', 9, 0)
(72.0009994506836, 734.7550659179688, 525.5482788085938, 765.4845581054688, 'just by restricting to a smaller space, we evaluated the similarity measures on a variation of the U+W2 space which uses 500\nrandomly selected dimensions from the original space. The results are approximately unchanged from those on the original\nU+W2 space.\n', 10, 0)
(287.8630065917969, 786.9010009765625, 309.6812438964844, 800.0464477539062, '1033\n', 11, 0)

page suivante
(72.0009994506836, 63.68604278564453, 525.5467529296875, 212.46957397460938, 'We have tested two simple supervised approaches to distributional hypernymy detection and have\nfound that they show good performance, and are robust to changes in the underlying space. Our best\nclassiﬁer achieves .84 accuracy on BLESS and .85 on the ENTAILMENT dataset of Baroni et al. (2012). It\nuses features that encode dimension-wise difference between vectors. This classiﬁer can be interpreted\nas selecting the dimensions necessary for the Distributional Inclusion Hypothesis to work, thus as an\neffective way to implement selective distributional inclusion.\nThe next natural step is to use the supervised features to guide development of an unsupervised mea-\nsure for hypernymy detection: Now that we have examples, we hope to propose a method which selects\nrelevant features automatically. We also would like to explore detection of other relationships, such\nas meronymy. Finally, we would like to perform an extrinsic evaluation of our hypernymy detection\napproach in an actual RTE system.\n', 0, 0)
(72.00101470947266, 222.1990966796875, 170.83465576171875, 237.7528076171875, 'Acknowledgements\n', 1, 0)
(72.0009994506836, 244.87110900878906, 525.5491943359375, 298.6645812988281, 'This research was supported by the DARPA DEFT program under AFRL grant FA8750-13-2-0026. The\nauthors acknowledge the Texas Advanced Computing Center (TACC)10 for providing grid resources that\nhave contributed to these results. We thank the anonymous reviewers and the UTexas NLP group for\ntheir helpful comments and suggestions.\n', 2, 0)
(72.0009994506836, 321.06011962890625, 127.54483795166016, 336.61383056640625, 'References\n', 3, 0)
(72.0009994506836, 341.3586730957031, 525.5458374023438, 375.2816162109375, 'Marco Baroni and Alessandro Lenci. 2011. How we BLESSed distributional semantic evaluation. In Proceedings\nof the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics, pages 1–10, Edinburgh,\nUK, July. Association for Computational Linguistics.\n', 4, 0)
(72.0009994506836, 383.78668212890625, 525.5482788085938, 417.7095947265625, 'Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and Eros Zanchetta.\n2009.\nThe WaCky wide web: A\ncollection of very large linguistically processed web-crawled corpora. Language Resources and Evaluation,\n43(3):209–226.\n', 5, 0)
(72.00096893310547, 426.2136535644531, 525.548828125, 471.0955810546875, 'Marco Baroni, Raffaella Bernardi, Ngoc-Quynh Do, and Chung-chieh Shan. 2012. Entailment above the word\nlevel in distributional semantics. In Proceedings of the 13th Conference of the European Chapter of the As-\nsociation for Computational Linguistics, pages 23–32, Avignon, France, April. Association for Computational\nLinguistics.\n', 6, 0)
(72.00096893310547, 479.60064697265625, 525.5482177734375, 513.5235595703125, 'Matthew Berland and Eugene Charniak. 1999. Finding parts in very large corpora. In Proceedings of the 37th\nAnnual Meeting of the Association for Computational Linguistics, pages 57–64, College Park, Maryland, USA,\nJune. Association for Computational Linguistics.\n', 7, 0)
(72.00096893310547, 522.027587890625, 525.5469360351562, 544.9915771484375, 'Paul Buitelaar, Philipp Cimiano, and Bernardo Magnini. 2005. Ontology Learning from Text: Methods, Evaluation\nand Applications. Frontiers in Artiﬁcial Intelligence and Applications Series. IOS Press, Amsterdam.\n', 8, 0)
(72.00096130371094, 553.4966430664062, 525.5482177734375, 576.4605712890625, 'Timothy Chklovski and Patrick Pantel. 2004. Verbocean: Mining the web for ﬁne-grained semantic verb relations.\nIn Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 33–40.\n', 9, 0)
(72.00096893310547, 584.9656372070312, 525.5482177734375, 607.9295654296875, 'Philipp Cimiano, Aleksander Pivk, Lars Schmidt-Thieme, and Steffen Staab. 2005. Learning taxonomic relations\nfrom heterogeneous sources of evidence. Ontology Learning from Text: Methods, evaluation and applications.\n', 10, 0)
(72.0009994506836, 616.43359375, 525.54638671875, 650.3565673828125, 'Daoud Clarke. 2009. Context-theoretic semantics for natural language: an overview. In Proceedings of the\nWorkshop on Geometrical Models of Natural Language Semantics, pages 112–119, Athens, Greece, March.\nAssociation for Computational Linguistics.\n', 11, 0)
(72.0009994506836, 658.8616333007812, 525.5431518554688, 692.7845458984375, 'Maayan Geffet and Ido Dagan. 2004. Feature vector quality and distributional similarity. In Proceedings of the\n20th International Conference on Computational Linguistics, page 247. Association for Computational Linguis-\ntics.\n', 12, 0)
(72.0009994506836, 701.2896118164062, 525.5481567382812, 746.1705322265625, 'Roxana Girju, Adriana Badulescu, and Dan Moldovan. 2003. Learning semantic constraints for the automatic\ndiscovery of part-whole relations. In Proceedings of the 2003 Conference of the North American Chapter of the\nAssociation for Computational Linguistics on Human Language Technology-Volume 1, pages 1–8. Association\nfor Computational Linguistics.\n', 13, 0)
(81.66500091552734, 753.6326904296875, 228.0167694091797, 765.090087890625, '10http://www.tacc.utexas.edu\n', 14, 0)
(287.8630065917969, 786.9010009765625, 309.6812438964844, 800.0464477539062, '1034\n', 15, 0)

page suivante
(72.0009994506836, 64.56060791015625, 525.5438842773438, 87.52452850341797, 'Roxana Girju, Adriana Badulescu, and Dan Moldovan. 2006. Automatic discovery of part-whole relations. Com-\nputational Linguistics, 32(1):83–135.\n', 0, 0)
(72.0009994506836, 96.653564453125, 525.5475463867188, 130.5764617919922, 'Marti A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 14th\nConference on Computational Linguistics, pages 539–545, Stroudsburg, PA, USA. Association for Computa-\ntional Linguistics.\n', 1, 0)
(72.0009994506836, 139.654541015625, 525.54833984375, 173.62742614746094, 'Aur´elie Herbelot and Mohan Ganesalingam. 2013. Measuring semantic content in distributional vectors. In\nProceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short\nPapers), pages 440–445, Soﬁa, Bulgaria, August. Association for Computational Linguistics.\n', 2, 0)
(72.0009994506836, 182.7564697265625, 525.5481567382812, 205.7194061279297, 'Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan Zhitomirsky-geffet.\n2010.\nDirectional distributional\nsimilarity for lexical inference. Natural Language Engineering, 16:359–389, 10.\n', 3, 0)
(72.0009994506836, 214.84844970703125, 525.5481567382812, 270.6893310546875, 'Alessandro Lenci and Giulia Benotto. 2012. Identifying hypernyms in distributional semantic spaces. In *SEM\n2012: The First Joint Conference on Lexical and Computational Semantics – Volume 1: Proceedings of the\nmain conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Se-\nmantic Evaluation (SemEval 2012), pages 75–79, Montr´eal, Canada, 7-8 June. Association for Computational\nLinguistics.\n', 4, 0)
(72.0009994506836, 279.8173828125, 525.544189453125, 302.78131103515625, 'Alessandro Lenci. 2008. Distributional approaches in linguistic and cognitive research. Italian Journal of Lin-\nguistics, 20(1):1–31.\n', 5, 0)
(72.0009994506836, 311.91033935546875, 525.548095703125, 345.833251953125, 'Dekang Lin, Shaojun Zhao, Lijuan Qin, and Ming Zhou. 2003. Identifying synonyms among distributionally\nsimilar words. In Proceedings of the 18th international Joint Conference on Artiﬁcial intelligence, pages 1492–\n1493.\n', 6, 0)
(72.00102996826172, 354.9613037109375, 525.5460815429688, 377.92523193359375, 'Dekang Lin. 1998. An information-theoretic deﬁnition of similarity. In Proceedings of the 15th International\nConference on Machine Learning, volume 98, pages 296–304.\n', 7, 0)
(72.00101470947266, 387.0542907714844, 525.5481567382812, 431.93524169921875, 'Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013. Linguistic regularities in continuous space word rep-\nresentations. In Proceedings of the 2013 Conference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies, pages 746–751, Atlanta, Georgia, June. Associa-\ntion for Computational Linguistics.\n', 8, 0)
(72.0009994506836, 441.0643005371094, 390.73443603515625, 453.0692443847656, 'Gregory L. Murphy. 2002. The Big Book of Concepts. MIT Press, Boston, MA.\n', 9, 0)
(72.00101470947266, 462.19830322265625, 525.5482177734375, 496.1202392578125, 'Patrick Pantel and Marco Pennacchiotti. 2006. Espresso: Leveraging generic patterns for automatically harvesting\nsemantic relations. In Proceedings of the 21st International Conference on Computational Linguistics and the\n44th annual meeting of the Association for Computational Linguistics.\n', 10, 0)
(72.0009994506836, 505.1993408203125, 525.548583984375, 551.291259765625, 'Fabian Pedregosa, Ga¨el Varoquaux, Alexandre Gramfort, Vincent Michel, Bertran Thirion, Olivier Grisel, Mathieu\nBlondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Courna-\npeau, Matthieu Brucher, MMatthieu Perrot, and ´Edouard Duchesnay. 2011. Scikit-learn: Machine learning in\nPython. Journal of Machine Learning Research, 12:2825–2830.\n', 11, 0)
(72.00101470947266, 560.4202880859375, 414.60479736328125, 572.4252319335938, 'Enrico Santus. 2013. SLQS: An entropy measure. Master’s thesis, University of Pisa.\n', 12, 0)
(72.00101470947266, 581.5533447265625, 525.5482788085938, 615.4762573242188, 'Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2005. Learning syntactic patterns for automatic hypernym dis-\ncovery. In Lawrence K. Saul, Yair Weiss, and L´eon Bottou, editors, Advances in Neural Information Processing\nSystems 17, pages 1297–1304, Cambridge, MA. MIT Press.\n', 13, 0)
(72.00099182128906, 624.6053466796875, 525.5482177734375, 669.4862670898438, 'Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006. Semantic taxonomy induction from heterogenous evidence.\nIn Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting\nof the Association for Computational Linguistics, ACL-44, pages 801–808, Stroudsburg, PA, USA. Association\nfor Computational Linguistics.\n', 14, 0)
(72.00101470947266, 678.6152954101562, 525.5446166992188, 701.5792846679688, 'Peter Turney and Patrick Pantel. 2010. From frequency to meaning: Vector space models of semantics. Journal\nof Artiﬁcial Intelligence Research, 37:141–188.\n', 15, 0)
(72.00098419189453, 710.707275390625, 470.8815612792969, 722.7122192382812, 'Peter D. Turney. 2006. Similarity of semantic relations. Computational Linguistics, 32(3):379–416.\n', 16, 0)
(72.00096893310547, 731.84130859375, 525.548095703125, 765.7642211914062, 'Julie Weeds and David Weir. 2003. A general framework for distributional similarity. In Michael Collins and Mark\nSteedman, editors, Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,\npages 81–88.\n', 17, 0)
(287.8630065917969, 786.9010009765625, 309.6812438964844, 800.0464477539062, '1035\n', 18, 0)

page suivante
(72.0009994506836, 64.56060791015625, 525.5482177734375, 98.48351287841797, 'Julie Weeds, David Weir, and Diana McCarthy. 2004. Characterising measures of lexical distributional similarity.\nIn Proceedings of the 20th International Conference on Computational Linguistics, pages 1015–1021, Geneva,\nSwitzerland, Aug 23–Aug 27. Association for Computational Linguistics, COLING.\n', 0, 0)
(72.00102996826172, 106.403564453125, 525.5481567382812, 140.3264617919922, 'Maayan Zhitomirsky-Geffet and Ido Dagan. 2005. The distributional inclusion hypotheses and lexical entailment.\nIn Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 107–114,\nAnn Arbor, Michigan, June. Association for Computational Linguistics.\n', 1, 0)
(72.00102996826172, 148.24652099609375, 525.54443359375, 171.21043395996094, 'Maayan Zhitomirsky-Geffet and Ido Dagan. 2009. Bootstrapping distributional feature vector quality. Computa-\ntional linguistics, 35(3):435–461.\n', 2, 0)
(287.8630065917969, 786.9010009765625, 309.6812438964844, 800.0464477539062, '1036\n', 3, 0)

page suivante
