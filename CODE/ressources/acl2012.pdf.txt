(138.91900634765625, 71.84965515136719, 473.08514404296875, 90.5140609741211, 'Finding Salient Dates for Building Thematic Timelines\n', 0, 0)
(95.61499786376953, 97.74102783203125, 210.38497924804688, 154.0384063720703, 'R´emy Kessler\nLIMSI-CNRS\nOrsay, France\nkessler@limsi.fr\n', 1, 0)
(245.02896118164062, 97.884033203125, 366.97210693359375, 167.9854278564453, 'Xavier Tannier\nUniv. Paris-Sud,\nLIMSI-CNRS\nOrsay, France\nxtannier@limsi.fr\n', 2, 0)
(383.6819152832031, 97.74102783203125, 534.3174438476562, 154.0384063720703, 'Caroline Hag`ege\nXerox Research Center Europe\nMeylan, France\nhagege@xrce.xerox.com\n', 3, 0)
(129.21490478515625, 181.21405029296875, 278.78643798828125, 237.5104522705078, 'V´eronique Moriceau\nUniv. Paris-Sud, LIMSI-CNRS\nOrsay, France\nmoriceau@limsi.fr\n', 4, 0)
(332.6819152832031, 181.21405029296875, 483.31756591796875, 237.5104522705078, 'Andr´e Bittar\nXerox Research Center Europe\nMeylan, France\nbittar@xrce.xerox.com\n', 5, 0)
(163.1579132080078, 255.73406982421875, 207.64320373535156, 271.28778076171875, 'Abstract\n', 6, 0)
(93.81790924072266, 277.2986145019531, 276.985595703125, 444.7214050292969, 'We present an approach for detecting salient\n(important) dates in texts in order to auto-\nmatically build event timelines from a search\nquery (e.g. the name of an event or person,\netc.). This work was carried out on a corpus\nof newswire texts in English provided by the\nAgence France Presse (AFP). In order to ex-\ntract salient dates that warrant inclusion in an\nevent timeline, we ﬁrst recognize and normal-\nize temporal expressions in texts and then use\na machine-learning approach to extract salient\ndates that relate to a particular topic. We fo-\ncused only on extracting the dates and not the\nevents to which they are related.\n', 7, 0)
(71.99990844726562, 458.1839294433594, 154.81358337402344, 473.7376403808594, '1\nIntroduction\n', 8, 0)
(71.99989318847656, 479.5838928222656, 298.80499267578125, 723.0653076171875, 'Our aim here was to build thematic timelines for\na general domain topic deﬁned by a user query.\nThis task, which involves the extraction of important\nevents, is related to the tasks of Retrospective Event\nDetection (Yang et al., 1998), or New Event Detec-\ntion, as deﬁned for example in Topic Detection and\nTracking (TDT) campaigns (Allan, 2002).\nThe majority of systems designed to tackle this\ntask make use of textual information in a bag-of-\nwords manner.\nThey use little temporal informa-\ntion, generally only using document metadata, such\nas the document creation time (DCT). The few sys-\ntems that do make use of temporal information (such\nas the now discontinued Google timeline), only ex-\ntract absolute, full dates (that feature a day, month\nand year). In our corpus, described in Section 3.1,\nwe found that only 7% of extracted temporal expres-\nsions are absolute dates.\n', 9, 0)
(313.19989013671875, 257.13092041015625, 540.0, 568.9855346679688, 'We distinguish our work from that of previous re-\nsearchers in that we have focused primarily on ex-\ntracted temporal information as opposed to other\ntextual content. We show that using linguistic tem-\nporal processing helps extract important events in\ntexts. Our system extracts a maximum of temporal\ninformation and uses only this information to detect\nsalient dates for the construction of event timelines.\nOther types of content are used for initial thematic\ndocument retrieval. Output is a list of dates, ranked\nfrom most important to least important with respect\nto the given topic. Each date is presented with a set\nof relevant sentences.\nWe can see this work as a new, easily evaluable\ntask of “date extraction”, which is an important com-\nponent of timeline summarization.\nIn what follows, we ﬁrst review some of the re-\nlated work in Section 2. Section 3 presents the re-\nsources used and gives an overview of the system.\nThe system used for temporal analysis is described\nin Section 4, and the strategy used for indexing and\nﬁnding salient dates, as well as the results obtained,\nare given in Section 51.\n', 10, 0)
(313.19989013671875, 579.2941284179688, 402.2900390625, 594.8478393554688, '2\nRelated Work\n', 11, 0)
(313.19989013671875, 602.3800659179688, 540.0, 669.7225341796875, 'The ISO-TimeML language (Pustejovsky et al.,\n2010) is a speciﬁcation language for manual anno-\ntation of temporal information in texts, but, to the\nbest of our knowledge, it has not yet actually been\nused in information retrieval systems.\nNeverthe-\n', 12, 0)
(313.1999816894531, 677.7907104492188, 540.0045776367188, 722.51953125, '1This work has been partially funded by French National\nResearch Agency (ANR) under project Chronolines (ANR-10-\nCORD-010). We would like to thank the French News Agency\n(AFP) for providing us with the corpus.\n', 13, 0)

page suivante
(72.0, 72.87897491455078, 298.80023193359375, 723.0656127929688, 'less, (Alonso et al., 2007; Alonso, 2008; Kanhabua,\n2009) and (Mestl et al., 2009), among others, have\nhighlighted that the analysis of temporal informa-\ntion is often an essential component in text under-\nstanding and is useful in a wide range of informa-\ntion retrieval applications. (Harabagiu and Bejan,\n2005; Saquete et al., 2009) highlight the importance\nof processing temporal expressions in Question An-\nswering systems. For example, in the TREC-10 QA\nevaluation campaign, more than 10% of questions\nrequired an element of temporal processing in order\nto be correctly processed (Li et al., 2005a). In multi-\ndocument summarization, temporal processing en-\nables a system to detect redundant excerpts from\nvarious texts on the same topic and to present re-\nsults in a relevant chronological order (Barzilay and\nElhadad, 2002). Temporal processing is also useful\nfor aiding medical decision-making. (Kim and Choi,\n2011) present work on the extraction of temporal in-\nformation in clinical narrative texts. Similarly, (Jung\net al., 2011) present an end-to-end system that pro-\ncesses clinical records, detects events and constructs\ntimelines of patients’ medical histories.\nThe various editions of the TDT task have given\nrise to the development of different systems that de-\ntect novelty in news streams (Allan, 2002; Kumaran\nand Allen, 2004; Fung et al., 2005). Most of these\nsystems are based on statistical bag-of-words mod-\nels that use similarity measures to determine prox-\nimity between documents (Li et al., 2005b; Brants\net al., 2003). (Smith, 2002) used spatio-temporal in-\nformation from texts to detect events from a digital\nlibrary. His method used place/time collocations and\nranked events according to statistical measures.\nSome efforts have been made for automatically\nbuilding textual and graphical timelines.\nFor ex-\nample, (Allan et al., 2001) present a system that\nuses measures of pertinence and novelty to con-\nstruct timelines that consist of one sentence per date.\n(Chieu and Lee, 2004) propose a similar system that\nextracts events relevant to a query from a collection\nof documents. Important events are those reported\nin a large number of news articles and each event is\nconstructed according to one single query and rep-\nresented by a set of sentences. (Swan and Allen,\n2000) present an approach to generating graphical\ntimelines that involves extracting clusters of noun\nphrases and named entities. More recently, (Yan et\n', 0, 0)
(313.20001220703125, 72.87915802001953, 540.0000610351562, 126.67166137695312, 'al., 2011b; Yan et al., 2011a) used a summarization-\nbased approach to automatically generate timelines,\ntaking into account the evolutionary characteristics\nof news.\n', 1, 0)
(313.20001220703125, 138.4862060546875, 496.36566162109375, 154.0399169921875, '3\nResources and System Overview\n', 2, 0)
(313.20001220703125, 162.2574920654297, 396.1200866699219, 176.45022583007812, '3.1\nAFP Corpus\n', 3, 0)
(313.20001220703125, 181.61219787597656, 540.0001831054688, 289.6017150878906, 'For this work, we used a corpus of newswire texts\nprovided by the AFP French news agency. The En-\nglish AFP corpus is composed of 1.3 million texts\nthat span the 2004-2011 period (511 documents/day\nin average and 426 millions words). Each document\nis an XML ﬁle containing a title, a date of creation\n(DCT), set of keywords, and textual content split\ninto paragraphs.\n', 4, 0)
(313.20001220703125, 301.0404968261719, 423.3055725097656, 315.2332458496094, '3.2\nAFP Chronologies\n', 5, 0)
(313.20001220703125, 320.39422607421875, 540.0000610351562, 455.4827575683594, 'AFP “chronologies” (textual event timelines) are a\nspeciﬁc type of articles written by AFP journal-\nists in order to contextualize current events. These\nchronologies may concern any topic discussed in the\nmedia, and consist in a list of dates (typically be-\ntween 10 and 20) associated with a text describing\nthe related event(s). Figure 1 shows an example of\nsuch a chronology. Further examples are given in\nFigure 2. We selected 91 chronologies satisfying the\nfollowing constraints:\n', 6, 0)
(324.5820007324219, 469.21527099609375, 540.0005493164062, 550.1067504882812, '• All dates in the chronologies are between 2004\nand 2011 to be sure that the related events\nare described in the corpus.\nFor example,\n“Chronology of climax to Vietnam War” was\nexcluded because its corresponding dates do\nnot appear in the content of the articles.\n', 7, 0)
(324.5820007324219, 562.4692993164062, 539.9999389648438, 656.9097290039062, '• All dates in the chronology are anterior to the\nchronology’s creation date. For example, the\nchronology “Space in 2005: A calendar”, pub-\nlished in January 2005 and listing scheduled\nevents, was not selected (because almost no\nrocket launches ﬁnally happened on the ex-\npected day).\n', 8, 0)
(324.5820007324219, 669.2722778320312, 540.00390625, 723.065673828125, '• The temporal granularity of the chronology is\nthe day. For example, “A timeline of how the\nLondon transport attacks unfolded”, relating\nthe events hour by hour, is not in our focus.\n', 9, 0)

page suivante
(75.38700103759766, 73.91233825683594, 206.9419403076172, 84.48265075683594, '<NewsML Version="1.2">\n', 0, 0)
(80.36888885498047, 91.84532165527344, 293.1214904785156, 407.5815124511719, '<NewsItem xml:lang="en">\n<HeadLine>Key\ndates\nin\nThai-\nland’s\npolitical\ncrisis</HeadLine>\n<DateId>20100513T100519Z</DateId>\n<NameLabel>Thailand-politics</NameLabel>\n<DataContent>\n<p>The following is a timeline of events since\nthe protests began, soon after Thailand’s Supreme\nCourt conﬁscated 1.4 billion dollars of Thaksin’s\nwealth for abuse of power.</p>\n<p>March 14: Tens of thousands of Red Shirts\ndemonstrate in the capital calling for Abhisit’s gov-\nernment to step down, [...]</p>\n<p>March 28: The government and the Reds en-\nter into talks but hit a stalemate after two days\n[...]</p>\n<p>April 3: Tens of thousands of protesters move\nfrom Bangkok’s historic district into the city’s com-\nmercial heart [...]</p>\n<p>April 7: Abhisit declares state of emergency\nin capital after Red Shirts storm parliament.</p>\n<p>April 8: Authorities announce arrest warrants\nfor protest leaders.</p>\n. . .\n</DataContent>\n</NewsItem>\n', 1, 0)
(75.38688659667969, 413.50958251953125, 129.51182556152344, 425.5145263671875, '</NewsML>\n', 2, 0)
(85.52999877929688, 435.03955078125, 285.27008056640625, 447.04449462890625, 'Figure 1: Example of an AFP manual chronology.\n', 3, 0)
(72.0, 468.4109802246094, 298.8002014160156, 535.75244140625, 'For\nlearning\nand\nevaluation\npurposes,\nall\nchronologies were converted to a single XML\nformat.\nEach document was manually associated\nwith a user search query made up of the keywords\nrequired to retrieve the chronology.\n', 4, 0)
(72.0, 546.6863403320312, 177.21827697753906, 560.8790893554688, '3.3\nSystem Overview\n', 5, 0)
(71.99999237060547, 565.7520141601562, 298.8057861328125, 701.4424438476562, 'Figure 3 shows the general architecture of the sys-\ntem. First, pre-processing of the AFP corpus tags\nand normalizes temporal expressions in each of the\narticles (step x in the Figure). Next, the corpus is\nindexed by the Lucene search engine2 (step y).\nGiven a query, a number of documents are re-\ntrieved by Lucene (z). These documents can be ﬁl-\ntered ({), and dates are extracted from the remain-\ning documents. These dates are then ranked in order\nto show the most important ones to the user (|), to-\n', 6, 0)
(84.65299987792969, 710.6676635742188, 217.25509643554688, 722.1250610351562, '2http://lucene.apache.org\n', 7, 0)
(316.5870056152344, 73.00152587890625, 534.3194580078125, 204.44801330566406, '- Chronology of 18 months of trouble in Ivory Coast\n- Chechen rebels’ history of hostage-takings\n- Iraqi political wrangling since March 7 election\n- Athletics: Timeline of men’s 800m world record\n- Major accidents in Chinese mines\n- Space in 2005: A calendar\n- Developments in Iranian nuclear standoff\n- Chronology of climax to Vietnam War\n- Timeline of ex-IMF chief’s sex attack case\n- A timeline of how the London transport attacks un-\nfolded\n', 8, 0)
(343.2829895019531, 215.75054931640625, 509.91741943359375, 227.75547790527344, 'Figure 2: Examples of AFP chronologies.\n', 9, 0)
(371.83099365234375, 413.41156005859375, 481.3697509765625, 425.41650390625, 'Figure 3: System overview.\n', 10, 0)
(313.1999816894531, 449.8009948730469, 504.3817138671875, 462.94647216796875, 'gether with the sentences that contain them.\n', 11, 0)
(313.1999816894531, 471.9830322265625, 514.1430053710938, 487.5367431640625, '4\nTemporal and Linguistic Processing\n', 12, 0)
(313.199951171875, 494.1050109863281, 540.0001220703125, 574.9964599609375, 'In this section, we describe the linguistic and tempo-\nral information extracted during the pre-processing\nphase and how the extraction is carried out.\nWe\nrely on the powerful linguistic analyzer XIP (A¨ıt-\nMokhtar et al., 2002), that we adapted for our pur-\nposes.\n', 13, 0)
(313.199951171875, 583.6572875976562, 356.5309143066406, 597.8500366210938, '4.1\nXIP\n', 14, 0)
(313.199951171875, 601.5260009765625, 540.0001831054688, 723.0654296875, 'The linguistic analyzer we use performs a deep syn-\ntactic analysis of running text.\nIt takes as input\nXML ﬁles and analyzes the textual content enclosed\nin the various XML tags in different ways that are\nspeciﬁed in an XML guide (a ﬁle providing instruc-\ntions to the parser, see (Roux, 2004) for details).\nXIP performs complete linguistic processing rang-\ning from tokenization to deep grammatical depen-\ndency analysis. It also performs named entity recog-\n', 15, 0)

page suivante
(72.0, 72.87897491455078, 298.8002014160156, 275.9495544433594, 'nition (NER) of the most usual named entity cat-\negories and recognizes temporal expressions. Lin-\nguistic units manipulated by the parser are either\nterminal categories or chunks. Each of these units\nis associated with an attribute-value matrix that con-\ntains the unit’s relevant morphological, syntactic and\nsemantic information.\nLinguistic constituents are\nlinked by oriented and labelled n-ary relations de-\nnoting syntactic or semantic properties of the input\ntext. A Java API is provided with the parser so that\nall linguistic structures and relations can be easily\nmanipulated by Java code.\nIn the following subsections, we give details of\nthe linguistic information that is used for the detec-\ntion of salient dates.\n', 0, 0)
(72.0, 285.6153564453125, 220.17832946777344, 299.80810546875, '4.2\nNamed Entity Recognition\n', 1, 0)
(72.0, 303.9541015625, 298.80029296875, 425.4936218261719, 'Named Entity (NE) Recognition is one of the out-\nputs provided by XIP. NEs are represented as unary\nrelations in the parser output. We used the exist-\ning NE recognition module of the English grammar\nwhich tags the following NE types: location names,\nperson names and organization names. Ambigu-\nous NE types (ambiguity between type location or\norganization for country names for instance) are\nalso considered.\n', 2, 0)
(72.00001525878906, 435.159423828125, 183.7310028076172, 449.3521728515625, '4.3\nTemporal Analysis\n', 3, 0)
(72.00001525878906, 453.4981689453125, 298.80023193359375, 588.586669921875, 'A previous module for temporal analysis was de-\nveloped and integrated into the English grammar\n(Hag`ege and Tannier, 2008), and evaluated during\nTempEval campaign (Verhagen et al., 2007). This\nmodule was adapted for tagging salient dates. Our\ngoal with temporal analysis is to be able to tag and\nnormalize3 a selected subset of temporal expressions\n(TEs) which we consider to be relevant for our task.\nThis subset of expressions is described in the follow-\ning sections.\n', 4, 0)
(72.00001525878906, 596.7804565429688, 174.72012329101562, 610.9732055664062, '4.3.1\nAbsolute Dates\n', 5, 0)
(72.0, 613.6461791992188, 298.8002624511719, 680.9886474609375, 'Absolute dates are dates that can be normalized\nwithout external or contextual knowledge. This is\nthe case, for instance, of “On January 5th 2003”.\nIn these expressions, all information needed for nor-\nmalization is contained in the linguistic expression.\n', 6, 0)
(72.0, 688.7496948242188, 298.8049621582031, 722.51953125, '3We call normalization the operation of turning a temporal\nexpression into a formated, fully speciﬁed representation. This\nincludes ﬁnding the absolute value of relative dates.\n', 7, 0)
(313.20001220703125, 72.87897491455078, 540.0001831054688, 126.67147827148438, 'However, absolute dates are relatively infrequent in\nour corpus (7%), so in order to broaden the cover-\nage for the detection of salient dates, we decided to\nconsider relative dates, which are far more frequent.\n', 8, 0)
(313.20001220703125, 135.84226989746094, 435.0873107910156, 150.03500366210938, '4.3.2\nDCT-relative Dates\n', 9, 0)
(313.20001220703125, 153.2689971923828, 540.0035400390625, 478.0456237792969, 'DCT-relative temporal expressions are those\nwhich are relative to the creation date of the docu-\nment. This class represents 40% of dates extracted\nfrom the AFP corpus. Unlike the absolute dates, the\nlinguistic expression does not provide all the infor-\nmation needed for normalization. External informa-\ntion is required, in particular, the date which corre-\nsponds to the moment of utterance. In news articles,\nthis is the DCT. Two sub-classes of relative TEs can\nbe distinguished. The ﬁrst sub-class only requires\nknowledge of the DCT value to perform the normal-\nization. This is the case of expressions like next Fri-\nday, which correspond to the calendar date of the\nﬁrst Friday following the DCT. The second sub-class\nrequires further contextual knowledge for normal-\nization. For example, on Friday will correspond ei-\nther to last Friday or to next Friday depending on\nthe context where this expression appears (e.g. He\nis expected to come on Friday corresponds to next\nFriday while He arrived on Friday corresponds to\nlast Friday). In such cases, the tense of the verb\nthat governs the TE is essential for normalization.\nThis information is provided by the linguistic analy-\nsis carried out by XIP.\n', 10, 0)
(313.20001220703125, 487.2164001464844, 444.4036865234375, 501.4091491699219, '4.3.3\nUnderspeciﬁed Dates\n', 11, 0)
(313.20001220703125, 504.64215087890625, 540.0001220703125, 639.7305908203125, 'Considering the kind of corpus we deal with\n(news), we decided to consider TEs whose granu-\nlarity is at least equal to a day. As a result, TEs\nwere normalized to a numerical YYYYMMDD for-\nmat (where YYYY corresponds to the year, MM to\nthe month and DD to the day). In case of TEs with\na granularity superior to the day or month, DD and\nMM ﬁelds remain unspeciﬁed accordingly. How-\never, these underspeciﬁed dates are not used in our\nexperiments.\n', 12, 0)
(313.20001220703125, 650.3734130859375, 482.29095458984375, 664.566162109375, '4.4\nModality and Reported Speech\n', 13, 0)
(313.20001220703125, 669.2720947265625, 540.0, 723.0655517578125, 'An important issue that can affect the calculation of\nsalient dates is the modality associated with time-\nstamped events in text. For instance, the status of a\nsalient date candidate in a sentence like “The meet-\n', 14, 0)

page suivante
(71.99999237060547, 72.87897491455078, 298.805419921875, 248.61453247070312, 'ing takes place on Friday” has to be distinguished\nfrom the one in “The meeting should take place on\nFriday” or “The meeting will take place on Friday,\nMr. Hong said”. The time-stamped event meeting\ntakes place is factual in the ﬁrst example and can\nbe taken as granted. In the second and third exam-\nples, however, the event does not necessarily occur.\nThis is expressed by the modality introduced by the\nmodal auxiliary should (second example), or by the\nuse of the future tense or reported speech (third ex-\nample). We annotate TEs with information regard-\ning the factuality of the event they modify. More\nspeciﬁcally, we consider the following features:\n', 0, 0)
(71.99998474121094, 257.2283020019531, 298.8002624511719, 311.4135437011719, 'Events that are mentioned in the future:\nIf a\ntime-stamped event is in the future tense, we add a\nspeciﬁc attribute MODALITY with value FUTURE to\nthe corresponding TE annotation.\n', 1, 0)
(71.99998474121094, 320.02734375, 298.80462646484375, 374.21258544921875, 'Events used with a modal verb:\nIf a time-\nstamped event is introduced by a modal verb such\nas should or would, then attribute MODALITY to the\ncorresponding TE annotation has the value MODAL.\n', 2, 0)
(72.0, 382.8263854980469, 298.80023193359375, 518.306640625, 'Reported speech verbs:\nReported speech verbs\n(or verbs of speaking) introduce indirect or reported\nspeech.\nWe dealt with time-stamped events gov-\nerned by a reported speech verb, or otherwise ap-\npearing in reported speech. Once again, XIP’s lin-\nguistic analysis provided the necessary information,\nincluding the marking of reported speech verbs and\nclause segmentation of complex sentences. If a rel-\nevant TE modiﬁes a reported speech verb, the anno-\ntation of this TE contains a speciﬁc attribute, DE-\n', 3, 0)
(72.0000228881836, 518.711181640625, 298.8030090332031, 654.1566162109375, 'CLARATION=”YES”.\nIf the relevant TE modiﬁes\na verb that appears in a clause introduced by a re-\nported speech verb then the annotation contains the\nattribute REPORTED=”YES”.\nNote that the different annotations can be com-\nbined (e.g. modality and reported speech can occur\nfor a same time-stamped event). For example, the\nTE Friday in “The meeting should take place on Fri-\nday, Mr. Hong said” is annotated with both modality\nand reported speech attributes.\n', 4, 0)
(72.00005340576172, 664.242431640625, 248.56387329101562, 678.4351806640625, '4.5\nCorpus-dependent Special Cases\n', 5, 0)
(72.00005340576172, 682.8211669921875, 298.8002014160156, 723.0656127929688, 'While we developed the linguistic and temporal an-\nnotators, we took into account some speciﬁcities of\nour corpus.\nWe decided that the TEs today and\n', 6, 0)
(316.5870056152344, 73.21723937988281, 534.318115234375, 193.61062622070312, '<DCT value="20050105"/>\n<EC TYPE="TIMEX" value="unknown">The year\n2004</EC> was the deadliest\n<EC TYPE="TIMEX"\nvalue="unknown">in a decade</EC> for journalists\naround the world, mainly because of the number of reporters\nkilled\nin\n<EC\nTYPE="LOCORG">Iraq</EC>,\nthe\nmedia\nrights\ngroup\n<EN\nTYPE="ORG">Reporters\nSans\nFrontieres</EN>\n(Reporters\nWithout\nBor-\nders)\nsaid\n<EC\nTYPE="DATE" SUBTYPE="REL"\nREF="ST" DECLARATION="YES" value\n="20050105">Wednesday</EC>.\n', 7, 0)
(319.7720031738281, 204.967529296875, 533.429931640625, 216.9724578857422, 'Figure 4: Example of XIP output for a sample article.\n', 8, 0)
(313.1999816894531, 236.61195373535156, 540.0035400390625, 385.2494812011719, 'now were not relevant for the detection of salient\ndates. In the AFP news corpus, these expressions\nare mostly generic expressions synomymous with\nnowadays and do not really time-stamp an event\nwith respect to the DCT. Another speciﬁcity of the\ncorpus is the fact that if the DCT corresponds to a\nMonday, and if an event in a past tense is described\nwith the associated TE on Monday or Monday, it\nmeans that this event occurs on the DCT day itself,\nand not on the Monday before. We adapted the TE\nnormalizer to these special cases.\n', 9, 0)
(313.1999816894531, 393.96826171875, 476.5418701171875, 408.1610107421875, '4.6\nImplementation and Example\n', 10, 0)
(313.1999816894531, 411.8379821777344, 540.0044555664062, 723.0654296875, 'As said previously, a NER module is integrated into\nthe XIP parser, which we used “as is”. The TE tag-\nger and normalizer was adapted from (Hag`ege and\nTannier, 2008). We used the Java API provided with\nthe parser to perform the annotation and normal-\nization of TEs.\nThe output for the linguistic and\ntemporal annotation consists in XML ﬁles where\nonly selected information is kept (structural infor-\nmation distinguishing headlines from news content,\nDCT), and enriched with the linguistic annotations\ndescribed before (NEs and TEs with relevant at-\ntributes corresponding to the normalization and typ-\ning). Information concerning modality, future tense\nand reported speech, appears as attributes on the TE\ntag. Figure 4 shows an example of an analyzed ex-\ncerpt of a news article.\nIn this news excerpt, only one TE (Wednesday) is\nnormalized as both The year 2004 and in a decade\nare not considered to be relevant. The ﬁrst one being\na generic TE and the second one being of granular-\nity superior to a year. The annotation of the relevant\nTE has the attribute indicating that it time-stamps an\nevent realized by a reported speech verb. The nor-\n', 11, 0)

page suivante
(72.0, 72.87897491455078, 298.80023193359375, 221.51651000976562, 'malized value of the TE corresponds to the 5th of\nJanuary 2005, which is a Wednesday. NEs are also\nannotated.\nIn the entire AFP corpus, 11.5 millions temporal\nexpressions were detected, among which 845,000\nabsolute dates (7%) and 4.6 millions normalized\nrelative dates (40%).\nAlthough we have not yet\nevaluated our tagging of relative dates, the system\non which our current date normalization is based\nachieved good results in the TempEval (Verhagen et\nal., 2007) campaign.\n', 0, 0)
(72.0, 230.0640869140625, 217.45892333984375, 245.6177978515625, '5\nExperiments and Results\n', 1, 0)
(72.0, 251.6980743408203, 298.8002014160156, 359.6875915527344, 'In Section 5.1, we propose two baseline approaches\nin order to give a good idea of the difﬁculty of the\ntask (Section 5.4 also discusses this point). In Sec-\ntion 5.2, we present our experiments using simple\nﬁltering and statistics on dates calculated by Lucene.\nFinally, Section 5.3 gives details of our experiments\nwith a learning approach. In our experiments, we\nused three different values to rank dates:\n', 2, 0)
(83.38200378417969, 366.2831115722656, 298.7970275878906, 392.97760009765625, '• occ(d) is the number of textual units (docu-\nments or sentences) containing the date d.\n', 3, 0)
(83.38201904296875, 400.97711181640625, 298.80303955078125, 454.7696228027344, '• Lucene provides ranked documents together\nwith their relevance score. luc(d) is the sum of\nLucene scores for textual units containing the\ndate d.\n', 4, 0)
(83.38201141357422, 462.7691345214844, 274.9181823730469, 483.3218994140625, '• An adaptation of classical tf.idf for dates:\n', 5, 0)
(135.95401000976562, 482.3243103027344, 246.98199462890625, 500.6134033203125, 'tf.idf(d) = f(d).log\nN\n', 6, 0)
(230.93099975585938, 497.1871643066406, 255.45872497558594, 508.09625244140625, 'df(d)\n', 7, 0)
(93.81797790527344, 514.0399780273438, 298.79595947265625, 567.8323974609375, 'where f(d) is the number of occurrences of\ndate d in the sentence (generally, f(d) = 1), N\nis the number of indexed sentences and df(d)\nis the number of sentences containing date d.\n', 8, 0)
(71.99998474121094, 574.427978515625, 298.8001708984375, 723.0653686523438, 'In all experiments (including baselines), timelines\nhave been built by considering only dates between\nthe ﬁrst and the last dates of the corresponding man-\nual chronology. Processing runs were evaluated on\nmanually-written chronologies (see Section 3.2) ac-\ncording to Mean Average Precision (MAP), which\nis a widely accepted metric for ranked lists. MAP\ngives a higher weight to higher ranked elements than\nlower ranked elements.\nSigniﬁcance of evaluation\nresults are indicated by the p-value results of Stu-\ndent’s t-test (t(90) = 1.9867).\n', 9, 0)
(327.1090087890625, 71.56158447265625, 421.7637023925781, 83.4569320678711, 'Baselines “only DCTs”\n', 10, 0)
(339.06500244140625, 84.364501953125, 524.3040161132812, 99.0542984008789, 'Model\nBLocc\nDCT\nBLluc\nDCT\nBLtf.idf\nDCT\n', 11, 0)
(339.06500244140625, 97.132568359375, 521.634521484375, 109.13750457763672, 'MAP Score\n0.5036\n0.5521\n0.5523\n', 12, 0)
(327.1090087890625, 109.486572265625, 455.7958984375, 121.38191986083984, 'Baselines “only absolute dates”\n', 13, 0)
(339.06500244140625, 122.2896728515625, 524.3040161132812, 137.0554656982422, 'Model\nBLocc\nabs\nBLluc\nabs\nBLtf.idf\nabs\n', 14, 0)
(339.06500244140625, 135.05657958984375, 521.634521484375, 147.06150817871094, 'MAP Score\n0.2627\n0.2782\n0.2778\n', 15, 0)
(327.1090087890625, 147.41058349609375, 526.0919189453125, 159.30592346191406, 'Baselines “absolute dates or alternatively DCTs”\n', 16, 0)
(339.06500244140625, 160.2135009765625, 524.3040161132812, 174.75230407714844, 'Model\nBLocc\nmix\nBLluc\nmix\nBLtf.idf\nmix\n', 17, 0)
(339.06500244140625, 172.9815673828125, 521.634521484375, 184.9864959716797, 'MAP Score\n0.4005\n0.4110\n0.4135\n', 18, 0)
(348.2550048828125, 194.71954345703125, 504.94677734375, 206.72447204589844, 'Table 1: MAP results for baseline runs.\n', 19, 0)
(313.20001220703125, 224.5272674560547, 403.51641845703125, 238.72000122070312, '5.1\nBaseline Runs\n', 20, 0)
(313.20001220703125, 242.0792694091797, 540.0025634765625, 368.9664611816406, 'BLDCT . Indexing and search were done at docu-\nment level (i.e. each AFP article, with its title\nand keywords, is a document). Given a query,\nthe top 10,000 documents were retrieved. In\nthese runs, only the DCT for each document\nwas considered. Dates were ranked by one of\nthe three values described above (occ, luc or\ntf.idf) leading to runs BLocc\nDCT , BLluc\nDCT and\nBLtfidf\nDCT .\n', 21, 0)
(313.1999206542969, 374.6622619628906, 540.0049438476562, 459.46942138671875, 'BLabs. Indexing and search were done at sentence\nlevel (document title and keywords are added\nto sentence text). Given a query, the top 10,000\nsentences were retrieved. Only absolute dates\nin these sentences were considered. We thus\nobtained runs BLocc\nabs, BLluc\nabs and BLtfidf\nabs .\n', 22, 0)
(335.0179443359375, 460.908935546875, 539.9998779296875, 541.8004150390625, 'Note that in this baseline, as well as in all the\nsubsequent runs, the information unit was the\nsentence because a date was associated to a\nsmall part of the text. The rest of the document\ngenerally contained text that was not related to\nthe speciﬁc date.\n', 23, 0)
(313.199951171875, 550.9302368164062, 539.9998168945312, 591.56640625, 'BLmix. Same as BLabs, except that sentences con-\ntaining no absolute dates were considered and\nassociated to the DCT.\n', 24, 0)
(313.1999816894531, 602.1039428710938, 540.0000610351562, 655.8973999023438, 'Table 1 shows results for these baseline runs.\nUsing only DCTs with Lucene scores or tf.idf(d)\nalready yielded interesting results,\nwith MAP\naround 0.55.\n', 25, 0)
(313.1999816894531, 664.876220703125, 528.3381958007812, 692.6189575195312, '5.2\nSalient Date Extraction with XIP Results\nand Simple Filtering\n', 26, 0)
(313.1999816894531, 696.3709106445312, 540.0000610351562, 723.0653686523438, 'In these experiments, we considered a Lucene index\nto be built as follows: each document was taken to\n', 27, 0)

page suivante
(86.75499725341797, 71.56158447265625, 289.52447509765625, 83.56652069091797, 'Model\nMAP Score Model\nMAP Score\n', 0, 0)
(78.78500366210938, 85.90753173828125, 202.50054931640625, 97.8028793334961, 'Salient date runs with all dates\n', 1, 0)
(86.75499725341797, 97.95257568359375, 270.1571044921875, 109.95751190185547, 'SDluc\n0.6962\nSDtf.idf\n0.6982\n', 2, 0)
(78.78500366210938, 112.298583984375, 203.88534545898438, 124.19393157958984, 'Salient dates runs with ﬁltering\n', 3, 0)
(86.75499725341797, 124.70367431640625, 270.1571044921875, 139.3925018310547, 'SDluc\nR\n0.6975\nSDtf.idf\nR\n0.6996\n', 4, 0)
(86.75499725341797, 137.920654296875, 286.287353515625, 152.60948181152344, 'SDluc\nF\n0.6967\nSDtf.idf\nF\n0.6993\n∗∗\n', 5, 0)
(86.75499725341797, 151.13763427734375, 282.2076721191406, 165.8274383544922, 'SDluc\nM\n0.6978\nSDtf.idf\nM\n0.7005\n∗\n', 6, 0)
(86.75499725341797, 164.3546142578125, 286.287353515625, 179.04441833496094, 'SDluc\nD\n0.7066\n∗∗\nSDtf.idf\nD\n0.7091\n∗∗\n', 7, 0)
(86.75499725341797, 177.5716552734375, 286.287353515625, 192.26145935058594, 'SDluc\nF MD\n0.7086\n∗∗\nSDtf.idf\nF MD\n0.7112\n∗∗\n', 8, 0)
(86.75499725341797, 190.78863525390625, 286.287353515625, 205.4784393310547, 'SDluc\nRF MD\n0.7127\n∗∗\nSDtf.idf\nRF MD\n0.7146\n∗∗\n', 9, 0)
(71.99996948242188, 212.9415283203125, 298.8050231933594, 284.7225036621094, 'Table 2: MAP results for salient date extraction with XIP\nand simple ﬁltering. Signiﬁcance of ﬁltering improve-\nment is indicated by Student t-test against no ﬁltering (∗:\np < 0.05 (signiﬁcant); ∗∗: p < 0.01 (highly signiﬁcant)).\nImprovement of using tf.idf(d) rather than occ(d) is also\nhighly signiﬁcant.\n', 10, 0)
(71.99995422363281, 304.6752624511719, 298.8058776855469, 602.9304809570312, 'be a sentence containing a normalized date. This\nsentence was indexed with the title and keywords of\nthe AFP article containing it. Given a query, the top\n10,000 documents were retrieved. Combinations be-\ntween the following ﬁltering operations were pos-\nsible, by removing all dates associated with a re-\nported speech verb (R), a modal verb (M) and/or\na future verb (F). All these ﬁltering operations were\nintended to remove references to events that were\nnot certain, thereby minimizing noise in results.\nThese processing runs are named SD runs, with\nindices representing the ﬁltering operations. For ex-\nample, a run obtained by ﬁltering modal and future\nverbs is called SDM,F . In all combinations, dates\nwere ranked by the sum of Lucene scores for these\nsentences (luc) or by tf.idf4.\nTable 2 presents the results for this series of exper-\niments. MAP values are much higher than for base-\nlines. Using tf.idf(d) is only very slightly better\nthan luc. Filtering operations bring some improve-\nment but the beneﬁts of these different techniques\nhave to be further investigated.\n', 11, 0)
(71.99995422363281, 612.0963745117188, 210.6328125, 626.2891235351562, '5.3\nMachine-Learning Runs\n', 12, 0)
(71.99995422363281, 630.1490478515625, 298.8001403808594, 670.3924560546875, 'We used our set of manually-written chronologies\nas a training corpus to perform machine learning\nexperiments. We used IcsiBoost5, an implementa-\n', 13, 0)
(72.0, 677.57666015625, 298.8045654296875, 722.1250610351562, '4We do not present runs where dates are ranked by the num-\nber of times they appear in retrieved sentences (occ), as we did\nfor baselines, since results are systematically lower.\n5http://code.google.com/p/icsiboost/\n', 14, 0)
(313.20001220703125, 72.87897491455078, 540.0033569335938, 343.4595642089844, 'tion of adaptative boosting (AdaBoost (Freund and\nSchapire, 1997)).\nIn our approach, we consider two classes: salient\ndates are dates that have an entry in the manual\nchronologies, while non-salient dates are all other\ndates. This choice does, however, represent an im-\nportant bias. The choices of journalists are indeed\nvery subjective, and chronologies must not exceed a\ncertain length, which means that relevant dates can\nbe thrown away. These issues will be discussed in\nSection 5.4.\nThe classiﬁer instances were not all sentences re-\ntrieved by the search engine. Using all sentences\nwould not yield a useful feature set. We rather ag-\ngregated all sentences corresponding to the same\ndate before learning the classiﬁer. Therefore, each\ninstance corresponded to a single date, and features\nwere ﬁgures concerning the set of sentences contain-\ning this date.\nFeatures used in this series of runs are as follows:\n', 15, 0)
(321.8550109863281, 349.9640808105469, 540.0040283203125, 457.95361328125, '1. Features representing the fact that the more\na date is mentioned, the more important it is\nlikely to be: 1) Sum of the Lucene scores for\nall sentences containing the date 2) Number of\nsentences containing the date 3) Ratio between\nthe total weights of the date and weights of all\nreturned dates 4) Ratio between the frequency\nof the date and frequency of all returned dates;\n', 16, 0)
(321.8550109863281, 465.9201354980469, 540.0040283203125, 533.2625732421875, '2. Features representing the fact that an important\nevent is still written about, a long time after it\noccurs: 1) Distance between the date and the\nmost recent mention of this date 2) Distance be-\ntween the date and the DCT;\n', 17, 0)
(321.8550109863281, 541.2281494140625, 540.0040893554688, 662.767578125, '3. Other features: 1) Lucene’s best ranking of the\ndate 2) Number of times where the date is ab-\nsolute in the text 3) Number of times where\nthe date is relative (but normalized) in the text\n4) Total number of keywords of the query in the\ntitle, sentence and named entities of retrieved\ndocuments 5) Number of times where the date\nmodiﬁes a reported speech verb or is extracted\nfrom reported speech.\n', 18, 0)
(313.20001220703125, 669.2721557617188, 540.000244140625, 723.0655517578125, 'We did not aim to classify dates, but rather to rank\nthem.\nInstead, we used the predicted probability\nP(d) returned by the classiﬁer, and mixed it with\nthe Lucene score of sentences, or with date tf.idf:\n', 19, 0)

page suivante
(142.3990020751953, 71.56158447265625, 239.73143005371094, 83.56652069091797, 'Model\nMAP Score\n', 0, 0)
(130.4429931640625, 85.90753173828125, 227.4188995361328, 97.8028793334961, 'Machine-Learning Runs\n', 1, 0)
(142.3990020751953, 98.3515625, 219.73910522460938, 112.1214370727539, 'MLluc\nbase\n0.7033\n', 2, 0)
(142.3990020751953, 110.39654541015625, 239.8543243408203, 122.6180419921875, 'MLluc\n0.7905\n∗∗\n', 3, 0)
(142.3990020751953, 122.4405517578125, 239.8543243408203, 134.6630859375, 'MLtf.idf\n0.7918\n∗∗\n', 4, 0)
(71.99999237060547, 144.1795654296875, 298.8008728027344, 210.77015686035156, 'Table 3: MAP results for salient date extraction with\nmachine-learning. MLluc\nbase used Lucene scores and only\nthe ﬁrst set of features described above.\nMLluc and\nMLtf.idf used the three sets of features.\nThey are both\nhighly signiﬁcant under t-test (p ≈ 6.10−4).\n', 5, 0)
(125.78601837158203, 244.38052368164062, 245.0047149658203, 263.3078308105469, 'score(d) = P(d) × val(d)\n', 6, 0)
(71.99995422363281, 266.30804443359375, 298.8001708984375, 416.9615783691406, 'where val(d) is either luc(d) or tf.idf(d).\nBecause the task is very subjective and (above\nall) because of the low quantity of learning data, we\nprefered not to opt for a “learning to rank” approach.\nWe evaluated this approach with a classic 4-fold\ncross-validation.\nOur 91 chronologies were ran-\ndomly divided into 4 sub-samples, each of them be-\ning used once as test data. The ﬁnal scores, pre-\nsented in Table 3, are the average of these 4 pro-\ncesses. As shown in this table, the learning approach\nimproves MAP results by about 0.05 point.\n', 7, 0)
(71.99995422363281, 429.3003845214844, 250.81103515625, 443.4931335449219, '5.4\nDiscussion and Final Experiment\n', 8, 0)
(71.99995422363281, 449.1711120605469, 298.8034362792969, 680.111572265625, 'Chronologies hand-written by journalists are a very\nuseful resources for evaluation of our system, as they\nare completely dissociated from our research and are\nan exact representation of the output we aim to ob-\ntain. However, assembling such a chronology is a\nvery subjective task, and no clear method for evalu-\nation agreement between two journalists seems im-\nmediately apparent.\nOnly experts can build such\nchronologies, and calculating this agreement would\nrequire at least two experts from each domain, which\nare hard to come by. One may then consider our sys-\ntem as a useful tool for building a chronology more\nobjectively.\nTo illustrate this point, we chose four speciﬁc top-\nics6 and showed one of our runs on each topic to an\nAFP expert for these subjects. We asked him to as-\nsess the ﬁrst 30 dates of these runs.\n', 9, 0)
(72.0, 688.7496948242188, 298.8006286621094, 722.51953125, '6Namely, “Arab revolt timeline for Morocco”, “Kyrgyzs-\ntan unrest timeline”, “Lebanon’s new government: a timeline”,\n“Libya timeline”.\n', 10, 0)
(365.2149963378906, 71.56158447265625, 483.6990661621094, 84.0044937133789, 'Topic\nAPC\nAPE\n', 11, 0)
(365.2149963378906, 85.90753173828125, 487.984130859375, 97.91246795654297, 'Morocco\n0.5847\n0.5718\n', 12, 0)
(365.2149963378906, 97.862548828125, 487.984130859375, 109.86748504638672, 'Kyrgyzstan\n0.6125\n0.9989\n', 13, 0)
(365.2149963378906, 109.81854248046875, 476.77630615234375, 121.82347869873047, 'Libya\n0.7856\n1\n', 14, 0)
(365.2149963378906, 121.7735595703125, 487.984130859375, 133.7784881591797, 'Lebanon\n0.4673\n0.7652\n', 15, 0)
(313.20001220703125, 143.51153564453125, 540.00244140625, 179.86546325683594, 'Table 4: Average precision results for manual evaluation\non 4 topics, against the original chronologies (APC), and\nthe expert assessment (APE).\n', 16, 0)
(313.2000427246094, 204.0550079345703, 540.0007934570312, 395.57354736328125, 'Table 4 presents results for this evaluation, com-\nparing average precision values obtained 1) against\nthe original, manual chronologies (APC), and 2)\nagainst the expert assessment (APE). These values\nshow that, for 3 runs out of 4, many dates returned\nby the system are considered as valid by the expert,\neven if not presented in the original chronology.\nEven if this experiment is not strong enough to\nlead to a formal conclusion (post-hoc evaluation\nwith only 4 topics and a single assessor), this tends\nto show that our system produces usable outputs and\nthat our system can be of help to journalists by pro-\nviding them with chronologies that are as useful and\nobjective as possible.\n', 17, 0)
(313.2000732421875, 412.5331115722656, 480.4772644042969, 428.0868225097656, '6\nConclusion and Future Work\n', 18, 0)
(313.2000732421875, 440.3770751953125, 540.000244140625, 710.95751953125, 'This article presents a task of “date extraction” and\nshows the importance of taking temporal informa-\ntion into consideration and how with relatively sim-\nple temporal processing, we were able to indirectly\npoint to important events using the temporal infor-\nmation associated with these events. Of course, as\nour ﬁnal goal consists in the detection of important\nevents, we need to take into account the textual con-\ntent. In future work, we envisage providing, together\nwith the detection of salient dates, a semantic analy-\nsis that will help determine the importance of events.\nAnother interesting direction in which we soon aim\nto work is to consider all textual excerpts that are as-\nsociated with salient dates, and use clustering tech-\nniques to determine if textual excerpts correspond to\nthe same event or not. Finally, as our news corpus\nis available both for English and French (compara-\nble corpus, not necessarily translations), we aim to\ninvestigate cross-lingual extraction of salient dates\nand salient events.\n', 19, 0)

page suivante
(72.0, 71.48199462890625, 127.54383850097656, 87.03570556640625, 'References\n', 0, 0)
(72.0, 93.57855224609375, 298.7996826171875, 141.49851989746094, 'Salah A¨ıt-Mokhtar, Jean-Pierre Chanod, and Claude\nRoux. 2002. Robustness beyond Shallowness: Incre-\nmental Deep Parsing. Natural Language Engineering,\n8:121–144.\n', 1, 0)
(72.00003051757812, 143.21356201171875, 298.8023681640625, 203.03953552246094, 'James Allan, Rahul Gupta, and Vikas Khandelwal. 2001.\nTemporal summaries of new topics. In Proceedings of\nthe 24th annual international ACM SIGIR conference\non Research and development in information retrieval,\nSIGIR ’01, pages 10–18.\n', 2, 0)
(72.00003051757812, 204.75360107421875, 298.7996826171875, 228.7135467529297, 'James Allan, editor. 2002. Topic Detection and Tracking.\nSpringer.\n', 3, 0)
(72.00003051757812, 230.4285888671875, 298.7986755371094, 278.298583984375, 'Omar Alonso, Ricardo Baeza-Yates, and Michael Gertz.\n2007.\nExploratory Search Using Timelines.\nIn\nSIGCHI 2007 Workshop on Exploratory Search and\nHCI Workshop.\n', 4, 0)
(72.00001525878906, 280.0136413574219, 298.7987976074219, 315.9285583496094, 'Omar Rogelio Alonso. 2008. Temporal information re-\ntrieval. Ph.D. thesis, University of California at Davis,\nDavis, CA, USA. Adviser-Gertz, Michael.\n', 5, 0)
(72.00003051757812, 317.64361572265625, 298.79998779296875, 365.5135192871094, 'Regina Barzilay and Noemie Elhadad.\n2002.\nInfer-\nring Strategies for Sentence Ordering in Multidocu-\nment News Summarization. Journal of Artiﬁcial In-\ntelligence Research, 17:35–55.\n', 6, 0)
(72.00003814697266, 367.22857666015625, 298.8006591796875, 439.00946044921875, 'Thorsten Brants, Francine Chen, and Ayman Farahat.\n2003. A system for new event detection. In Proceed-\nings of the 26th annual international ACM SIGIR con-\nference on Research and development in informaion\nretrieval, SIGIR ’03, pages 330–337, New York, NY,\nUSA. ACM.\n', 7, 0)
(72.00003051757812, 440.7235107421875, 298.8006591796875, 500.5494079589844, 'Hai Leong Chieu and Yoong Keok Lee. 2004. Query\nbased event extraction along a timeline. In Proceed-\nings of the 27th annual international ACM SIGIR con-\nference on Research and development in information\nretrieval, SIGIR ’04, pages 425–432.\n', 8, 0)
(72.00003051757812, 502.2634582519531, 298.7994384765625, 550.1343994140625, 'Yoav Freund and Robert E. Schapire. 1997. A Decision-\nTheoretic Generalization of On-Line Learning and an\nApplication to Boosting.\nJournal of Computer and\nSystem Sciences, 55(1):119–139.\n', 9, 0)
(72.00003814697266, 551.8484497070312, 298.80377197265625, 611.6743774414062, 'Gabriel Pui Cheong Fung, Jeffrey Xu Yu, Philip S. Yu,\nand Hongjun Lu. 2005. Parameter free bursty events\ndetection in text streams. In VLDB ’05: Proceedings\nof the 31st international conference on Very large data\nbases, pages 181–192.\n', 10, 0)
(72.00003051757812, 613.3394165039062, 298.7995910644531, 685.1693725585938, 'Caroline Hag`ege and Xavier Tannier. 2008. XTM: A Ro-\nbust Temporal Text Processor. In Computational Lin-\nguistics and Intelligent Text Processing, proceedings\nof 9th International Conference CICLing 2008, pages\n231–240, Haifa, Israel, February. Springer Berlin /\nHeidelberg.\n', 11, 0)
(72.00004577636719, 686.8844604492188, 298.7986145019531, 722.6897583007812, 'Sanda Harabagiu and Cosmin Adrian Bejan.\n2005.\nQuestion Answering Based on Temporal Inference. In\nProceedings of the Workshop on Inference for Textual\n', 12, 0)
(324.1090393066406, 73.75341796875, 540.0010375976562, 97.71337127685547, 'Question Answering, Pittsburg, Pennsylvania, USA,\nJuly.\n', 13, 0)
(313.2000427246094, 98.04345703125, 539.9996948242188, 181.7794647216797, 'Hyuckchul Jung, James Allen, Nate Blaylock, Will\nde Beaumont, Lucian Galescu, and Mary Swift. 2011.\nBuilding timelines from narrative clinical records: ini-\ntial results based-on deep natural language under-\nstanding. In Proceedings of BioNLP 2011 Workshop,\nBioNLP ’11, pages 146–154, Stroudsburg, PA, USA.\nAssociation for Computational Linguistics.\n', 14, 0)
(313.2000427246094, 182.10955810546875, 540.0001831054688, 253.8905487060547, 'Nattiya Kanhabua.\n2009.\nExploiting temporal infor-\nmation in retrieval of archived documents.\nIn Pro-\nceedings of the 32nd Annual International ACM SIGIR\nConference on Research and Development in Informa-\ntion Retrieval, SIGIR 2009, Boston, MA, USA, July 19-\n23, 2009, page 848.\n', 15, 0)
(313.20001220703125, 254.22064208984375, 539.9996948242188, 302.090576171875, 'Youngho Kim and Jinwook Choi.\n2011.\nRecogniz-\ning temporal information in korean clinical narra-\ntives through text normalization. Healthc Inform Res,\n17(3):150–5.\n', 16, 0)
(313.2000427246094, 302.4206237792969, 540.0043334960938, 374.2015075683594, 'Giridhar Kumaran and James Allen. 2004. Text clas-\nsiﬁcation and named entities for new event detection.\nIn SIGIR ’04: Proceedings of the 27th annual in-\nternational ACM SIGIR conference on Research and\ndevelopment in information retrieval, pages 297–304.\nACM.\n', 17, 0)
(313.2000732421875, 374.53155517578125, 540.0045166015625, 434.3574523925781, 'Wei Li, Wenjie Li, Qin Lu, and Kam-Fai Wong. 2005a.\nA Preliminary Work on Classifying Time Granulari-\nties of Temporal Questions. In Proceedings of Second\ninternational joint conference in NLP (IJCNLP 2005),\nJeju Island, Korea, oct.\n', 18, 0)
(313.2000427246094, 434.6865234375, 539.9986572265625, 506.4674072265625, 'Zhiwei Li, Bin Wang, Mingjing Li, and Wei-Ying Ma.\n2005b.\nA Probabilistic Model for Restrospective\nNews Event Detection.\nIn Proceedings of the 28th\nAnnual International ACM SIGIR Conference on Re-\nsearch and Development in Information Retrieval, Sal-\nvador, Brazil. ACM Press, New York City, NY, USA.\n', 19, 0)
(313.2000732421875, 506.7974853515625, 539.9996337890625, 554.6683959960938, 'Thomas Mestl, Olga Cerrato, Jon Ølnes, Per Myrseth,\nand Inger-Mette Gustavsen. 2009. Time Challenges -\nChallenging Times for Future Information Search. D-\nLib Magazine, 15(5/6).\n', 20, 0)
(313.2000732421875, 554.9974365234375, 540.0007934570312, 674.599365234375, 'James Pustejovsky, Kiyong Lee, Harry Bunt, and Lau-\nrent Romary.\n2010.\nIso-timeml: An international\nstandard for semantic annotation. In Nicoletta Calzo-\nlari (Conference Chair), Khalid Choukri, Bente Mae-\ngaard, Joseph Mariani, Jan Odijk, Stelios Piperidis,\nMike Rosner, and Daniel Tapias, editors, Proceed-\nings of the Seventh International Conference on Lan-\nguage Resources and Evaluation (LREC’10), Valletta,\nMalta, may. European Language Resources Associa-\ntion (ELRA).\n', 21, 0)
(313.2000732421875, 674.929443359375, 539.9994506835938, 722.7993774414062, 'Claude Roux. 2004. Annoter les documents XML avec\nun outil d’analyse syntaxique.\nIn 11`eme Confrence\nannuelle de Traitement Automatique des Langues Na-\nturelles, Fs, Maroc, April. ATALA.\n', 22, 0)

page suivante
(72.0, 73.70355224609375, 298.80194091796875, 133.5795135498047, 'Estela Saquete, Jose L. Vicedo, Patricio Mart´ınez-Barco,\nRafael Mu˜noz, and Hector Llorens. 2009. Enhancing\nQA Systems with Complex Temporal Question Pro-\ncessing Capabilities. Journal of Articiﬁal Intelligence\nResearch, 35:775–811.\n', 0, 0)
(72.0, 134.276611328125, 298.8025817871094, 194.1025848388672, 'David A. Smith. 2002. Detecting events with date and\nplace information in unstructured text. In JCDL ’02:\nProceedings of the 2nd ACM/IEEE-CS joint confer-\nence on Digital libraries, pages 191–196, New York,\nNY, USA. ACM.\n', 1, 0)
(72.0, 194.7996826171875, 298.8033752441406, 254.6256561279297, 'Russell Swan and James Allen. 2000. Automatic genera-\ntion of overview timelines. In Proceedings of the 23rd\nannual international ACM SIGIR conference on Re-\nsearch and development in information retrieval, SI-\nGIR ’00, pages 49–56, New York, NY, USA. ACM.\n', 2, 0)
(72.0, 255.32275390625, 298.80224609375, 339.05865478515625, 'Marc Verhagen, Robert Gaizauskas, Franck Schilder,\nMark Hepple, Graham Katz, and James Pustejovsky.\n2007. SemEval-2007 - 15: TempEval Temporal Rela-\ntion Identiﬁcation. In Proceedings of SemEval work-\nshop at ACL 2007, Prague, Czech Republic, June. As-\nsociation for Computational Linguistics, Morristown,\nNJ, USA.\n', 3, 0)
(72.0, 339.7567138671875, 298.79852294921875, 423.4925842285156, 'Rui Yan, Liang Kong, Congrui Huang, Xiaojun Wan, Xi-\naoming Li, and Yan Zhang.\n2011a.\nTimeline gen-\neration through evolutionary trans-temporal summa-\nrization. In Proceedings of the 2011 Conference on\nEmpirical Methods in Natural Language Processing,\nEMNLP 2011, 27-31 July 2011, Edinburgh, UK, pages\n433–443.\n', 4, 0)
(71.99998474121094, 424.18963623046875, 298.80169677734375, 519.8804931640625, 'Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong,\nXiaoming Li, and Yan Zhang.\n2011b.\nEvolution-\nary timeline summarization: a balanced optimization\nframework via iterative substitution.\nIn Proceeding\nof the 34th International ACM SIGIR Conference on\nResearch and Development in Information Retrieval,\nSIGIR 2011, Beijing, China, July 25-29, 2011, pages\n745–754.\n', 5, 0)
(72.0, 520.5785522460938, 298.8006286621094, 592.3585205078125, 'Y. Yang, T. Pierce, and J. G. Carbonell. 1998. A study on\nretrospective and on-line event detection. In Proceed-\nings of the 21st Annual International ACM SIGIR Con-\nference on Research and Development in Information\nRetrieval, Melbourne, Australia, August. ACM Press,\nNew York City, NY, USA.\n', 6, 0)

page suivante
