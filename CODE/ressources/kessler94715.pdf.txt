(107.55699920654297, 49.138877868652344, 504.4439392089844, 105.84580993652344, 'Extraction of terminology in the ﬁeld of\nconstruction\n', 0, 0)
(98.09001159667969, 144.3200225830078, 201.05908203125, 210.66746520996094, '1st R´emy Kessler\nUniversit´e Bretagne Sud\nCNRS 6074A\n56017 Vannes,France\nremy.kessler@univ-ubs.fr\n', 1, 0)
(250.34902954101562, 144.31996154785156, 349.7257385253906, 210.6674041748047, '2nd Nicolas B´echet\nUniversit´e Bretagne Sud\nCNRS 6074A\n56017 Vannes,France\nnicolas.bechet@irisa.fr\n', 2, 0)
(402.60809326171875, 144.3199005126953, 513.9102172851562, 210.66734313964844, '3rd Giuseppe Berio\nUniversit´e Bretagne Sud\nCNRS 6074A\n56017 Vannes,France\ngiuseppe.berio@univ-ubs.fr\n', 3, 0)
(48.96409606933594, 253.50421142578125, 300.0234069824219, 324.9814453125, 'Abstract—We describe a corpus analysis method to extract\nterminology from a collection of technical speciﬁcations in the\nﬁeld of construction. Using statistics and word n-grams analysis,\nwe extract the terminology of the domain and then perform\npruning steps with linguistic patterns and internet queries to\nimprove the quality of the ﬁnal terminology. Results are evaluated\nby using a manual evaluation carried out by 6 experts in the ﬁeld.\n', 4, 0)
(48.96409225463867, 333.07928466796875, 300.0236511230469, 354.74346923828125, 'Index Terms—terminology extraction, Internet queries, linguis-\ntic patterns.\n', 5, 0)
(135.62008666992188, 363.1714782714844, 213.3718719482422, 375.1764221191406, 'I. INTRODUCTION\n', 6, 0)
(48.96408462524414, 378.13848876953125, 300.02203369140625, 700.7252807617188, 'The current era is increasingly inﬂuenced by the prominence\nof smart data and mobile applications. The work presented\nin this paper has been carried out in one industrial project\n(VOCAGEN) aiming at automating the production of struc-\ntured data from human machine dialogues. Speciﬁcally, the\ntargeted application drives dialogues with people working in\na construction area for populating a database reporting key\ndata extracted from those dialogues. This application requires\ncomplex processing for both transcripting speeches but also for\ndriving dialogues. The ﬁrst process is required for good speech\nrecognition in a noisy environment. The second processing is\nrequired because the database needs to be populated with both\nright and complete data; indeed, people tend to apply a broad\n(colloquial) vocabulary and the transcripted words need to be\nused for ﬁlling in the corresponding data. Additionally, if some\ndata populate the database, additional data may be required\nfor completeness, thus the dialogue should enable to get those\nadditional data (e.g. if the word ”room” is recognised and used\nto populate the database, the location of the room must also\nbe got; this can be done by driving the dialogue).\nThe application provides people with “hand-free” device,\nenabling a complete, quick and standardized reporting. First\nusages of this application will be oriented to reporting failures\nand problems in constructions.\nThe two processing steps mentioned above require on the\none side a “language model” (for transcripting the sentences)\nand on the other side a “knowledge model” for driving the\n', 7, 0)
(311.97808837890625, 252.94232177734375, 563.0357055664062, 492.3790588378906, 'dialogue and correctly understanding the meaning of the word.\nThe knowledge model is mainly an ontology of the domain (in\nthis case, the construction domain) providing the standardized\nconcepts and their relationships. As well-known, building such\nknowledge models needs time and is costly; one of the earlier\nquestions raised by our industrial partners has been about\n“how to build, as automaticaly as possible, such a knowledge\nmodel”. This question is closely related to the interest of\nquickly adapting the application to other domains (than the\nconstruction one) for reaching new markets. We developed a\ncomplete methodology and system for partially answering the\nquestion, focusing on how to extract a relevant terminology\nfrom a collection of technical speciﬁcations.\nThe rest of the paper is organized as follow. Section II\npresent context of the project. Related work are reviewed in\nSection III. Section IV presents collected resources and some\nstatistics about them. Section V describes the methodology de-\nveloped for extracting relevant terms from collected resources.\nThe details about the evaluation are presented in Section VI-A\nand results obtained, are given in Section VI-B.\n', 8, 0)
(381.69708251953125, 501.46710205078125, 493.328125, 513.4720458984375, 'II. INDUSTRIAL CONTEXT\n', 9, 0)
(311.97802734375, 518.2630615234375, 563.036376953125, 697.6410522460938, 'Figure 1 presents the context of this work in VOCA-\nGEN project. Our industrial partner Script&Go1 develop an\napplication for the construction management dedicated to\ntouch devices and wishes to set up an oral dialogue module\nto facilitate on construction site seizure. The second industrial\npartner (Tykomz) develops a vocal recognition suite based on\ntoolkit sphynx 4 [1]. This toolkit includes hierarchical agglom-\nerative clustering methods using well-known measures such as\nBIC and CLR and provides elementary tools, such as segment\nand cluster generators, decoder and model trainers. Fitting\nthose elementary tools together is an easy way of developing\na speciﬁc diarization system. To work, it is necessary to build\na model of knowledge, i.e. a model describing the expressions\nthat must be recognized by the program. To improve the\nperformance of the system, this knowledge model must be\n', 10, 0)
(319.9480285644531, 708.1082153320312, 426.0820617675781, 718.6842041015625, '1http://www.scriptandgo.com/en/\n', 11, 0)

page suivante
(76.24296569824219, 172.7644500732422, 175.50003051757812, 181.93531799316406, ' \n \n', 0, 0)
(90.94300079345703, 195.3856201171875, 258.0440368652344, 204.98959350585938, 'Fig. 1. ﬁgure describing the context of the project\n', 1, 0)
(48.9640007019043, 217.7725830078125, 300.0215759277344, 313.4635314941406, 'powered by a domain-speciﬁc vocabulary. For example, in the\nsentence ”there is a stain of paint in the kitchen”, the system\nmust understand that it is a stain of paint and that the kitchen is\na room. To our knowledge, there is no ontology or taxonomy\nspeciﬁc to the construction industry in French. A version is\nunder development by [2] but ontology is in English and very\ngeneric. We therefore choose to extract useful knowledge from\ntextual data, and then, in a second step, to organize them.\n', 2, 0)
(128.11300659179688, 320.8175964355469, 220.880615234375, 332.8225402832031, 'III. RELATED WORKS\n', 3, 0)
(48.9640007019043, 336.38958740234375, 300.0225830078125, 719.244384765625, 'The goal of ontology learning (OL) is to build knowledge\nmodels from text. OL use NLP knowledge extraction tools\nto extract terminology (concepts) and links between them\n(relationships). The main approaches found in the literature are\nrule-based systems, statistical or learning based approaches.\nThe reference in the ﬁeld of rule-based systems was de-\nveloped by [3]. General Architecture for Text Engineering\n(GATE) is a Java collection of tools initially developed at the\nUniversity of Shefﬁeld since 1995. An alternative is offered by\nthe existing semi-automatic ontology learning text2onto [4].\nMore recently, [5] developed UIMA, a system that can be\npositioned as an alternative to GATE. Amongst other things,\nUIMA makes possible to generate rules from a collection of\nannotated documents. Exit, introduced by [6] is an iterative\napproach that ﬁnds the terms in an incremental way.\n[7] with TERMINAE is certainly the oldest statistic ap-\nproach. Developed for French and based on lexical frequen-\ncies, it requires pre-processing with TermoStat [8] and ANNIE\n(GATE). [9] presents a method for extracting terminology spe-\nciﬁc to a domain from a corpus of domain-speciﬁc text, where\nno external general domain reference corpus is required. They\npresent an adaptation of the classic tf-idf as ranking measure\nand use different ﬁlters to produce a speciﬁc terminology.\nMore recently, the efﬁciency of ranking measure like mutual\ninformation developed for statistical approach is discussed in\n[10] and [11]. [12] proposes Termolator a terminology extrac-\ntion system using a chunking procedure, and using internet\nqueries for ranking candidate terms. Approach is interesting\nbut the authors emphasize the fact that the runtime for each\nqueries is a limiting factor to produce a relevant ranking.\nCloser to our work, [13] presents an approach combining\nlinguistic pattern and Z-score to extract terminology in the\n', 4, 0)
(311.97802734375, 49.7054443359375, 563.03564453125, 324.72357177734375, 'ﬁeld of nanotechnology. [14] propose TAXI, which combines\nstatistics and learning approach. TAXI is a system for building\na taxonomy using 2 corpora, a generic, the other speciﬁc.\nIt ranks the relevance of candidates by measure (frequency-\nbased), and by learning with SVM. [15], [16] present TexSIS,\na bilingual terminology extraction system with chunk-based\nalignment method for the generation of candidate terms. After\nthe corpus alignment step, they use an approach combining\nlog likelihood measure and Mutual Expectation measure [17]\nto rank candidate terms in each language. In the same or-\nder, [18], [19] present an approach to extract grammatical\nterminology from linguistic corpora. They compare a series\nof well-established statistical measures that have been used\nin similar automatic term extraction tasks and conclude that\ncorpus-comparing methods perform better than metrics that\nare not based on corpus comparison. [20] and [21] present\nmethods with word embeddings. With a small data set for\nlearning phase, they improve the term extraction results in\nn-gram terms. However, these papers involve labelled data\nsets for learning phase, which is the main difference with\nour proposed approach. The originality of our approach is to\ncombine a lexico-syntactical and a statistical approach while\nusing external resources.\n', 5, 0)
(311.97796630859375, 330.11163330078125, 563.0355224609375, 548.2783813476562, 'IV. RESOURCES AND STATISTICS\nFirst experiments were carried out using technical reports\ncollected from some customers from our industrial partners\nwho will be called as NC collection thereafter. Each document\ncontains all the non-compliance that was found on one work\nsite and describe solutions to resolve it. However heterogeneity\nof the formats as well as the artiﬁcial repetition of the informa-\ntion between two reports found in the same construction site\nmade the term extraction quite difﬁcult. An insightful analysis\nof those reports reveals vocabulary richness, however, difﬁcult\nto exploit given numerous misspellings, typing shortcuts, very\n”telegraphic” style with verbs in the inﬁnitive, little punctu-\nation, few determinants, etc. As a consequence, we used a\ncollection of technical speciﬁcations called CCTP2. CCTPs are\navailable online on public sector websites3. Several thousand\ndocuments were collected by our industrial partner using an\nautomatic web collecting process. Figure 2 presents some key\ndescriptive statistics of theses collections.\n', 6, 0)
(317.9549865722656, 559.8015747070312, 544.8184814453125, 571.8065185546875, 'Collection\nNC\nCCTP\n', 7, 0)
(317.9549865722656, 572.154541015625, 558.2633056640625, 584.1594848632812, 'Total number of documents\n58 402\n3665\n', 8, 0)
(391.3900146484375, 584.508544921875, 484.8291931152344, 596.4038696289062, 'Without pre-processing\n', 9, 0)
(317.9549865722656, 596.862548828125, 558.2637329101562, 608.8674926757812, 'Total number of words\n130 309\n230 962 734\n', 10, 0)
(317.9549865722656, 609.215576171875, 558.2628784179688, 621.2205200195312, 'Total number of different words\n93 000\n20 6264\n', 11, 0)
(317.9549865722656, 621.569580078125, 558.2628784179688, 633.5745239257812, 'Average words/document\n125.3\n63 018.48\n', 12, 0)
(381.2070007324219, 638.80859375, 493.8086242675781, 648.41259765625, 'Fig. 2. statistics of the collection.\n', 13, 0)
(311.9779968261719, 671.3466796875, 563.0400390625, 718.6846313476562, '2The technical speciﬁcations book (CCTP in French) is a contractual\ndocument that gathers the technical clauses of a public contract in the ﬁeld\nof construction.\n3For\nexample,\nhttps://www.marches-publics.gouv.fr/\nor\nhttp://marchespublics.normandie.fr/.\n', 14, 0)

page suivante
(61.720123291015625, 176.4996795654297, 177.35060119628906, 182.31643676757812, ' \n \n', 0, 0)
(150.337646484375, 132.40481567382812, 175.0030975341797, 140.78775024414062, 'ranking\n', 1, 0)
(89.89613342285156, 60.23047637939453, 102.99266815185547, 65.63746643066406, 'CCTP\n', 2, 0)
(65.43440246582031, 65.68798065185547, 76.87698364257812, 68.2028579711914, 'CR 1 06/02\n', 3, 0)
(65.43440246582031, 70.71540832519531, 86.18671417236328, 78.2576904296875, 'Lot A :\nSiphon indépendant \nsous évier\n', 4, 0)
(76.5772476196289, 71.01554870605469, 87.9860610961914, 73.53042602539062, 'CR 2 15/02\n', 5, 0)
(76.5772476196289, 76.00543212890625, 98.7207260131836, 91.0888442993164, 'Lot A :\n- Siphon indépendant \nsous évier\nLot B :\n- Pose des plinthes \nsur la cloison\n', 6, 0)
(82.20494842529297, 84.33443450927734, 93.61827087402344, 86.84931182861328, 'CR 3 22/02\n', 7, 0)
(82.20494842529297, 89.36184692382812, 105.19332122802734, 104.44525146484375, 'Lot A :\n- Siphon indépendant \nsous évier\nLot B :\n- suppression de la \ncloison entre wc et sdb\n', 8, 0)
(238.8426055908203, 75.00226593017578, 288.1774597167969, 83.38519287109375, 'words ngrams \n', 9, 0)
(245.14564514160156, 83.36878967285156, 279.7959899902344, 91.75171661376953, 'extraction \n', 10, 0)
(248.7848663330078, 132.36727905273438, 273.863037109375, 140.75021362304688, 'pruning\n', 11, 0)
(138.1067657470703, 78.56647491455078, 187.90928649902344, 86.94940185546875, 'pre-processing\n', 12, 0)
(70.38677978515625, 117.91700744628906, 109.97599792480469, 120.41898345947266, 'citernea\nu\ndevant\nentree\n', 13, 0)
(70.53684997558594, 123.69477844238281, 111.25310516357422, 126.19676208496094, 'marche\ns\nchez\ntechniplan\n', 14, 0)
(70.42430114746094, 129.5100555419922, 109.93500518798828, 131.1866455078125, 'coulage\npar\ndefaut\n', 15, 0)
(70.38677978515625, 134.01222229003906, 109.52728271484375, 136.5142059326172, "proposit\nions\nd'\nauge\n", 16, 0)
(70.4618148803711, 139.7899932861328, 111.27989959716797, 142.29197692871094, 'typologi\ne\ndes\nciterneaux\n', 17, 0)
(70.61188507080078, 145.60528564453125, 110.19960021972656, 147.28187561035156, "espace\nd'\nactivite\n", 18, 0)
(71.09962463378906, 150.10743713378906, 111.32791900634766, 151.78402709960938, 'vision\ndepuis\nascenseur\n', 19, 0)
(70.53684997558594, 155.8852081298828, 108.92977905273438, 158.38720703125, 'vaissell\ne\nsous\nbar\n', 20, 0)
(71.43728637695312, 161.66297912597656, 109.67434692382812, 163.33956909179688, 'mise\nen\nplace\n', 21, 0)
(70.3117446899414, 166.16514587402344, 111.14056396484375, 168.70465087890625, 'coulisse\nau\npour \ndouchette\n', 22, 0)
(68.88606262207031, 170.9733123779297, 107.70968627929688, 179.3562469482422, 'terminology\n', 23, 0)
(190.4443817138672, 85.73226928710938, 292.136474609375, 95.68941497802734, '①\n➁\n', 24, 0)
(186.5800323486328, 137.5063018798828, 288.19708251953125, 149.11505126953125, '➂\n④\n', 25, 0)
(133.26800537109375, 197.3345947265625, 215.7186737060547, 206.93856811523438, 'Fig. 3. System overview\n', 26, 0)
(132.9739990234375, 220.0565185546875, 216.01844787597656, 232.0614471435547, 'V. METHODOLOGY\n', 27, 0)
(48.96400451660156, 236.38250732421875, 131.70338439941406, 248.27784729003906, 'A. System Overview\n', 28, 0)
(48.96400451660156, 252.19549560546875, 300.0218811035156, 359.84136962890625, 'Figure 3 presents an overview of the system designed and\nimplemented: steps are further explained in Sections V-B to\nV-E. In Step 1 pre-processing of raw information extracted\nfrom CCTP collection takes place; this is required for nor-\nmalizing the entire set of documents. In Step 2 n-grams are\nextracted (by using measures). 1,2,3 grams are extracted. In\nStep 3, n-grams are ﬁltered by using linguistic patterns and\nInternet queries. Finally, in Step 4 a ranking is applied to the\nﬁltered n-grams.\n', 29, 0)
(48.96400451660156, 368.263427734375, 300.0214538574219, 380.1587829589844, 'B. Normalization, pre-processing and word ngrams extraction\n', 30, 0)
(48.96400451660156, 384.075439453125, 300.02191162109375, 575.4082641601562, 'In Step 1, a text normalization is performed to improve the\nquality of the process. We remove special characters such as\n“/” or “()”. Different pretreatments are done to reduce noise\nin the model: we remove numbers (numeric and/or textual),\nspecial symbols. “.” are tagged with a special character to\nnot create artiﬁcial n-grams. Speciﬁc words (including named\nentities) like company names, dates, etc. are normalized and\nwill be removed in the next module. We do not include a\nstop list to keep n-grams with prepositions, for the purpose\ndescribed in the remainder. Then, we tokenize the entire\ncollection before using TreeTagger [22] to get the part-of-\nspeech tags and lemmas of each word. After this step we\ntransform all vocabulary from the CCTP collection into 1-\ngrams, 2-grams and 3-grams. Special characters or normalized\nwords resulting from the previous processing are discarded. N-\ngrams with a very low frequency (2) are also discarded.\n', 31, 0)
(48.96400451660156, 583.830322265625, 171.90245056152344, 595.7256469726562, 'C. Linguistic patterns module\n', 32, 0)
(48.96400451660156, 599.642333984375, 300.0219421386719, 719.2442626953125, 'We use grammatical labels generated in the previous step\n(section V-B) and linguistic patterns to retrieve collocations\nsuch as NOUN-NOUN, NOUN-PREP-NOUN. These patterns\nare frequently found in the literature [6] to capture speciﬁc\nwords in French like ”carte de cr´edit”(credit card) and discard\n3-gram like ’cr´editer sa carte’ (credit his card) with the\npattern VERB-PREP-NOUN. Among frequent patterns found\nin literature, those patterns have been selected according to the\nstatistics obtained from a knowledge model of another ﬁeld\n(agriculture), given by one of our industrial partners. Figure\n', 33, 0)
(311.97802734375, 49.704345703125, 563.03564453125, 73.66527557373047, '4 presents main patterns we selected using this knowledge\nmodel. The sum of the percentages is less than 100% because\n', 34, 0)
(445.8059997558594, 86.93255615234375, 534.114501953125, 98.93749237060547, 'Number\nPercentage\n', 35, 0)
(340.8999938964844, 99.28558349609375, 527.6190185546875, 111.29051971435547, '1-grams\n1360\n65.24%\n', 36, 0)
(340.8999938964844, 111.6395263671875, 527.6190185546875, 147.5544891357422, 'NOUN\n1037\n76.25%\nVERB\n194\n14.26%\nADJ\n120\n8.82%\n', 37, 0)
(340.8999938964844, 147.903564453125, 527.6190185546875, 159.9084930419922, '2-grams\n390\n19.57%\n', 38, 0)
(340.8999938964844, 160.257568359375, 527.6190185546875, 208.12754821777344, 'NOUN-NOUN\n346\n88.72%\nADJ-NOUN\n11\n2.82%\nPREP-NOUN\n7\n1,79%\nVERB-NOUN\n5\n1,28%\n', 39, 0)
(340.8999938964844, 208.4765625, 525.1283569335938, 220.4814910888672, '3-grams\n188\n9.43%\n', 40, 0)
(340.8999938964844, 220.83056640625, 527.6189575195312, 268.7005615234375, 'NOUN-NOUN-NOUN\n150\n79.79%\nPREP-NOUN-NOUN\n15\n7.98%\nNOUN-PREP-NOUN\n6\n3,19%\nVERB-NOUN-NOUN\n6\n3,19%\n', 41, 0)
(311.9779968261719, 273.53668212890625, 563.0361328125, 283.1406555175781, 'Fig. 4. Distribution of linguistic patterns according to the knowledge model.\n', 42, 0)
(311.9779968261719, 293.9806213378906, 563.0355224609375, 377.71649169921875, 'patterns with a very low frequency are not included in the\ntable. We observed that the noun based patterns are the most\nfrequent patterns, whatever the size of the n-gram. The other\nselected patterns also contain nouns, but they are n-grams\nwith verbs, adjectives or prepositions. Therefore, we have\nconﬁgured our system to keep only the ngrams corresponding\nto these patterns.\n', 43, 0)
(311.9779968261719, 386.3035583496094, 378.83697509765625, 398.19891357421875, 'D. Pruning step\n', 44, 0)
(311.97796630859375, 402.1845703125, 563.0355224609375, 509.8304138183594, 'This step uses the Internet to prune n-grams for which no\ninformation is returned after querying Bing4 search engine.\nWe count the number of links in the result pages that contain\nexactly the ngram. We save the number of exact matches\nbetween the ngram and the title and snippet of each result.\nWe keep only the n-grams whose number of matches exceeds\na deﬁned threshold. We varied this threshold between 1 and\n50 and results presented in Section VI-B have been obtained\nwith a threshold of 10.\n', 45, 0)
(311.97796630859375, 518.41748046875, 378.279052734375, 530.3128051757812, 'E. Ranking step\n', 46, 0)
(311.9779357910156, 534.2974853515625, 563.037353515625, 641.9443969726562, 'We tested several measures as provided in [6], [16] like\nmaximum likelihood estimation or mutual information in\norder to rank selected n-grams by quality but results were\ndisappointing. We ﬁnally use classical Z score [23] with\ntwenty years of the French newspaper Le Monde5 as generic\ncollection. This metric considers word frequencies weighted\nover two different corpora, in order to assign high values to\nwords having much higher or lower frequencies than expected\nin a generic collection. We deﬁned it as follows :\n', 47, 0)
(414.3929443359375, 655.074462890625, 563.036376953125, 668.2645874023438, 'p1 = a0/b0\n(1)\n', 48, 0)
(414.3929443359375, 675.7534790039062, 563.036376953125, 688.943603515625, 'p2 = a1/b1\n(2)\n', 49, 0)
(319.94793701171875, 698.24560546875, 489.0218505859375, 718.6845703125, '4https://www.bing.com/\n5http://www.islrn.org/resources/421-401-527-366-2/\n', 50, 0)

page suivante
(124.4489974975586, 49.70452880859375, 300.0223693847656, 62.8956184387207, 'p = (a0 + a1)/(b0 + b1)\n(3)\n', 0, 0)
(97.55599975585938, 67.73894500732422, 211.7650909423828, 111.39029693603516, 'ZScore =\np1 − p2\nq\n', 1, 0)
(153.1199951171875, 83.75665283203125, 221.49209594726562, 102.47406768798828, '(p ∗ (1 − p) ∗ ( 1\n', 2, 0)
(215.81399536132812, 83.75665283203125, 243.45208740234375, 99.83262634277344, 'b0 + 1\n', 3, 0)
(237.7740020751953, 72.9945068359375, 300.0223693847656, 99.83262634277344, 'b1 )\n(4)\n', 4, 0)
(48.96397399902344, 104.6815185546875, 300.0234680175781, 152.55247497558594, 'Where a is the lexical unit considered (1-gram, 2-gram or\n3-gram), a0 the frequency of a in the CCTP collection, b0 the\ntotal size in words of CCTP collection, b1 the frequency of a\nin the collection Le Monde.\n', 5, 0)
(103.74897766113281, 160.68353271484375, 245.242919921875, 172.68846130371094, 'VI. EXPERIMENTS AND RESULTS\n', 6, 0)
(48.96398162841797, 176.80450439453125, 153.00340270996094, 188.69984436035156, 'A. Experimental protocol\n', 7, 0)
(48.96398162841797, 192.49749755859375, 300.0218811035156, 276.2335205078125, 'We have made a manual evaluation on all 3 grams retained\nby the system. Manual evaluation was realized by 6 specialists\nin the ﬁeld of construction. Each specialist evaluating one third\nof the results. 5144 3-grams were evaluated with this method\nand each n-gram was evaluated by 2 different specialists.\nFor each n-grams, the specialist can choose between three\npossibilities:\n', 8, 0)
(58.92698287963867, 278.53857421875, 157.52359008789062, 294.3760986328125, '• 0 3-gram is irrelevant\n', 9, 0)
(58.92698669433594, 290.4935607910156, 296.30255126953125, 306.3310852050781, '• 1 3-gram is relevant but does not belong to the domain\n', 10, 0)
(48.9639778137207, 302.44854736328125, 300.0228271484375, 436.359375, '• 2 3-gram is relevant and belongs to the domain\nEvaluation was done in two steps and we use Kappa\nmeasure6 [24] and inter-annotator agreement at the end of the\nﬁrst step to show the difﬁculty of the task. At the end of the\nﬁrst step, we obtained a Kappa score of 0.62 and a global\ninter-annotator agreement of 0.74, which is quite good as\nexplained in [25]. The difﬁculty of the task was to distinguish\nthe domain-speciﬁc vocabulary from the generic vocabulary\nused in the ﬁeld of construction. Each disagreement was re-\nevaluated in the second step by a pair of experts. Figure 5\nshows the ﬁnal results of the evaluation.\n', 11, 0)
(48.9639778137207, 444.49041748046875, 91.30501556396484, 456.3857727050781, 'B. Results\n', 12, 0)
(48.96397399902344, 460.18341064453125, 300.0218505859375, 531.9642944335938, 'In this section, we present the results obtained during the\nmanual evaluation of the 3-grams retained by the system. We\nonly compute the accuracy and the error rate, because we are\nnot able to compute the recall for this collection7. We have\nmerged the assessments of each expert using two different\nevaluation rules:\n', 13, 0)
(58.92697525024414, 534.2683715820312, 300.01873779296875, 558.2283325195312, '• a strict evaluation where a n-gram is considered correct\nif both experts have rated it relevant and in the domain .\n', 14, 0)
(58.926979064941406, 558.1793212890625, 300.0187072753906, 594.0942993164062, '• a ﬂexible evaluation where a n-gram is considered correct\nif both experts consider it relevant and at least one of the\nexperts consider it in the domain.\n', 15, 0)
(124.05799865722656, 609.4015502929688, 274.66259765625, 621.406494140625, 'strict evaluation\nﬂexible evaluation\n', 16, 0)
(74.32499694824219, 621.7555541992188, 246.25950622558594, 645.7155151367188, 'accuracy\n0.77\n0.91\nerror rate\n0.23\n0.09\n', 17, 0)
(86.53999328613281, 650.5505981445312, 262.447998046875, 660.1546020507812, 'Fig. 5. Results of manual evaluation on the 3-grams.\n', 18, 0)
(56.933990478515625, 670.7006225585938, 222.78733825683594, 681.3206176757812, '6We use general formula as follows : κ = A0−Ae\n', 19, 0)
(48.9639892578125, 671.7166137695312, 300.0260314941406, 718.6846313476562, '1−Ae\nwhere A0 = observed\nagreement and Ae = expected (chance) agreement.\n7Indeed, we do not know every the relevant terms existing in the corpus,\nso we cannot estimate the recall for the collection of terms we automatically\nextract.\n', 20, 0)
(311.97796630859375, 49.70458984375, 563.039794921875, 229.0826873779297, 'Strict evaluation shows good quality results (0.77). Anal-\nysis of the results shows that the main error is related to\n”incomplete n-grams”. For example, the 3-gram “personne\n`a mobilit´e” (person with mobility) is not relevant while the\n4-gram “personne `a mobilit´e r´eduite” (person with reduced\nmobility ) can belong to the ﬁeld of construction. Some errors\ncan also be traced back to the CCTP documents. For example,\n“engin de guerre” (war machine) is a term which does not\nbelong to the ﬁeld but a law relating to the presence of war\nmachine on the building sites is reported in every CCTP. The\nﬂexible evaluation shows very good results (0.91) and the\ndifﬁculty of assessing class of some terms such as “absence de\nremise” which has 2 distinct meanings in French (no outhouse\nand no discount). The ﬁrst meaning is relevant in the ﬁeld of\nconstruction but not the second.\n', 21, 0)
(354.3749694824219, 238.46075439453125, 520.6454467773438, 250.46568298339844, 'VII. CONCLUSION AND PERSPECTIVES\n', 22, 0)
(311.97796630859375, 255.4627685546875, 563.0355224609375, 482.6605224609375, 'The paper reports our experiments and results for building\na precise and large terminology for the construction domain.\nCollecting terminology is indeed the ﬁrst step towards a\ncomplete knowledge model containing both concepts and\nrelationships. During our work we were faced to several\nproblems: ﬁnding resources and selecting them for building\nan appropriate corpus, thinking and developing pre-processing\nfor cleaning those resources, experimenting distinct measures\nfor n-grams and selecting the most appropriate, improving\nresults by adding linguistic patterns and Internet queries. The\ncurrent results are quite promising according to the evaluation\nof the extracted terminology carried out by 6 experts in the\nﬁeld. As a perspective, we will develop generic modules and\nguidelines for adapting these pre-processing modules to other\nlanguages. Most importantly, the results of our work are useful\nfor extracting taxonomical and non-taxonomical relationships.\nFor the both purposes, we are currently working on SemEval\ncollection [26]. Applying our method to other domain corpora\nand datasets is another future direction for this research.\n', 23, 0)
(409.6119689941406, 492.0395812988281, 465.4123840332031, 504.0445251464844, 'REFERENCES\n', 24, 0)
(315.9629821777344, 510.5836181640625, 563.0360717773438, 529.1536865234375, '[1] S. Meignier and T. Merlin, “Lium spkdiarization: an open source toolkit\nfor diarization,” in in CMU SPUD Workshop, 2010.\n', 25, 0)
(315.9629821777344, 528.692626953125, 563.038818359375, 556.2296752929688, '[2] P. Pauwels and W. Terkaj, “Express to owl for construction industry:\nTowards a recommendable and usable ifcowl ontology,” Automation in\nConstruction, vol. 63, pp. 100–133, 03 2016.\n', 26, 0)
(315.96295166015625, 555.7686767578125, 563.0361328125, 574.3386840820312, '[3] H. Cunningham, “Gate, a general architecture for text engineering,” in\nComputers and the Humanities, vol. 36, 2002, pp. 223–254.\n', 27, 0)
(315.9629211425781, 573.837646484375, 563.0401611328125, 601.4146728515625, '[4] P. Cimiano and J. V¨olker, “text2onto,” in International conference on\napplication of natural language to information systems. Springer, 2005,\npp. 227–238.\n', 28, 0)
(315.96295166015625, 600.9536743164062, 563.0360717773438, 628.4906616210938, '[5] P. Kluegl, M. Toepfer, P.-D. Beck, G. Fette, and F. Puppe, “Uima ruta:\nRapid development of rule-based information extraction applications,”\nNatural Language Engineering, vol. 22, no. 1, p. 1–40, 2016.\n', 29, 0)
(315.9629211425781, 627.9896850585938, 563.0397338867188, 655.566650390625, '[6] M. Roche and Y. Kodratoff, “Exit: Un syst`eme it´eratif pour l’extraction\nde la terminologie du domaine `a partir de corpus sp´ecialis´es,” in\nProceedings of JADT 4, 2004, pp. 946–956.\n', 30, 0)
(315.96295166015625, 655.065673828125, 563.0388793945312, 691.6087036132812, '[7] B. Bi´ebow, S. Szulman, and A. J. B. Cl´ement, “Terminae: A linguistics-\nbased tool for the building of a domain ontology,” in Knowledge\nAcquisition, Modeling and Management, D. Fensel and R. Studer, Eds.,\n1999, pp. 49–66.\n', 31, 0)
(315.9629821777344, 691.147705078125, 563.0364990234375, 718.6846923828125, '[8] P. Drouin, “Term extraction using non technical corpora as point of lever-\nage,” in John Benjamins Publishing Company: Amsterdam/Philadelphia,\nn. Terminology, vol. 9, Ed., 2003, pp. 99–115.\n', 32, 0)

page suivante
(52.94900131225586, 51.54560089111328, 300.0220642089844, 79.08255767822266, '[9] M. F. M. Chowdhury, A. M. Gliozzo, and S. M. Trewin, “Domain-\nspeciﬁc terminology extraction by boosting frequency metrics,” Sep. 27\n2018, uS Patent App. 15/469,766.\n', 0, 0)
(48.96399688720703, 78.44458770751953, 300.0221252441406, 97.01554107666016, '[10] G. Bouma, “Normalized (pointwise) mutual information in collocation\nextraction,” Proceedings of GSCL, 2009.\n', 1, 0)
(48.96400451660156, 96.37757110595703, 300.022216796875, 123.9145278930664, '[11] Y. Bestgen, “Evaluation de mesures d’association pour les bigrammes et\nles trigrammes au moyen du test exact de ﬁsher,” Proceedings of TALN\n2017, pp. 10–19, 2017.\n', 2, 0)
(48.96400833129883, 123.27655792236328, 300.0221862792969, 159.77951049804688, '[12] A. L. Meyers, Y. He, Z. Glass, J. Ortega, S. Liao, A. Grieve-Smith,\nR. Grishman, and O. Babko-Malaya, “The termolator: Terminology\nrecognition based on chunking, statistical and search-based scores,”\nFrontiers in Research Metrics and Analytics, vol. 3, p. 19, 2018.\n', 3, 0)
(48.96400451660156, 159.14251708984375, 300.0221862792969, 177.71249389648438, '[13] L. Gillam, M. Tariq, and K. Ahmad, “Terminology and the construction\nof ontology,” TERMINOLOGY, vol. 11, pp. 55–81, 2005.\n', 4, 0)
(48.964012145996094, 177.07550048828125, 300.0220947265625, 231.51046752929688, '[14] A. Panchenko, S. Faralli, E. Ruppert, S. Remus, H. Naets, C. Fairon, S. P.\nPonzetto, and C. Biemann, “TAXI at semeval-2016 task 13: a taxonomy\ninduction method based on lexico-syntactic patterns, substrings and\nfocused crawling,” in Proceedings of the 10th International Workshop\non Semantic Evaluation, SemEval@NAACL-HLT 2016, San Diego, CA,\nUSA, June 16-17, 2016, 2016, pp. 1320–1327.\n', 5, 0)
(48.964012145996094, 230.87347412109375, 300.02215576171875, 294.27545166015625, '[15] E.\nLefever,\nL.\nMacken,\nand\nV.\nHoste,\n“Language-independent\nbilingual terminology extraction from a multilingual parallel corpus,”\nin Proceedings of the 12th Conference of the European Chapter\nof the Association for Computational Linguistics, ser. EACL ’09.\nStroudsburg, PA, USA: Association for Computational Linguistics,\n2009, pp. 496–504. [Online]. Available: http://dl.acm.org/citation.cfm?\nid=1609067.1609122\n', 6, 0)
(48.964019775390625, 293.6374816894531, 300.0221252441406, 330.1404724121094, '[16] L. Macken, E. Lefever, and V. Hoste, “Texsis: bilingual terminology\nextraction\nfrom\nparallel\ncorpora\nusing\nchunk-based\nalignment,”\nTerminology, vol. 19, no. 1, pp. 1–30, 2013. [Online]. Available:\nhttp://dx.doi.org/10.1075/term.19.1.01mac\n', 7, 0)
(48.964019775390625, 329.5035095214844, 300.022216796875, 357.0404968261719, '[17] G. Dias and H.-J. Kaalep, “Automatic extraction of multiword units\nfor estonian : Phrasal verbs,” in Languages in Development, 2003, p.\n41:81–91.\n', 8, 0)
(48.96403503417969, 356.40252685546875, 300.0235900878906, 383.93951416015625, '[18] B. Daille, “Study and implementation of combined techniques for\nautomatic extraction of terminology,” The Balancing Act: Combining\nSymbolic and Statistical Approaches to Language, 12 2002.\n', 9, 0)
(48.96403503417969, 383.3015441894531, 300.0240783691406, 410.8385314941406, '[19] C. Lang, R. Schneider, and K. Suchowolec, “Extracting specialized\nterminology from linguistic corpora,” GRAMMAR AND CORPORA, p.\n425, 2018.\n', 10, 0)
(48.96403503417969, 410.2005615234375, 300.0221862792969, 437.737548828125, '[20] E. Amjadian, D. Inkpen, T. S. Paribakht, and F. Faez, “Local-global\nvectors to improve unigram terminology extraction,” in Proceedings of\nthe 5th International Workshop on Computational Terminology, 2016.\n', 11, 0)
(48.964019775390625, 437.0995788574219, 300.0221862792969, 464.6365661621094, '[21] G. Wohlgenannt and F. Minic, “Using word2vec to build a simple\nontology learning system.” in International Semantic Web Conference\n(Posters & Demos), 2016.\n', 12, 0)
(48.964027404785156, 463.99859619140625, 300.0221252441406, 482.569580078125, '[22] H. Schmid, “Probabilistic part-of-speech tagging using decision trees,”\n1994.\n', 13, 0)
(48.964027404785156, 481.9316101074219, 300.02423095703125, 509.4685974121094, '[23] E. Altman, “Financial ratios, discriminant analysis and the predic-\ntion of corporate bankruptcy.” in The Journal of Finance, 23(4).\ndoi:10.2307/2978933, 1968, pp. 589–609.\n', 14, 0)
(48.964027404785156, 508.83062744140625, 300.0228576660156, 527.401611328125, '[24] J. Cohen, “A Coefﬁcient of Agreement for Nominal Scales,” Educational\nand Psychological Measurement, vol. 20, no. 1, p. 37, 1960.\n', 15, 0)
(48.96404266357422, 526.763671875, 300.02264404296875, 545.3336181640625, '[25] M. L. McHugh, “Interrater reliability: the kappa statistic,” in Biochemia\nmedica, 2012.\n', 16, 0)
(48.96405029296875, 544.6966552734375, 300.0221862792969, 590.1656494140625, '[26] M. Apidianaki, S. M. Mohammad, J. May, E. Shutova, S. Bethard,\nand M. Carpuat, “Proceedings of the 12th international workshop on\nsemantic evaluation,” in Proceedings of The 12th International Workshop\non Semantic Evaluation.\nAssociation for Computational Linguistics,\n2018. [Online]. Available: http://aclweb.org/anthology/S18-1000\n', 17, 0)

page suivante
