(135.9209747314453, 754.6322021484375, 459.3537902832031, 779.9996948242188, 'Proceedings of the ACL-HLT 2011 System Demonstrations, pages 86–91,\nPortland, Oregon, USA, 21 June 2011. c⃝2011 Association for Computational Linguistics\n', 0, 0)
(157.87777709960938, 65.77214050292969, 454.1268310546875, 102.3695297241211, 'MACAON\nAn NLP Tool Suite for Processing Word Lattices\n', 1, 0)
(85.11278533935547, 126.4434814453125, 531.1209106445312, 142.14019775390625, 'Alexis Nasr\nFr´ed´eric B´echet\nJean-Franc¸ois Rey\nBenoˆıt Favre\nJoseph Le Roux∗\n', 2, 0)
(81.84180450439453, 140.96487426757812, 530.1589965820312, 196.2156219482422, 'Laboratoire d’Informatique Fondamentale de Marseille- CNRS - UMR 6166\nUniversit´e Aix-Marseille\n(alexis.nasr,frederic.bechet,jean-francois.rey,benoit.favre,joseph.le.roux)\n@lif.univ-mrs.fr\n', 3, 0)
(163.1588134765625, 244.39447021484375, 207.64410400390625, 259.94818115234375, 'Abstract\n', 4, 0)
(93.81880187988281, 270.7300109863281, 276.9871826171875, 414.2408142089844, 'MACAON is a tool suite for standard NLP tasks\ndeveloped for French. MACAON has been de-\nsigned to process both human-produced text\nand highly ambiguous word-lattices produced\nby NLP tools. MACAON is made of several na-\ntive modules for common tasks such as a tok-\nenization, a part-of-speech tagging or syntac-\ntic parsing, all communicating with each other\nthrough XML ﬁles . In addition, exchange pro-\ntocols with external tools are easily deﬁnable.\nMACAON is a fast, modular and open tool, dis-\ntributed under GNU Public License.\n', 5, 0)
(72.00081634521484, 433.3293151855469, 154.81448364257812, 448.8830261230469, '1\nIntroduction\n', 6, 0)
(72.00081634521484, 455.5832824707031, 298.801025390625, 671.9667358398438, 'The automatic processing of textual data generated\nby NLP software, resulting from Machine Transla-\ntion, Automatic Speech Recognition or Automatic\nText Summarization, raises new challenges for lan-\nguage processing tools. Unlike native texts (texts\nproduced by humans), this new kind of texts is the\nresult of imperfect processors and they are made\nof several hypotheses, usually weighted with con-\nﬁdence measures. Automatic text production sys-\ntems can produce these weighted hypotheses as n-\nbest lists, word lattices, or confusion networks. It is\ncrucial for this space of ambiguous solutions to be\nkept for later processing since the ambiguities of the\nlower levels can sometimes be resolved during high-\nlevel processing stages. It is therefore important to\nbe able to represent this ambiguity.\n', 7, 0)
(72.00080108642578, 678.2351684570312, 298.8059387207031, 711.1800537109375, '∗This work has been funded by the French Agence Nationale\npour la Recherche, through the projects SEQUOIA (ANR-08-\nEMER-013) and DECODA (2009-CORD-005-01)\n', 8, 0)
(313.2008056640625, 245.79151916503906, 540.0035400390625, 667.1400146484375, 'MACAON is a suite of tools developped to pro-\ncess ambiguous input and extend inference of in-\nput modules within a global scope.\nIt con-\nsists in several modules that perform classical\nNLP tasks (tokenization, word recognition, part-of-\nspeech tagging, lemmatization, morphological anal-\nysis, partial or full parsing) on either native text\nor word lattices.\nMACAON is distributed under\nGNU public licence and can be downloaded from\nhttp://www.macaon.lif.univ-mrs.fr/.\nFrom a general point of view, a MACAON module\ncan be seen as an annotation device1 which adds a\nnew level of annotation to its input that generally de-\npends on annotations from preceding modules. The\nmodules communicate through XML ﬁles that allow\nthe representation different layers of annotation as\nwell as ambiguities at each layer. Moreover, the ini-\ntial XML structuring of the processed ﬁles (logical\nstructuring of a document, information from the Au-\ntomatic Speech Recognition module ...) remains\nuntouched by the processing stages.\nAs already mentioned, one of the main charac-\nteristics of MACAON is the ability for each module\nto accept ambiguous inputs and produce ambiguous\noutputs, in such a way that ambiguities can be re-\nsolved at a later stage of processing. The compact\nrepresentation of ambiguous structures is at the heart\nof the MACAON exchange format, described in sec-\ntion 2. Furthermore every module can weight the\nsolutions it produces. such weights can be used to\nrank solutions or limit their number for later stages\n', 9, 0)
(313.2007751464844, 677.4102172851562, 540.0057373046875, 711.1800537109375, '1Annotation must be taken here in a general sense which in-\ncludes tagging, segmentation or the construction of more com-\nplex objets as syntagmatic or dependencies trees.\n', 10, 0)
(290.4825439453125, 724.5388793945312, 301.39166259765625, 737.684326171875, '86\n', 11, 0)

page suivante
(72.00080108642578, 61.53949737548828, 133.2008514404297, 74.68496704101562, 'of processing.\n', 0, 0)
(72.00080108642578, 80.91046905517578, 298.80084228515625, 121.15396118164062, 'Several processing tools suites alread exist for\nFrench among which SXPIPE (Sagot and Boullier,\n2008), OUTILEX (Blanc et al., 2006), NOOJ2 or UNI-\n', 1, 0)
(72.0008316040039, 120.31513214111328, 298.8009948730469, 202.44998168945312, 'TEX3. A general comparison of MACAON with these\ntools is beyond the scope of this paper. Let us just\nmention that MACAON shares with most of them the\nuse of ﬁnite state machines as core data represen-\ntation. Some modules are implemented as standard\noperations on ﬁnite state machines.\n', 2, 0)
(72.0008316040039, 208.6754913330078, 298.801025390625, 248.91897583007812, 'MACAON can also be compared to the numerous\ndevelopment frameworks for developping process-\ning tools, such as GATE4, FREELING5, ELLOGON6\n', 3, 0)
(72.00084686279297, 245.36354064941406, 298.8028564453125, 276.0169982910156, 'or LINGPIPE7 that are usually limited to the process-\ning of native texts.\n', 4, 0)
(72.00084686279297, 282.2425231933594, 298.8060302734375, 579.9210205078125, 'The MACAON exchange format shares a cer-\ntain number of features with linguistic annotation\nscheme standards such as the Text Encoding Initia-\ntive8, XCES9, or EAGLES10. They all aim at deﬁning\nstandards for various types of corpus annotations.\nThe main difference between MACAON and these\napproaches is that MACAON deﬁnes an exchange for-\nmat between NLP modules and not an annotation\nformat. More precisely, this format is dedicated to\nthe compact representation of ambiguity: some in-\nformation represented in the exchange format are\nto be interpreted by MACAON modules and would\nnot be part of an annotation format.\nMoreover,\nthe MACAON exchange format was deﬁned from the\nbottom up, originating from the authors’ need to use\nseveral existing tools and adapt their input/output\nformats in order for them to be compatible. This is in\ncontrast with a top down approach which is usually\nchosen when specifying a standard. Still, MACAON\nshares several characteristics with the LAF (Ide and\nRomary, 2004) which aims at deﬁning high level\nstandards for exchanging linguistic data.\n', 5, 0)
(81.66480255126953, 610.0252075195312, 260.2945861816406, 710.7855834960938, '2www.nooj4nlp.net/pages/nooj.html\n3www-igm.univ-mlv.fr/˜unitex\n4gate.ac.uk\n5garraf.epsevg.upc.es/freeling\n6www.ellogon.org\n7alias-i.com/lingpipe\n8www.tei-c.org/P5\n9www.xml-ces.org\n10www.ilc.cnr.it/eagles/home.html\n', 6, 0)
(313.2008056640625, 60.14251708984375, 488.7501525878906, 75.69622802734375, '2\nThe MACAON exchange format\n', 7, 0)
(313.2007751464844, 83.11548614501953, 540.00537109375, 680.4830322265625, 'The MACAON exchange format is based on four con-\ncepts: segment, attribute, annotation level and seg-\nmentation.\nA segment refers to a segment of the text or\nspeech signal that is to be processed, as a sentence,\na clause, a syntactic constituent, a lexical unit, a\nnamed entity ...A segment can be equipped with at-\ntributes that describe some of its aspects. A syntac-\ntic constituent, for example, will deﬁne the attribute\ntype which speciﬁes its syntactic type (Noun Phrase,\nVerb Phrase ...). A segment is made of one or more\nsmaller segments.\nA sequence of segments covering a whole sen-\ntence for written text, or a spoken utterance for oral\ndata, is called a segmentation. Such a sequence can\nbe weighted.\nAn annotation level groups together segments of\na same type, as well as segmentations deﬁned on\nthese segments. Four levels are currently deﬁned:\npre-lexical, lexical, morpho-syntactic and syntactic.\nTwo relations are deﬁned on segments: the prece-\ndence relation that organises linearly segments of a\ngiven level into segmentations and the dominance\nrelation that describes how a segment is decomposed\nin smaller segments either of the same level or of a\nlower level.\nWe have represented in ﬁgure 2, a schematic rep-\nresentation of the analysis of the reconstructed out-\nput a speech recognizer would produce on the in-\nput time ﬂies like an arrow11. Three annotation lev-\nels have been represented, lexical, morpho-syntactic\nand syntactic. Each level is represented by a ﬁnite-\nstate automaton which models the precedence rela-\ntion deﬁned over the segments of this level. Seg-\nment time, for example, precedes segment ﬂies. The\nsegments are implicitly represented by the labels of\nthe automaton’s arcs. This label should be seen as\na reference to a more complex objet, the actual seg-\nment. The dominance relations are represented with\ndashed lines that link segments of different levels.\nSegment time, for example, is dominated by seg-\nment NN of the morpho-syntactic level.\nThis example illustrates the different ambiguity\ncases and the way they are represented.\n', 8, 0)
(322.86480712890625, 688.3692016601562, 540.0053100585938, 700.2210693359375, '11For readability reasons, we have used an English example,\n', 9, 0)
(313.4248046875, 700.3755493164062, 523.9559326171875, 711.1800537109375, 'MACAON, as mentioned above, currently exists for French.\n', 10, 0)
(290.4825439453125, 724.5388793945312, 301.39166259765625, 737.684326171875, '87\n', 11, 0)

page suivante
(83.41153717041016, 194.58926391601562, 103.38646697998047, 202.78709411621094, 'thyme\n', 0, 0)
(86.47138977050781, 228.02471923828125, 100.32649993896484, 236.22254943847656, 'time\n', 1, 0)
(123.9509048461914, 206.20054626464844, 136.99038696289062, 214.39837646484375, 'flies\n', 2, 0)
(161.469970703125, 194.58926391601562, 172.47796630859375, 202.78709411621094, 'like\n', 3, 0)
(177.8745880126953, 228.02471923828125, 192.96246337890625, 236.22254943847656, 'liken\n', 4, 0)
(199.78623962402344, 194.58926391601562, 267.8466796875, 202.78709411621094, 'an\narrow\n', 5, 0)
(238.41958618164062, 228.02471923828125, 282.8299255371094, 236.22254943847656, 'a\nrow\n', 6, 0)
(90.3858871459961, 137.44300842285156, 171.04554748535156, 145.64083862304688, 'JJ\nIN\n', 7, 0)
(180.68722534179688, 168.5002899169922, 190.46861267089844, 176.6981201171875, 'VB\n', 8, 0)
(198.5064697265625, 137.44300842285156, 264.1087341308594, 145.64083862304688, 'DT\nNN\n', 9, 0)
(235.19607543945312, 168.5002899169922, 282.2994384765625, 176.6981201171875, 'DT\nNN\n', 10, 0)
(89.1533432006836, 148.47970581054688, 98.93473815917969, 156.6775360107422, 'VB\n', 11, 0)
(88.5908203125, 168.5002899169922, 99.1880111694336, 176.6981201171875, 'NN\n', 12, 0)
(124.9499282836914, 137.44302368164062, 135.547119140625, 145.64085388183594, 'NN\n', 13, 0)
(123.16740417480469, 168.5002899169922, 137.42381286621094, 176.6981201171875, 'VBZ\n', 14, 0)
(162.70944213867188, 148.47970581054688, 282.0492248535156, 156.6775360107422, 'VB\nVB\n', 15, 0)
(272.267822265625, 82.43841552734375, 282.0492248535156, 90.63624572753906, 'VP\n', 16, 0)
(88.35578155517578, 103.76477813720703, 98.13716888427734, 111.96260833740234, 'VP\n', 17, 0)
(88.83680725097656, 82.43841552734375, 99.02912139892578, 90.63624572753906, 'NP\n', 18, 0)
(106.81962585449219, 59.269622802734375, 117.0119400024414, 67.46745300292969, 'NP\n', 19, 0)
(125.63550567626953, 82.43840026855469, 135.41688537597656, 90.63623046875, 'VP\n', 20, 0)
(125.63550567626953, 103.76476287841797, 135.82781982421875, 111.96259307861328, 'NP\n', 21, 0)
(162.43421936035156, 82.43840026855469, 172.2156219482422, 90.63623046875, 'VP\n', 22, 0)
(179.99176025390625, 103.76476287841797, 189.7731475830078, 111.96259307861328, 'VP\n', 23, 0)
(216.81329345703125, 59.31809997558594, 226.5946807861328, 67.51593017578125, 'PP\n', 24, 0)
(235.75790405273438, 80.51518249511719, 245.95021057128906, 88.7130126953125, 'NP\n', 25, 0)
(254.93600463867188, 103.76476287841797, 265.1283264160156, 111.96259307861328, 'NP\n', 26, 0)
(72.00080108642578, 261.01507568359375, 298.7994384765625, 368.6609191894531, 'Figure 1: Three annotation levels for a sample sentence.\nPlain lines represent annotation hypotheses within a level\nwhile dashed lines represent links between levels. Trian-\ngles with the tip up are “and” nodes and triangles with\nthe tip down are “or” nodes. For instance, in the part-of-\nspeech layer, The ﬁrst NN can either refer to “time” or\n“thyme”. In the chunking layer, segments that span mul-\ntiple part-of-speech tags are linked to them through “and”\nnodes.\n', 27, 0)
(72.0007553100586, 386.9823913574219, 298.8058166503906, 657.7638549804688, 'The most immediate ambiguity phenomenon is\nthe segmentation ambiguity: several segmentations\nare possible at every level. This ambiguity is rep-\nresented in a compact way through the factoring of\nsegments that participate in different segmentations,\nby way of a ﬁnite state automaton.\nThe second ambiguity phenomenon is the dom-\ninance ambiguity, where a segment can be decom-\nposed in several ways into lower level segments.\nSuch a case appears in the preceding example, where\nthe NN segment appearing in one of the outgoing\ntransition of the initial state of the morpho-syntactic\nlevel dominates both thyme and time segments of the\nlexical level. The triangle with the tip down is an\n“or” node, modeling the fact that NN corresponds to\ntime or thyme.\nTriangles with the tip up are “and” nodes. They\nmodel the fact that the PP segment of the syntac-\ntic level dominates segments IN, DT and NN of the\nmorpho-syntactic level.\n', 28, 0)
(72.0007553100586, 666.9617309570312, 192.19723510742188, 681.1544799804688, '2.1\nXML representation\n', 29, 0)
(72.0007553100586, 685.0314331054688, 298.80511474609375, 698.1768798828125, 'The MACAON exchange format is implemented in\n', 30, 0)
(72.27375793457031, 698.5804443359375, 298.8006286621094, 711.7258911132812, 'XML. A segment is represented with the XML tag\n', 31, 0)
(313.2007141113281, 61.53943634033203, 524.7103881835938, 74.68490600585938, '<segment> which has four mandatory attributes:\n', 32, 0)
(324.58270263671875, 87.24042510986328, 540.0056762695312, 154.58291625976562, '• type indicates the type of the segment, four dif-\nferent types are currently deﬁned: atome (pre-\nlexical unit usually referred to as token in en-\nglish), ulex (lexical unit), cat (part of speech)\nand chunk (a non recursive syntactic unit).\n', 33, 0)
(324.58270263671875, 165.89942932128906, 540.0006103515625, 206.14291381835938, '• id associates to a segment a unique identiﬁer in\nthe document, in order to be able to reference\nit.\n', 34, 0)
(324.58270263671875, 217.4594268798828, 540.0006103515625, 298.3509216308594, '• start and end deﬁne the span of the segment.\nThese two attributes are numerical and repre-\nsent either the index of the ﬁrst and last char-\nacter of the segment in the text string or the\nbeginning and ending time of the segment in\na speech signal.\n', 35, 0)
(313.20068359375, 310.90643310546875, 540.0059204101562, 446.4809875488281, 'A segment can deﬁne other attributes that can be\nuseful for a given description level. We often ﬁnd\nthe stype attribute that deﬁnes subtypes of a given\ntype.\nThe dominance relation is represented through the\nuse of the <sequence> tag. The domination of the\nthree segments IN, DT and NN by a PP segment,\nmentionned above is represented below, where p1,\np2 and p3 are respectively the ids of segments IN,\nDT and NN.\n', 36, 0)
(313.2007141113281, 453.7867736816406, 533.7745361328125, 528.9375, '<segment type="chunk" stype="PP" id="c1">\n<sequence>\n<elt segref="p1"/>\n<elt segref="p2"/>\n<elt segref="p3"/>\n</sequence>\n</segment>\n', 37, 0)
(313.20068359375, 536.4784545898438, 540.0013427734375, 617.369873046875, 'The ambiguous case, described above where seg-\nment NN dominates segments time or thyme is rep-\nresented below as a disjunction of sequences inside\na segment. The disjunction itself is not represented\nas an XML tag. l1 and l2 are respectively the ids\nof segments time and thyme.\n', 38, 0)
(313.20068359375, 624.6766967773438, 523.0148315429688, 710.7854614257812, '<segment type="cat" stype="NN" id="c1">\n<sequence>\n<elt segref="l1" w="-3.37"/>\n</sequence>\n<sequence>\n<elt segref="l2" w="-4.53"/>\n</sequence>\n</segment>\n', 39, 0)
(290.4825439453125, 724.5388793945312, 301.39166259765625, 737.684326171875, '88\n', 40, 0)

page suivante
(72.00080108642578, 61.53949737548828, 298.8024597167969, 223.72604370117188, 'The dominance relation can be weighted, by way\nof the attribute w. Such a weight represents in the\npreceding example the conditional log-probability\nof a lexical unit given a part of speech, as in a hidden\nMarkov model.\nThe precedence relation (i.e.\nthe organization\nof segments in segmentations), is represented as a\nweighted ﬁnite state automaton. Automata are rep-\nresented as a start state, accept states and a list of\ntransitions between states, as in the following exam-\nple that corresponds to the lexical level of our exam-\nple.\n', 0, 0)
(72.00081634521484, 228.6088104248047, 292.5738830566406, 391.4294128417969, '<fsm n="9">\n<start n="0"/>\n<accept n="6"/>\n<ltrans>\n<trans o="0" d="1" i="l1" w="-7.23"/>\n<trans o="0" d="1" i="l2" w="-9.00"/>\n<trans o="1" d="2" i="l3" w="-3.78"/>\n<trans o="2" d="3" i="l4" w="-7.37"/>\n<trans o="3" d="4" i="l5" w="-3.73"/>\n<trans o="2" d="4" i="l6" w="-6.67"/>\n<trans o="4" d="5" i="l7" w="-4.56"/>\n<trans o="5" d="6" i="l8" w="-2.63"/>\n<trans o="4" d="6" i="l9" w="-7.63"/>\n</ltrans>\n</fsm>\n', 1, 0)
(82.9098129272461, 397.03436279296875, 298.80322265625, 410.1798400878906, 'The <trans/> tag represents a transition, its\n', 2, 0)
(72.00080871582031, 410.5843505859375, 298.8020324707031, 464.3768615722656, 'o,d,i and w features are respectively the origin, and\ndestination states, its label (the id of a segment) and\na weight.\nAn\nannotation\nlevel\nis\nrepresented\nby\nthe\n', 3, 0)
(72.0008316040039, 464.7803955078125, 298.8006286621094, 477.9258728027344, '<section> tag which regroups two tags,\nthe\n', 4, 0)
(72.0008316040039, 478.33038330078125, 298.8011169433594, 518.5738525390625, '<segments> tag that contains the different segment\ntags deﬁned at this annotation level and the <fsm>\ntag that represents all the segmentations of this level.\n', 5, 0)
(72.00086212158203, 527.513427734375, 224.50059509277344, 543.067138671875, '3\nThe MACAON architecture\n', 6, 0)
(72.00086212158203, 549.5393676757812, 298.8009948730469, 562.684814453125, 'Three aspects have guided the architecture of\n', 7, 0)
(72.00086212158203, 563.08837890625, 298.8047180175781, 711.725830078125, 'MACAON: openness, modularity, and speed. Open-\nness has been achieved by the deﬁnition of an ex-\nchange format which has been made as general as\npossible, in such a way that mapping can be de-\nﬁned from and to third party modules as ASR, MT\nsystems or parsers. Modularity has been achieved\nby the deﬁnition of independent modules that com-\nmunicate with each other through XML ﬁles using\nstandard UNIX pipes. A module can therefore be re-\nplaced easily. Speed has been obtained using efﬁ-\ncient algorithms and a representation especially de-\n', 8, 0)
(313.20086669921875, 61.53937530517578, 540.0009765625, 88.23385620117188, 'signed to load linguistic data and models in a fast\nway.\n', 9, 0)
(313.20086669921875, 89.62439727783203, 540.0028076171875, 170.51589965820312, 'MACAON is composed of libraries and compo-\nnents. Libraries contain either linguistic data, mod-\nels or API functions. Two kinds of components are\npresented, the MACAON core components and third\nparty components for which mappings to and from\nthe MACAON exchange format have been deﬁned.\n', 10, 0)
(313.20086669921875, 182.7797088623047, 381.3826904296875, 196.97244262695312, '3.1\nLibraries\n', 11, 0)
(313.2008056640625, 202.60841369628906, 540.0010986328125, 310.5979919433594, 'The main MACAON library is macaon common.\nIt deﬁnes a simple interface to the MACAON ex-\nchange format and functions to load XML MACAON\nﬁles into memory using efﬁcient data structures.\nOther libraries macaon lex, macaon code and\nmacaon tagger lib represent the lexicon, the\nmorphological data base and the tagger models in\nmemory.\n', 12, 0)
(313.2008056640625, 311.988525390625, 540.0050048828125, 352.2320251464844, 'MACAON only relies on two third-party libraries,\nwhich are gfsm12, a ﬁnite state machine library and\nlibxml, an XML library13.\n', 13, 0)
(313.2008361816406, 364.496826171875, 482.25860595703125, 378.6895751953125, '3.2\nThe MACAON core components\n', 14, 0)
(313.2008361816406, 384.3245544433594, 540.0029907226562, 438.1180419921875, 'A brief description of several standard components\ndeveloped in the MACAON framework is given be-\nlow. They all comply with the exchange format de-\nscribed above and add a <macaon stamp> to the\n', 15, 0)
(313.2007751464844, 438.5215148925781, 540.0029296875, 478.7650146484375, 'XML ﬁle that indicates the name of the component,\nthe date and the component version number, and rec-\nognizes a set of standard options.\n', 16, 0)
(313.2007751464844, 493.17877197265625, 540.0028076171875, 560.9129638671875, 'maca select is a pre-processing component: it adds\na macaon tag under the target tags speciﬁed by\nthe user to the input XML ﬁle.\nThe follow-\ning components will only process the document\nparts enclosed in macaon tags.\n', 17, 0)
(313.2007751464844, 573.8367919921875, 540.0007934570312, 668.669921875, 'maca segmenter segments a text into sentences by\nexamining the context of punctuation with a\nregular grammar given as a ﬁnite state automa-\nton. It is disabled for automatic speech tran-\nscriptions which do not typically include punc-\ntuation signs and come with their own segmen-\ntation.\n', 18, 0)
(313.2008056640625, 677.1962280273438, 528.892333984375, 710.7855834960938, '12ling.uni-potsdam.de/˜moocow/projects/\ngfsm/\n13xmlsoft.org\n', 19, 0)
(290.4825439453125, 724.5388793945312, 301.39166259765625, 737.684326171875, '89\n', 20, 0)

page suivante
(72.00080108642578, 61.14677047729492, 298.80670166015625, 128.88198852539062, 'maca tokenizer tokenizes a sentence into pre-\nlexical units. It is also based on regular gram-\nmars that recognize simple tokens as well as a\npredeﬁned set of special tokens, such as time\nexpressions, numerical expressions, urls....\n', 0, 0)
(72.00080871582031, 136.3437957763672, 298.8034362792969, 217.62802124023438, 'maca lexer allows to regroup pre-lexical units into\nlexical units. It is based on the lefff French lex-\nicon (Sagot et al., 2006) which contains around\n500,000 forms. It implements a dynamic pro-\ngramming algorithm that builds all the possible\ngrouping of pre-lexical units into lexical units.\n', 1, 0)
(72.00079345703125, 225.0887908935547, 298.8052978515625, 306.3730163574219, 'maca tagger associates to every lexical unit one or\nmore part-of-speech labels.\nIt is based on a\ntrigram Hidden Markov Model trained on the\nFrench Treebank (Abeill´e et al., 2003). The es-\ntimation of the HMM parameters has been re-\nalized by the SRILM toolkit (Stolcke, 2002).\n', 2, 0)
(72.00080108642578, 313.83477783203125, 298.8007507324219, 368.02099609375, 'maca anamorph produces the morphological anal-\nysis of lexical units associated to a part of\nspeech. The morphological information come\nfrom the lefff lexicon.\n', 3, 0)
(72.00081634521484, 375.4827880859375, 298.8008117675781, 470.3160400390625, 'maca chunker gathers sequences of part-of-speech\ntags in non recursive syntactic units. This com-\nponent implements a cascade of ﬁnite state\ntransducers, as proposed by Abney (1996). It\nadds some features to the initial Abney pro-\nposal, like the possibility to deﬁne the head of\na chunk.\n', 4, 0)
(72.00080871582031, 477.77777099609375, 298.79638671875, 491.9705810546875, 'maca conv is a set of converters from and to the\n', 5, 0)
(93.81878662109375, 491.7195129394531, 298.80145263671875, 545.511962890625, 'MACAON exchange format.\nhtk2macaon\nand fsm2macaon convert word lattices from\nthe HTK format (Young, 1994) and ATT\nFSM format (Mohri et al.,\n2000) to the\n', 6, 0)
(93.81879425048828, 545.91650390625, 298.8009033203125, 613.2579345703125, 'MACAON exchange format. macaon2txt and\ntxt2macaon convert from and to plain text\nﬁles.\nmacaon2lorg and lorg2macaon\nconvert to and from the format of the LORG\nparser (see section 3.3).\n', 7, 0)
(72.00080871582031, 620.7197875976562, 298.7989501953125, 661.35693359375, 'maca view is a graphical interface that allows to in-\nspect MACAON XML ﬁles and run the compo-\nnents.\n', 8, 0)
(72.00079345703125, 667.1618041992188, 210.49180603027344, 681.3545532226562, '3.3\nThird party components\n', 9, 0)
(72.00080108642578, 685.031494140625, 298.80535888671875, 711.7259521484375, 'MACAON is an open architecture and provides a rich\nexchange format which makes possible the repre-\n', 10, 0)
(313.2008056640625, 61.53949737548828, 540.0009155273438, 74.68496704101562, 'sentation of many NLP tools input and output in the\n', 11, 0)
(313.20086669921875, 75.08850860595703, 540.0011596679688, 128.88198852539062, 'MACAON format. MACAON has been interfaced with\nthe SPEERAL Automatic Speech Recognition Sys-\ntem (Nocera et al., 2006). The word lattices pro-\nduced by SPEERAL can be converted to pre-lexical\n', 12, 0)
(313.473876953125, 129.28553771972656, 399.8408508300781, 142.43099975585938, 'MACAON automata.\n', 13, 0)
(313.20086669921875, 142.8345489501953, 540.00439453125, 332.1200866699219, 'MACAON does not provide any native module for\nparsing yet but it can be interfaced with any already\nexisting parser. For the purpose of this demonstra-\ntion we have chosen the LORG parser developed at\nNCLT, Dublin14. This parser is based on PCFGs\nwith latent annotations (Petrov et al., 2006), a for-\nmalism that showed state-of-the-art parsing accu-\nracy for a wide range of languages. In addition it of-\nfers a sophisticated handling of unknown words re-\nlying on automatically learned morphological clues,\nespecially for French (Attia et al., 2010). Moreover,\nthis parser accepts input that can be tokenized, pos-\ntagged or pre-bracketed. This possibility allows for\ndifferent settings when interfacing it with MACAON.\n', 14, 0)
(313.2008972167969, 340.86865234375, 395.2733459472656, 356.42236328125, '4\nApplications\n', 15, 0)
(313.2008361816406, 362.7046203613281, 540.006103515625, 660.3831176757812, 'MACAON has been used in several projects, two of\nwhich are brieﬂy described here, the DEFINIENS\nproject and the LUNA project.\nDEFINIENS (Barque et al., 2010) is a project that\naims at structuring the deﬁnitions of a large coverage\nFrench lexicon, the Tr´esor de la langue franc¸aise.\nThe lexicographic deﬁnitions have been processed\nby MACAON in order to decompose the deﬁnitions\ninto complex semantico-syntactic units. The data\nprocessed is therefore native text that possesses a\nrich XML structure that has to be preserved during\nprocessing.\nLUNA15 is a European project that aims at extract-\ning information from oral data about hotel booking.\nThe word lattices produced by an ASR system have\nbeen processed by MACAON up to a partial syntactic\nlevel from which frames are built. More details can\nbe found in (B´echet and Nasr, 2009). The key aspect\nof the use of MACAON for the LUNA project is the\nability to perform the linguistic analyses on the mul-\ntiple hypotheses produced by the ASR system. It is\ntherefore possible, for a given syntactic analysis, to\n', 16, 0)
(313.2008056640625, 666.2371826171875, 540.0057983398438, 710.7855834960938, '14www.computing.dcu.ie/˜lorg.\nThis software\nshould be freely available for academic research by the time\nof the conference.\n15www.ist-luna.eu\n', 17, 0)
(290.4825439453125, 724.5388793945312, 301.39166259765625, 737.684326171875, '90\n', 18, 0)

page suivante
(72.00080108642578, 238.8050537109375, 298.7993469238281, 274.72100830078125, 'Figure 2: Screenshot of the MACAON visualization inter-\nface (for French models). It allows to input a text and see\nthe n-best results of the annotation.\n', 0, 0)
(72.00080108642578, 294.39349365234375, 298.8009033203125, 348.9629821777344, 'ﬁnd all the word sequences that are compatible with\nthis analysis.\nFigure 2 shows the interface that can be used to\nsee the output of the pipeline.\n', 1, 0)
(72.00080108642578, 360.87652587890625, 147.0675048828125, 376.43023681640625, '5\nConclusion\n', 2, 0)
(72.00080108642578, 385.11151123046875, 298.80096435546875, 479.5520324707031, 'In this paper we have presented MACAON, an NLP\ntool suite which allows to process native text as well\nas several hypotheses automatically produced by an\nASR or an MT system. Several evolutions are cur-\nrently under development, such as a named entity\nrecognizer component and an interface with a de-\npendency parser.\n', 3, 0)
(72.00081634521484, 502.40362548828125, 127.5446548461914, 517.9573364257812, 'References\n', 4, 0)
(72.00081634521484, 525.1311645507812, 298.80389404296875, 711.4600830078125, 'Anne Abeill´e, Lionel Cl´ement, and Franc¸ois Toussenel.\n2003.\nBuilding a treebank for french.\nIn Anne\nAbeill´e, editor, Treebanks. Kluwer, Dordrecht.\nSteven Abney. 1996. Partial parsing via ﬁnite-state cas-\ncades. In Workshop on Robust Parsing, 8th European\nSummer School in Logic, Language and Information,\nPrague, Czech Republic, pages 8–15.\nM. Attia, J. Foster, D. Hogan, J. Le Roux, L. Tounsi, and\nJ. van Genabith. 2010. Handling Unknown Words in\nStatistical Latent-Variable Parsing Models for Arabic,\nEnglish and French. In Proceedings of SPMRL.\nLucie Barque, Alexis Nasr, and Alain Polgu`ere. 2010.\nFrom the deﬁnitions of the tr´esor de la langue franc¸aise\nto a semantic database of the french language. In EU-\nRALEX 2010, Leeuwarden, Pays Bas.\n', 5, 0)
(313.20074462890625, 62.3641357421875, 540.0053100585938, 487.6201171875, 'Fr´ed´eric B´echet and Alexis Nasr. 2009. Robust depen-\ndency parsing for spoken language understanding of\nspontaneous speech. In Interspeech, Brighton, United\nKingdom.\nOlivier Blanc, Matthieu Constant, and Eric Laporte.\n2006. Outilex, plate-forme logicielle de traitement de\ntextes ´ecrits. In TALN 2006, Leuven.\nNancy Ide and Laurent Romary.\n2004.\nInternational\nstandard for a linguistic annotation framework. Nat-\nural language engineering, 10(3-4):211–225.\nM. Mohri, F. Pereira, and M. Riley. 2000. The design\nprinciples of a weighted ﬁnite-state transducer library.\nTheoretical Computer Science, 231(1):17–32.\nP. Nocera, G. Linares, D. Massoni´e, and L. Lefort. 2006.\nPhoneme lattice based A* search algorithm for speech\nrecognition. In Text, Speech and Dialogue, pages 83–\n111. Springer.\nSlav Petrov, Leon Barrett, Romain Thibaux, and Dan\nKlein. 2006. Learning Accurate, Compact, and In-\nterpretable Tree Annotation. In ACL.\nBenoˆıt Sagot and Pierre Boullier.\n2008.\nSxpipe 2:\narchitecture pour le traitement pr´esyntaxique de cor-\npus bruts.\nTraitement Automatique des Langues,\n49(2):155–188.\nBenoˆıt Sagot, Lionel Cl´ement, Eric Villemonte de la\nClergerie, and Pierre Boullier. 2006. The lefff 2 Syn-\ntactic Lexicon for French: Architecture, Acquisition,\nUse.\nIn International Conference on Language Re-\nsources and Evaluation, Genoa.\nAndreas Stolcke. 2002. Srilm - an extensible language\nmodeling toolkit. In International Conference on Spo-\nken Language Processing, Denver, Colorado.\nS.J. Young.\n1994.\nThe HTK Hidden Markov Model\nToolkit: Design and Philosophy. Entropic Cambridge\nResearch Laboratory, Ltd, 2:2–44.\n', 6, 0)
(290.4825439453125, 724.5388793945312, 301.39166259765625, 737.684326171875, '91\n', 7, 0)

page suivante
